<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>枫哲&#39;s文栖小筑</title>
  
  <subtitle>君子终日乾乾，夕惕若厉，无咎</subtitle>
  <link href="http://ai.mak.cn/atom.xml" rel="self"/>
  
  <link href="http://ai.mak.cn/"/>
  <updated>2024-12-18T08:53:26.346Z</updated>
  <id>http://ai.mak.cn/</id>
  
  <author>
    <name>fantasykai</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>实时通信的关键差异解析</title>
    <link href="http://ai.mak.cn/2024/09/15/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/%E5%AE%9E%E6%97%B6%E9%80%9A%E4%BF%A1%E7%9A%84%E5%85%B3%E9%94%AE%E5%B7%AE%E5%BC%82%E8%A7%A3%E6%9E%90/"/>
    <id>http://ai.mak.cn/2024/09/15/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/%E5%AE%9E%E6%97%B6%E9%80%9A%E4%BF%A1%E7%9A%84%E5%85%B3%E9%94%AE%E5%B7%AE%E5%BC%82%E8%A7%A3%E6%9E%90/</id>
    <published>2024-09-14T16:00:00.000Z</published>
    <updated>2024-12-18T08:53:26.346Z</updated>
    
    <content type="html"><![CDATA[<h1 id="实时通信的关键差异解析"><a href="#实时通信的关键差异解析" class="headerlink" title="实时通信的关键差异解析"></a>实时通信的关键差异解析</h1><blockquote><p>文章介绍了 OSI 七层网络协议模型相关知识，详细阐述了 WebSocket 和 Server-Sent Events (SSE)的工作原理、特点、适用场景等。重点比较了二者在多个维度的差异，如通信模式、连接建立、适用场景等，并分析了豆包选择 SSE 而非 WebSocket 的原因，最后总结二者均是实现实时通信的有效技术，各有适用场景。</p></blockquote><blockquote><p>链接：<a href="https://juejin.cn/post/7411406818025717770">https://juejin.cn/post/7411406818025717770</a><br>来源：稀土掘金</p></blockquote><h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><p>在我们平时使用豆包的过程中，不知道大家有没有发现，界面上的内容不是一次性显示出来的，而是像是以一种实时的方式打印出来的，这种方式我们把他称之为流式打印。这种效果感觉互动性更强，更加真实，那么这种技术是如何实现的呢？其实传统的请求-响应模型（如HTTP&#x2F;HTTPS）并不能很好地满足这种实时流式输出。为此，目前主流的web实时通信技术主要是以以WebSocket和Server-Sent Events (SSE)为主，下面我们就一起介绍一下这两者之间的差异，以及为什么豆包选择使用SSE而不是Websocket？</p><p><img src="https://p3-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/b4e3a8c5623b483db90b0d0444cdca50~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5LqU5Y-35Y6C5oi_:q75.awebp?rk3s=f64ab15b&x-expires=1734923281&x-signature=F4lz8ACEYugkjodb+ZKCP5bSkx0=" alt="image.png"></p><h2 id="二、一些网络协议相关的知识补充"><a href="#二、一些网络协议相关的知识补充" class="headerlink" title="二、一些网络协议相关的知识补充"></a>二、一些网络协议相关的知识补充</h2><h3 id="1-OSI网络协议模型"><a href="#1-OSI网络协议模型" class="headerlink" title="1. OSI网络协议模型"></a>1. OSI网络协议模型</h3><p>OSI（Open System Interconnection）参考模型即开放式系统互联通信参考模型，是一种概念模型，由国际标准化组织（ISO）提出，目的是为了使各种计算机在世界范围内互连为网络。OSI 模型将计算机网络体系结构划分为七层，从下到上分别是：</p><p><img src="https://p3-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/4b14ba20de584e908d2e622a9a0d237c~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5LqU5Y-35Y6C5oi_:q75.awebp?rk3s=f64ab15b&x-expires=1734923281&x-signature=IkykC1FIer//Lqj/OA3TYgq2Dww=" alt="image.png"></p><p><strong>物理层</strong></p><ol><li>定义：物理层主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。它的主要作用是传输比特流（就是由 1、0 转化为电流强弱来进行传输，到达目的地后在转化为 1、0，也就是我们常说的数模转换与模数转换）。</li></ol><p><strong>数据链路层</strong></p><ol><li>定义：数据链路层主要将从物理层接收的数据进行 MAC 地址（网卡的地址）的封装与解封装。常把这一层的数据叫做帧。在这一层工作的设备是交换机，数据通过交换机来传输时，会根据数据中包含的 MAC 地址信息进行转发，实现不同设备之间的通信。以太网协议、PPP 协议等。以太网协议是最常见的数据链路层协议之一，它规定了如何在局域网中传输数据帧。PPP 协议则常用于广域网连接中，实现数据的可靠传输。</li></ol><p><strong>网络层</strong></p><ol><li>定义：网络层主要将从下层接收到的数据进行 IP 地址的封装与解封装。在这一层工作的设备是路由器，它根据 IP 地址将数据包从一个网络转发到另一个网络，实现不同网络之间的通信。IP 协议、ICMP 协议等。IP 协议是网络层的核心协议，它规定了如何给网络中的设备分配 IP 地址，以及如何将数据包从源地址传输到目的地址。ICMP 协议用于在 IP 网络中发送控制消息，例如报告错误或进行网络诊断。</li></ol><p><strong>传输层</strong></p><ol><li>定义：传输层定义了一些传输数据的协议和端口号，如 TCP 和 UDP。它主要是将从下层接收的数据进行分段和重组，为应用层提供端到端的可靠数据传输服务。例如，当你在浏览器中访问一个网页时，浏览器和服务器之间的通信就是通过传输层的协议来实现的。TCP（Transmission Control Protocol，传输控制协议）是一种面向连接的、可靠的传输层协议。它通过三次握手建立连接，在数据传输过程中进行流量控制和拥塞控制，确保数据的准确无误传输。UDP（User Datagram Protocol，用户数据报协议）是一种无连接的、不可靠的传输层协议。它不保证数据的可靠传输，但具有传输速度快、开销小的优点，适用于一些对实时性要求较高的应用，如视频会议、在线游戏等。</li></ol><p><strong>会话层</strong></p><ol><li>定义：会话层主要负责建立、管理和终止表示层实体之间的通信会话。它通过在通信双方之间建立、维护和管理会话，确保数据的有序传输。例如，在进行远程登录时，会话层负责建立和管理用户与远程服务器之间的会话，确保用户的输入和服务器的响应能够正确地交互。会话层的主要功能包括会话建立、会话管理和会话终止。在会话建立阶段，通信双方通过协商确定会话的参数，如会话标识符、加密方式等。在会话管理阶段，会话层负责维护会话的状态，确保数据的正确传输和接收。在会话终止阶段，会话层负责安全地终止会话，释放资源。</li></ol><p><strong>表示层</strong></p><ol><li>定义：表示层主要负责数据的表示、加密和压缩等功能。它将应用层的数据转换为适合网络传输的格式，并进行加密和压缩等处理，以提高数据的安全性和传输效率。例如，当你在网上购物时，你的信用卡信息需要进行加密处理，以确保信息的安全传输。表示层就是负责这种加密和转换的工作。表示层的主要功能包括数据格式转换、数据加密和数据压缩。在数据格式转换方面，它可以将不同格式的数据转换为统一的网络标准格式，以便在不同的系统之间进行通信。在数据加密方面，它可以使用各种加密算法对数据进行加密，保护数据的安全性。在数据压缩方面，它可以对数据进行压缩，减少数据的传输量，提高传输效率。</li></ol><p><strong>应用层</strong></p><ol><li>定义：应用层是 OSI 模型的最高层，它直接面向用户，为用户提供各种网络应用服务。例如，电子邮件、文件传输、网页浏览等都是应用层的服务。应用层通过调用下层的服务，实现各种具体的网络应用功能。HTTP（HyperText Transfer Protocol，超文本传输协议）是用于在 Web 上传输超文本的协议。SMTP（Simple Mail Transfer Protocol，简单邮件传输协议）用于发送电子邮件。FTP（File Transfer Protocol，文件传输协议）用于在网络上传输文件等。 总之，OSI 七层网络协议模型为计算机网络的通信提供了一个标准化的框架，使得不同的计算机系统和网络设备能够相互通信和协作。每一层都有其特定的功能和协议，它们共同构成了一个完整的网络通信体系。</li></ol><h3 id="2-WebSocket"><a href="#2-WebSocket" class="headerlink" title="2. WebSocket"></a>2. WebSocket</h3><p>WebSocket 是一种在单个 TCP 连接上进行全双工通信的协议。它使得客户端和服务器之间可以实现实时、双向的数据传输。</p><p><img src="https://p3-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/c3933ff01fa94c51b9a0a1a1008fb706~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5LqU5Y-35Y6C5oi_:q75.awebp?rk3s=f64ab15b&x-expires=1734923281&x-signature=I2pCsBywY8c0pBK5WAg7ogJdAko=" alt="image.png"></p><h4 id="2-1-工作原理"><a href="#2-1-工作原理" class="headerlink" title="2.1 工作原理"></a>2.1 工作原理</h4><p>WebSocket是一种独立的协议，用于在单个TCP连接上提供全双工通信。它通过HTTP&#x2F;HTTPS协议完成初始握手，然后升级到WebSocket协议。</p><p><strong>握手过程</strong></p><ul><li>• 客户端发送一个HTTP请求给服务器，包含特殊的WebSocket头信息，用于请求协议升级（从HTTP&#x2F;HTTPS升级到WebSocket协议）。</li><li>• 服务器接收到这个请求后，检查头信息并确认是否同意升级。如果同意，它会返回一个带有101状态码的HTTP响应，表示协议切换（Switching Protocols）。</li></ul><p><strong>通信过程</strong></p><ul><li>• 在握手成功后，客户端和服务器通过WebSocket协议持久连接进行通信。此连接将保持打开状态，双向数据流可以在任一端发起，而不需要每次发消息都重新建立连接。WebSocket的消息是帧格式的，分为数据帧和控制帧。</li></ul><h4 id="2-2-特点"><a href="#2-2-特点" class="headerlink" title="2.2 特点"></a>2.2 特点</h4><ul><li>• <strong>双向通信</strong>：支持客户端和服务器之间的全双工通信。</li><li>• <strong>低延迟</strong>：适合要求低延迟的实时应用，如在线聊天、多人游戏。</li><li>• <strong>数据帧格式</strong>：WebSocket协议规定了消息的帧格式，包括控制帧和数据帧。</li></ul><h4 id="2-3-适用场景"><a href="#2-3-适用场景" class="headerlink" title="2.3 适用场景"></a>2.3 适用场景</h4><ol><li>实时聊天应用：WebSocket 非常适合实时聊天应用，用户可以即时发送和接收消息，无需不断刷新页面。聊天消息可以实时推送给所有在线用户，提供良好的交互体验。</li><li>在线游戏：在在线游戏中，需要实时传输玩家的操作和游戏状态。WebSocket 可以实现低延迟的通信，确保玩家能够及时响应游戏中的变化。</li><li>股票行情和金融数据：对于股票行情和金融数据的实时更新，WebSocket 可以提供快速的数据传输，使投资者能够及时了解市场动态。</li><li>协作工具：如在线文档编辑、实时绘图等协作工具需要实时同步用户的操作。WebSocket 可以实现多个用户之间的实时协作，提高工作效率。</li><li>物联网（IoT）：在物联网应用中，设备需要实时向服务器发送数据并接收指令。WebSocket 可以为物联网设备提供可靠的通信渠道，实现远程监控和控制。</li></ol><h3 id="3-Server-Sent-Events-SSE"><a href="#3-Server-Sent-Events-SSE" class="headerlink" title="3. Server-Sent Events (SSE)"></a>3. Server-Sent Events (SSE)</h3><h4 id="3-1-工作原理"><a href="#3-1-工作原理" class="headerlink" title="3.1 工作原理"></a>3.1 工作原理</h4><p>Server-Sent Events (SSE) 是一种在客户端和服务器之间传递事件的机制，主要用于<strong>服务器向客户端推送实时数据</strong>。<strong>SSE并不是一种协议而是一种机制</strong>，这也是区别于WebSocket的地方之一。</p><p>虽然SSE并没有像WebSocket那样定义出一个独立的协议，但它却通过标准的HTTP协议实现了类似长连接的功能。SSE规定了特定的<strong>MIME类型和数据格式</strong>，来让服务器持续发送数据流。</p><p><img src="https://p3-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/184fbdff2937467b901993bd34350b96~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5LqU5Y-35Y6C5oi_:q75.awebp?rk3s=f64ab15b&x-expires=1734923281&x-signature=qCf6DSSspZxXzw3LkLbGoui5QXQ=" alt="image.png"></p><h4 id="3-2-特点"><a href="#3-2-特点" class="headerlink" title="3.2 特点"></a>3.2 特点</h4><p>\1. <strong>使用标准HTTP协议</strong></p><p>SSE在现有的HTTP&#x2F;HTTPS协议之上构建，不需要额外的协议或端口。客户端向服务器发送一个普通HTTP请求，服务器响应该请求，并持续发送数据。 如下图所示：</p><p><img src="https://p3-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/075669e9968d4c36b98f70b2570a4861~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5LqU5Y-35Y6C5oi_:q75.awebp?rk3s=f64ab15b&x-expires=1734923281&x-signature=0lGOiKE8nBvzb6oLA/hue27lRx4=" alt="image.png"></p><p>\2. <strong>特定的MIME类型</strong></p><p>在SSE中，服务器的响应内容类型必须是 <code>text/event-stream</code>，这告诉浏览器或者客户端这是一个SSE数据流。 如下图所示：</p><p><img src="https://p3-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/204d08548ec24c869d76cbf91c11ea3f~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5LqU5Y-35Y6C5oi_:q75.awebp?rk3s=f64ab15b&x-expires=1734923281&x-signature=ZOSJ9TZHvGudhbOvsiDyafT9h4I=" alt="image.png"></p><p>\3. <strong>单向通信</strong></p><p>SSE是一种单向通信方式，即服务器推送数据到客户端，客户端通常只是接收和处理数据，不向服务器发送响应的数据流。需要额外进行双向通信时，可以通过Ajax等其他技术辅助手段实现。</p><p>\4. <strong>自动重连和事件流ID</strong>（Last-Event-ID）</p><p>SSE具有自动重连功能。如果连接中断，浏览器会自动重新连接，并且可以通过 <code>Last-Event-ID</code> 头来继续从断开点接收数据。</p><p><img src="https://p3-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/22664beed55d464a8552d6649c30ece4~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5LqU5Y-35Y6C5oi_:q75.awebp?rk3s=f64ab15b&x-expires=1734923281&x-signature=7BmGc4RND6Cv0Jt2V9QjEbGRCQQ=" alt="image.png"></p><h4 id="3-3-适用场景"><a href="#3-3-适用场景" class="headerlink" title="3.3 适用场景"></a>3.3 适用场景</h4><ol><li>实时通知：SSE 可以用于实现实时通知，如邮件通知、系统警报等。当有新的通知时，服务器可以立即将通知推送给客户端，用户无需手动刷新页面即可获取最新的通知。</li><li>股票行情和金融数据：与 WebSocket 类似，SSE 也可以用于实时更新股票行情和金融数据。服务器可以将最新的股票价格、指数等数据推送给客户端，让用户能够及时了解市场动态。</li><li>日志监控：在服务器端进行日志监控时，可以使用 SSE 将日志信息实时推送给客户端。这样，管理员可以在浏览器中实时查看服务器的日志，及时发现和解决问题。</li><li>社交网络更新：社交网络应用可以使用 SSE 来实时推送新的动态、消息和通知。用户可以在不刷新页面的情况下获取最新的社交网络更新。</li></ol><h2 id="三、-豆包为什么选择SSE而不是websocket的呢"><a href="#三、-豆包为什么选择SSE而不是websocket的呢" class="headerlink" title="三、 豆包为什么选择SSE而不是websocket的呢?"></a>三、 豆包为什么选择SSE而不是websocket的呢?</h2><p>SSE建立在已有的HTTP协议之上，这是Web开发中最常用和最成熟的协议之一。以下是这两者各个维度的比较</p><table><thead><tr><th>比较类别</th><th>Server-Sent Events（SSE）</th><th>WebSocket</th></tr></thead><tbody><tr><td>通信模式</td><td>单向，服务器向客户端发送数据</td><td>双向，客户端和服务器可互相发送数据</td></tr><tr><td>连接建立</td><td>基于 HTTP 协议，客户端发起特殊请求，服务器响应</td><td>通过握手协议建立全双工连接</td></tr><tr><td>适用场景</td><td>适用于单向的服务器推送场景，如实时通知、股票行情等</td><td>适用于双向通信的实时应用，如在线游戏、实时协作等</td></tr><tr><td>重连机制</td><td>如果连接中断，客户端自动尝试重新连接</td><td>如果连接中断，客户端可尝试重新连接</td></tr><tr><td>数据传输格式</td><td>事件流格式，每个事件由事件类型和数据组成</td><td>可以是文本数据或二进制数据</td></tr><tr><td>复杂性</td><td>相对简单，基于 HTTP 协议，无需处理复杂的双向通信状态</td><td>相对复杂，需要处理更多协议细节和状态管理</td></tr><tr><td>浏览器支持</td><td>广泛支持</td><td>广泛支持</td></tr><tr><td>协议开销</td><td>通常较小，因为基于 HTTP 协议且单向通信</td><td>相对较大一些，由于要建立全双工连接和处理更多状态</td></tr><tr><td>服务器资源占用</td><td>一般情况下相对较低，因为主要是单向推送</td><td>可能较高，因为需要处理双向通信和更多的连接状态变化</td></tr><tr><td>安全性</td><td>依赖于底层 HTTP 的安全机制</td><td>可以使用加密等安全措施，与 HTTP 类似但需额外配置</td></tr><tr><td>开发难度</td><td>对于简单的服务器推送场景较容易开发</td><td>双向通信场景下开发难度相对较高，需要处理更多复杂情况</td></tr><tr><td>与代理服务器兼容性</td><td>通常较好，因为基于 HTTP 协议，与常见代理服务器兼容性高</td><td>可能会遇到一些代理服务器不兼容的情况，需要进行额外配置</td></tr></tbody></table><p>综上所述，豆包选择了SSE而不是Websocket。</p><h2 id="四、-总结"><a href="#四、-总结" class="headerlink" title="四、 总结"></a>四、 总结</h2><p>WebSocket和Server-Sent Events (SSE) 都是实现长连接、实时通信的有效技术，各有优劣。WebSocket适合需要低延迟、双向通信的应用场景，如聊天应用、在线游戏和实时协作工具。SSE则更适用于单向数据推送场景，是一种简单而有效的服务器推送技术，非常适用于各种需要实时更新的应用场景，如网页对话、新闻实时更新、股票行情和实时投票结果展示，它基于 HTTP 协议，具有自动重连和事件流格式等特点，使得客户端能够轻松地接收服务器推送的信息。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;实时通信的关键差异解析&quot;&gt;&lt;a href=&quot;#实时通信的关键差异解析&quot; class=&quot;headerlink&quot; title=&quot;实时通信的关键差异解析&quot;&gt;&lt;/a&gt;实时通信的关键差异解析&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;文章介绍了 OSI 七层网络协议模型相关知</summary>
      
    
    
    
    <category term="技术小栈" scheme="http://ai.mak.cn/categories/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/"/>
    
    
    <category term="架构" scheme="http://ai.mak.cn/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>5公里成绩跑进20分钟！</title>
    <link href="http://ai.mak.cn/2024/08/25/%E8%B7%91%E6%AD%A5/5%E5%85%AC%E9%87%8C%E6%88%90%E7%BB%A9%E8%B7%91%E8%BF%9B20%E5%88%86%E9%92%9F%EF%BC%81/"/>
    <id>http://ai.mak.cn/2024/08/25/%E8%B7%91%E6%AD%A5/5%E5%85%AC%E9%87%8C%E6%88%90%E7%BB%A9%E8%B7%91%E8%BF%9B20%E5%88%86%E9%92%9F%EF%BC%81/</id>
    <published>2024-08-24T16:00:00.000Z</published>
    <updated>2024-12-18T09:12:14.327Z</updated>
    
    <content type="html"><![CDATA[<h1 id="5公里成绩跑进20分钟！"><a href="#5公里成绩跑进20分钟！" class="headerlink" title="5公里成绩跑进20分钟！"></a>5公里成绩跑进20分钟！</h1><p>5km，在跑者眼里是一个很有意义的路程。</p><p>5km，它不算长，也不算短，是很多跑者从初阶晋级到高阶的一个点。</p><p>唯有突破了5km，才能往更远的距离去跑，实现更大的突破。</p><p>5km，也是很多跑者需要着重训练的一个路程，既可以看出一个人的爆发力，还可以大概预测出你的半马、全马的成绩。</p><p>5km成绩如果能够突破20分钟，是很多业余跑者的梦想。</p><p>一旦5km跑进了20分钟，也就意味着你是业余跑者中的大神般的存在。</p><p><strong>贰</strong></p><p><strong>5km跑进20分，是什么概念？</strong></p><p>也就是意味着，你每公里的配速不能低于4分配速，也就是你的奔跑时速要达到15km&#x2F;h。</p><p>如果能够一直维持在4分配速，那么10km只需要40分钟，半马84分钟，全马2小时48分就能够跑完。</p><p>这在业余跑者中已经算是很高的成就了。</p><p>所以，以此类推，如果想要全马破3小时，你的5km速度就必须要破20分钟！</p><p><strong>叁</strong></p><p>下面介绍三种非常有效的训练方式，只要经过科学系统的训练，想要5km成绩突破20分，是很有希望的。</p><p><strong>1、加强力量训练：</strong></p><p>5km要破20分钟，需要你要有强大的肌肉力量。只有强有力的核心力量以及大小腿力量，你在奔跑的时候才能够完好的控制身体，不至于力量不足导致身体发软。</p><p>很多人在跑步时，往往都会忽视力量训练，认为我只要每天跑就行了。实际上这种认识是错误的。</p><p>在平时，有条件的可以到健身房进行锻炼，腰腹力量，背部力量，腿部力量都要锻炼到。</p><p>没有条件的，也要在家自己练习。比较实用的动作有深蹲、靠墙静蹲、卷腹、平板支撑等。</p><p><strong>2、练好有氧基础：</strong></p><p>想要跑得快，就必须要有足够的有氧能力。</p><p>有氧能力是决定你能跑多远的基础，但凡能够跑得又快又远的人，他的有氧基础都是响当当的。</p><p>在一周时间里，可以花个两三天时间来锻炼有氧基础。</p><p>有氧能力就是指在最大心率的60%强度下奔跑，距离可以控制在10km左右，长期坚持下去，个人的有氧能力会得到很大提升。</p><p><strong>3、提高乳酸阈值：</strong></p><p>想要跑得快，乳酸阈值一定要得到有效提高。</p><p>乳酸阈值是指人体在渐增负荷运动中，血乳酸浓度随运动负荷的渐增而增加，当运动强度达到某一负荷时，血乳酸浓度急剧上升，而在上升的这个起点就是阈值。</p><p>当我们跑得很快的时候，没过多久就会觉得大小腿发酸，就像灌铅了似的，这就是因为你体内的乳酸积累多了，所以就会非常容易感到疲惫。</p><p>而为了跑得更远跑得更快，我们就必须提高自己的乳酸阈值。</p><p>那么，如何才能提高乳酸阈值门槛呢？</p><p><strong>最简单有效的就是间歇跑和法特莱克跑。</strong></p><p>在有氧基础得到有效提高，肌肉力量也足够强大的时候，就可以开始练习间歇跑和冲刺跑了。因为间歇跑和冲刺跑强度都比较大，一星期练一次就够了。</p><p>所为法特莱克跑，是一种加速跑与慢跑交替进行的中长跑训练方法，在跑中插入一系列不定时间、不定距离的加速跑、反复跑甚至快速冲刺，使它们和慢跑或走步交替进行。法特莱克跑是无氧训练中经常用到的一个方法。</p><p>相信经过一段时间的训练，突破5公里成绩能够成功跑进20分钟，也是指日可待的事情。</p><p><strong>事实会证明，所有的辛苦和汗水，都不会白费。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;5公里成绩跑进20分钟！&quot;&gt;&lt;a href=&quot;#5公里成绩跑进20分钟！&quot; class=&quot;headerlink&quot; title=&quot;5公里成绩跑进20分钟！&quot;&gt;&lt;/a&gt;5公里成绩跑进20分钟！&lt;/h1&gt;&lt;p&gt;5km，在跑者眼里是一个很有意义的路程。&lt;/p&gt;
&lt;p&gt;5k</summary>
      
    
    
    
    <category term="跑步" scheme="http://ai.mak.cn/categories/%E8%B7%91%E6%AD%A5/"/>
    
    
    <category term="健康" scheme="http://ai.mak.cn/tags/%E5%81%A5%E5%BA%B7/"/>
    
  </entry>
  
  <entry>
    <title>提升跑步能力，这三项训练缺一不可</title>
    <link href="http://ai.mak.cn/2024/08/11/%E8%B7%91%E6%AD%A5/%E6%8F%90%E5%8D%87%E8%B7%91%E6%AD%A5%E8%83%BD%E5%8A%9B%EF%BC%8C%E8%BF%99%E4%B8%89%E9%A1%B9%E8%AE%AD%E7%BB%83%E7%BC%BA%E4%B8%80%E4%B8%8D%E5%8F%AF/"/>
    <id>http://ai.mak.cn/2024/08/11/%E8%B7%91%E6%AD%A5/%E6%8F%90%E5%8D%87%E8%B7%91%E6%AD%A5%E8%83%BD%E5%8A%9B%EF%BC%8C%E8%BF%99%E4%B8%89%E9%A1%B9%E8%AE%AD%E7%BB%83%E7%BC%BA%E4%B8%80%E4%B8%8D%E5%8F%AF/</id>
    <published>2024-08-10T16:00:00.000Z</published>
    <updated>2024-12-18T09:08:31.226Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://mp.weixin.qq.com/s/DfBvo1-iVbBgpoj1Dfwgyw">https://mp.weixin.qq.com/s/DfBvo1-iVbBgpoj1Dfwgyw</a></p></blockquote><h1 id="提升跑步能力，这三项训练缺一不可"><a href="#提升跑步能力，这三项训练缺一不可" class="headerlink" title="提升跑步能力，这三项训练缺一不可"></a>提升跑步能力，这三项训练缺一不可</h1><p>马拉松世界冠军基普乔格，全名埃利乌德·基普乔格，1984年11月5日出生于肯尼亚西部的裂谷省南迪郡，他的母亲是一位教师，父亲在他刚出生不久就去世了，基普乔格是家里四个孩子中最小的一个。</p><p>据说，基普乔格每天都要跑3公里去上学，因为迟到的学生，要接受老师的体罚。就这样，基普乔格一直跑到16岁，这也不知不觉中锻炼了他跑步的能力。</p><p>2000年，基普乔格结识了肯尼亚的奥运长跑冠军帕特里克·桑(Patrick Sang)。帕特里克·桑和基普乔格住处离得不远，基普乔格很想让帕特里克·桑为自己做一份训练计划。</p><p>而帕特里克·桑一眼就看中了这个跑步的苗子，在几次交流之后，帕特里克·桑就成为了基普乔格的教练。</p><p>而这也开启了属于基普大神的黄金20年时光。</p><p>2019年10月，基普乔格在奥地利维也纳的路拉特公园参加了Ineos 159挑战，再次向两小时的极限发起冲刺。最终以1小时59分40秒完成挑战，成为人类历史上，第一个跑进2小时的马拉松选手。</p><p>虽然这项成绩不被国际田联认可，但基普乔格还是创造了历史，成为人类体育史上的一大亮点。</p><p><strong>二、基普乔格推荐的3项身体素质训练</strong></p><p>我们都以为出生于肯尼亚的基普乔格，天生就是跑步的天才，实际上能够取得今天这样的成就，除了长跑的天赋，就是老天爷赏饭吃之外，也不能缺少他个人的刻苦训练。</p><p>如果我们以为基普乔格，只是靠跑步天分，就能够成为马拉松届的天花板，那么就误解了乔大侠颇为重视的身体素质训练。</p><p>以下分别罗列一下基普乔格推荐并且始终坚持的3项身体素质训练，相信也会对我们自身的跑步训练课有所启发和借鉴。</p><p>正如乔神的教练帕特里克·桑所言：“<strong>心理素质要比身体素质更重要，肯尼亚从不缺才华横溢的苗子，只有心理强大的人才会走的很远。</strong>”。</p><p>从2012年转战马拉松开始， 基普乔格已经驰骋马拉松赛场10年，创造了10年的辉煌，自律和坚持才是基普乔格成功的关键。</p><p><strong>素质训练①：肌肉力量训练</strong></p><p>1、深蹲</p><p>主要用来发展臀部和大腿前侧的力量</p><p>2、弓箭步提膝</p><p>可以模拟跑步发力，增强臀腿肌肉力量</p><p>3、单腿硬拉</p><p>可以增强腘绳肌耐力，增强髋外旋外展肌肉耐力，同时，维持跑步过程中髋关节的稳定性</p><p>4、单腿提踵</p><p>可有效增强脚踝和小腿的肌肉耐力</p><p><strong>素质训练②：核心训练</strong></p><p>1、平板交替抬腿</p><p>可以模拟跑步伸髋动作，增加腹横肌稳定和身体抗旋转的能力</p><p>2、仰卧蹬自行车</p><p>可以增加腹部内外斜肌肌肉耐力，好的跑步姿势，离不开强大的核心肌肉群。</p><p>3、俯身登山跑</p><p>可以模拟跑步发力，提升腹部肌肉和腰大肌肌肉耐力</p><p>4、摸膝卷腹</p><p>可以很好地刺激到腹部肌肉群，增强核心肌肉能力</p><p><strong>素质训练③：跑步专项技术</strong></p><p>1、垫歩提膝</p><p>可有效提升髋关节灵活性</p><p>2、折叠腿</p><p>学会脚跟拉向臀部，增大跑步的车轮半径</p><p>3、直腿跑</p><p>学会用髋关节发力，脚掌落地下压并快速提拉</p><p>4、后蹬跑</p><p>可以提升肌肉弹性以及爆发力，增强腿部韧带刚性，可以有效增大步幅</p><p>基普乔格的马拉松生涯并没有划上句号，正如他所说：<strong>记录就是应该被打破的。</strong></p><p>希望乔大侠能够继续挑战新的世界记录。即使无法再创造之前的运动传奇，也不会影响我们对这位伟大运动员的尊重和热爱。</p><p>乔大侠的成功，与严格的自律和坚持是分不开的，最后以他的一句名言结尾，希望我们也能够通过适合自己强度的训练，能够有所收获。</p><p><strong>“人人皆可超越自己的极限！”</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/DfBvo1-iVbBgpoj1Dfwgyw&quot;&gt;https://mp.weixin.qq.com/s/DfBvo1-iVbBgpoj1Dfwgyw&lt;/a&gt;&lt;/p&gt;
&lt;/bloc</summary>
      
    
    
    
    <category term="跑步" scheme="http://ai.mak.cn/categories/%E8%B7%91%E6%AD%A5/"/>
    
    
    <category term="健康" scheme="http://ai.mak.cn/tags/%E5%81%A5%E5%BA%B7/"/>
    
  </entry>
  
  <entry>
    <title>一米奇迹：怎样让你的工位更健康？</title>
    <link href="http://ai.mak.cn/2024/08/03/%E6%9D%82%E8%AE%B0/%E4%B8%80%E7%B1%B3%E5%A5%87%E8%BF%B9%EF%BC%9A%E6%80%8E%E6%A0%B7%E8%AE%A9%E4%BD%A0%E7%9A%84%E5%B7%A5%E4%BD%8D%E6%9B%B4%E5%81%A5%E5%BA%B7%EF%BC%9F/"/>
    <id>http://ai.mak.cn/2024/08/03/%E6%9D%82%E8%AE%B0/%E4%B8%80%E7%B1%B3%E5%A5%87%E8%BF%B9%EF%BC%9A%E6%80%8E%E6%A0%B7%E8%AE%A9%E4%BD%A0%E7%9A%84%E5%B7%A5%E4%BD%8D%E6%9B%B4%E5%81%A5%E5%BA%B7%EF%BC%9F/</id>
    <published>2024-08-02T16:00:00.000Z</published>
    <updated>2024-12-18T08:47:00.210Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>节选自：得到头条 | 377期</p></blockquote><p>今天，我将从两个话题出发，为你提供知识服务。第一个是，全国第36个爱国卫生健康月活动落下帷幕。第二个是，2024年一季度，可可价格大幅上涨。</p><p>先来看今天的第一条。刚刚结束的4月，是全国第36个爱国卫生健康月，今年的主题是“健康城镇，健康体重”。很多地方都组织了相关的活动，包括倡导绿色出行、推广卫生习惯，还有针对上班族的运动建议，等等。</p><p>但是，你也知道，这些建议对特别忙的职场人来说，落实起来多少有点难度。你在办公室里度过了最多的时间，但这部分时间的健康体验，往往很难保证。</p><p>因此今天，借着这个话题，我们就说几个，在办公室就能执行的健康方案。</p><p>这些方法来自斯坦福大学医学院的神经科学家安德鲁·休伯曼。他的主要研究课题之一，就是借用神经科学的原理，给上班族设计办公室里的健康方案。休伯曼还把这些内容做成了一个播客，叫休伯曼实验室，有50多万名用户。</p><p>我们给这些方案起了个名字，叫一米奇迹。也就是，在你工位一米之内的范围就能完成，并且效果不错的方法。掌握这些方法既能提升你的工作体验，让人身心变得更健康，同时也能提升工作效率。好，咱们正式开始。</p><p>先介绍个背景信息，休伯曼教授从神经科学的角度，把一天分为三个阶段，这三个阶段你身体内部的激素水平不同，工作状态也不同。</p><p>第一个阶段，是从起床开始算起的7到8小时，也就是从早上到下午的这段时间。这时你体内的多巴胺、去甲肾上腺素、皮质醇的含量都在一个比较高的状态。你整个人也高度专注，适合做逻辑分析之类的工作。咱们可以把这个阶段叫做“分析期”。</p><p>第二个阶段，是起床后的8到16个小时，也就是下午和傍晚。这时你体内的血清素等神经调节剂含量会提高，这些激素会提高大脑的抽象思维能力，适合做一些创造性的工作。咱们可以把这个阶段叫做“创意期”。</p><p>第三个阶段，就是睡前和睡眠阶段，这个时候，最关键的就是好好休息。</p><p>咱们的工作时间主要集中在前两个阶段，也就是，分析阶段和创意阶段。休伯曼教授说，你可以针对性地做一些调节，让这两个阶段的工作更健康。这些调节主要分三种。</p><p>第一种，是调节光照。</p><p>按照上面的分类，<strong>在第一阶段，也就是起床后的7到8小时，你应该尽可能地照亮自己的工作环境，促进体内多巴胺、去甲肾上腺素和皮质醇的释放。</strong> 这能让你更清醒、更专注。假如你在室内工作，最好的座位是自然光线充足的窗户边，而且最好打开窗户，因为玻璃会过滤掉自然光中50%的蓝光，而蓝光对神经的唤醒作用是非常重要的。假如不在窗边，你也要让自己的办公环境足够亮。并且，注意，要打开头顶的灯。<strong>头顶的灯光会直接刺激你眼睛里的一组神经元细胞，叫做“黑质神经节细胞”，这可以让你的大脑更敏锐。</strong></p><p>同时，你还可以通过一个小调整，帮自己保持这种敏锐。这就是，把电脑屏幕，调高一点。视觉焦点，也就是眼神对焦的地方，会对神经产生不同的影响。当你向上看时，神经会变得兴奋，向下看时，你会变得平静甚至犯困。因此，<strong>你可以把电脑高度调高，调到和眼睛平齐，或者更高一点的地方，让自己的视觉焦点在斜上方。这能帮助你保持专注。</strong></p><p>而到了第二阶段，也就是下午3点之后，这时你的抽象思考开始活跃，适合做一些创意性的工作。这时，你需要降低光照强度，可以关掉头顶的主灯，留一些环境灯。光线稍微暗一点，有利于体内血清素的释放，更适合去做一些创造性的工作。</p><p>总之，光照这方面，其实不复杂，主要就是遵循自然规律，早上强，下午弱，天黑就休息。</p><p>休伯曼说的第二种，是调节空间范围。这里他引用很有名的“大教堂效应”，也就是，建筑的高度，会对人的思考模式产生影响。<strong>在天花板低的空间，人更善于处理具象的东西，也就是更有分析能力，而在天花板高的空间里，人更善于处理抽象的东西，也就是更有创意。</strong></p><p>因此，还是按照前面的阶段，起床后的7到8小时，你可以在一个小空间里干活，保持高度的专注力，处理需要逻辑分析的工作。假如环境不允许，比如你就是得处在一个空旷嘈杂的环境里，那么休伯曼说，你可以人为地给自己创造一个小空间。他观察到，斯坦福附近有很多在咖啡厅工作和学习的人，会穿帽衫，戴帽子，这就是人为地给自己创造一个低天花板的小空间。</p><p>而到了第二个阶段，创意工作期，你就可以找一个空间大的地方，去处理偏抽象的工作。</p><p>同时，休伯曼还提到一个因素，叫双耳频率。也就是两只耳朵同时听一段声音，但两只耳朵听到的频率有所不同。当你听这种双耳频率的时候，大脑会慢慢调节出一种特定的专注状态。休伯曼说，听30分钟左右的40赫兹双耳频率，对工作的效果最好。相关的音频网上就有，你可以找来试试看。</p><p>最后咱们接着来看休伯曼说的第三种方法，是调节身体姿势。</p><p>这个方法不算新。关于坐着办公好，还是站着办公好，咱们之前也说过，单独采用哪种姿势，都不如交替着来好，一会儿站着，一会儿坐着。有研究指出，<strong>假如每天有一半以上的时间站着工作，就可以减缓脖子和肩膀的疼痛，改善驼背，并且能让你燃烧更多的卡路里。</strong></p><p>不过，这都是从身体健康层面来理解这个问题，休伯曼提醒，这对大脑的效率也有所影响。人在躺着的时候，警觉性是最低的，坐着次之，而当你站起来或者动起来的时候，大脑中的“蓝斑神经元”会变得活跃，它能促进多巴胺和肾上腺素的释放，让我们变得更加警觉。因此，站着办公和坐着办公五五开，比如半个小时交换一次，效果是最好的。另外，尤其要注意的一点是，休伯曼说，当你站着的时候，要注意保持独立，不要靠在桌子上。</p><p>好，以上就是休伯曼提供的行动清单。简单总结一下，在上午和中午的工作中，你可以打开顶灯，把显示器抬高，在小空间里办公。假如想更专注，你可以戴上帽子，听点儿双耳频率。下午和傍晚，你可以把光线调暗，在大空间里办公。同时，一天中，你最好时常站起来，保证有一半的时间站着办公。最后，也祝你有一个高效健康的办公空间。</p><p>再来看今天的第二条。最近，可可豆又涨价了。就在第一季度，美国可可豆期货的价格突破一万美元，即便近期有回落的迹象，也稳定在9700美元&#x2F;吨左右。英国可可豆期货的价格也同样上涨，最高时8672英镑&#x2F;吨，创下历史新高。根据“彭博社”的报道，从20世纪80年代以来，可可豆的交易价格基本保持在3500美元&#x2F;吨左右。而在今年第一季度，价格却涨了好几倍。</p><p>可可豆涨价会带来哪些影响？</p><p>第一，巧克力可能会涨价。比如，瑞士的巧克力品牌瑞士莲，去年上半年价格就上涨了9%左右。再比如，北美最大的巧克力及糖果制造商好时，2023年第三季度的价格同比上涨了11%左右。再比如，今年，雀巢、费列罗等国际知名巧克力品牌都陆续宣布涨价计划。</p><p>第二，未来巧克力的包装尺寸可能会越来越小，可可的纯度可能也会越来越低。根据“大洋网”的报道，在人均巧克力消费排名全球第一的瑞士，2023年瑞士人均购买的巧克力是11公斤，跟2022年相比有所下降。再比如，根据美国糖果协会的数据显示，2023年，美国的巧克力销量，跟2022年比萎缩了5.3%。换句话说，消费者对巧克力价格的反应很敏感。因此，为了保持市场竞争力，很多品牌开始从包装着手，也就是通过更小的包装，降低价格来维持销量。</p><p>第三，可可豆价格持续上涨，可能会导致可可添加剂产业增长。说白了，就是给可可脂找平替。比如，代可可脂。原来，代可可脂因为含有反式脂肪酸，在市面上不太受欢迎。但由于这次的可可豆危机，代可可脂又出现了翻红的迹象。</p><p>但话说回来，为什么这两年可可豆一直在涨价呢？</p><p>表面上看，是因为极端天气。也就是从2023年5月开始的厄尔尼诺现象，导致可可豆产量下降。再加上可可豆的种植地很集中。目前全世界75%的可可豆，集中在非洲的加纳、喀麦隆、科特迪瓦以及尼日利亚。这就好比鸡蛋都装在同一个篮子里，抗风险能力自然有限。</p><p>但是，假如深入观察，影响可可豆价格的，还有另一个更关键的原因，这就是金融因素。</p><p>作为全球交易量大的农产品之一，可可豆也是种期货。由于全球灾害性天气频发，再加上，可可树本身种植3到5年后才能结果。因此，欧美国家的期货市场就预测可可豆的产量很难在短期内提高，价格也会持续上涨。</p><p>比如，根据《金融时报》的报道，对冲基金们已经在伦敦和纽约的可可期货合约中，投入了将近87亿美元，主要就是押注未来可可豆的价格会继续上涨。</p><p>再比如，根据“彭博社”的报道，还有一些公司会采取“套期保值”策略，也就是在买进可可豆本身的同时，会买入同等数量的期货合约，来降低这笔货物的赔钱风险。</p><p>这些金融市场的行为，会进一步放大气候变化对可可豆价格造成的影响。</p><p>之前，薛兆丰老师在他的经济学课中就讲过，对未来天气变化的趋势，期货市场比国家气象局还要敏感。其中的道理就是，对气候的预测，会影响对农产品产量的预测，从而直接影响期货市场对价格的预测。</p><p>你看，说到这，我们又回到了经济学的视角。借用薛兆丰老师的话说，<strong>经济学研究的并不是关于钱的知识，而是真实世界的运行规律，是人与人之间的协作方式。而一切自然因素带来的影响，都会被人类的协作网络放大。</strong> 从这个角度看，懂一点经济学，是不是很有必要？最近，薛兆丰老师的经济学课又有加餐，假如你对经济学感兴趣，这门课推荐你来看一看。</p><p>最后，总结一下，今天说了两个话题。</p><p>第一，怎样借助神经科学提升工作健康度？我们说了一组很具体的建议。包括，上午找一个小点的空间，把光线调亮，把显示器抬高，并多做逻辑性的工作。下午反过来，把光线调暗，找一个大点的空间，多做创意性的工作。</p><p>第二，可可豆价格为什么上涨？自然因素只是一个基础，关键是人的预期，给这个基础提供了杠杆。换句话说，决定涨价的不仅是产量，更是人的预期。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;节选自：得到头条 | 377期&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天，我将从两个话题出发，为你提供知识服务。第一个是，全国第36个爱国卫生健康月活动落下帷幕。第二个是，2024年一季度，可可价格大幅上涨。&lt;/p&gt;
&lt;p&gt;先来看今天的第一条</summary>
      
    
    
    
    <category term="杂记" scheme="http://ai.mak.cn/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
    <category term="杂记" scheme="http://ai.mak.cn/tags/%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>微服务核心架构梳理</title>
    <link href="http://ai.mak.cn/2024/07/28/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/%E9%80%9A%E7%94%A8%E7%9A%84%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    <id>http://ai.mak.cn/2024/07/28/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/%E9%80%9A%E7%94%A8%E7%9A%84%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</id>
    <published>2024-07-27T16:00:00.000Z</published>
    <updated>2024-12-18T08:41:10.019Z</updated>
    
    <content type="html"><![CDATA[<h1 id="通用的高并发架构设计"><a href="#通用的高并发架构设计" class="headerlink" title="通用的高并发架构设计"></a>通用的高并发架构设计</h1><p>关键词：读&#x2F;写分离、数据缓存、缓存更新、CQRS、数据分片、异步写</p><p>本文节选自电子工业出版社博文视点刚刚出版的<strong>《亿级流量系统架构设计与实战》</strong>一书。</p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><blockquote><p>链接 <a href="https://mp.weixin.qq.com/s/KcPIR5jB6bJUGpEzcmlAGA">https://mp.weixin.qq.com/s/KcPIR5jB6bJUGpEzcmlAGA</a></p></blockquote><p><strong>高并发架构设计的要点</strong></p><p>高并发意味着系统要应对海量请求。从笔者多年的面试经验来看，很多面试者在面对“什么是高并发架构”的问题时，往往会粗略地认为一个系统的设计是否满足高并发架构，就是看这个系统是否可以应对海量请求。再细问具体的细节时，回答往往显得模棱两可，比如每秒多少个请求才是高并发请求、系统的性能表现如何、系统的可用性表现如何，等等。</p><p>为了可以清晰地评判一个系统的设计是否满足高并发架构，在正式给出通用的高并发架构设计方案前，我们先要厘清形成高并发系统的必要条件、高并发系统的衡量指标和高并发场景分类。</p><h3 id="形成高并发系统的必要条件"><a href="#形成高并发系统的必要条件" class="headerlink" title="形成高并发系统的必要条件"></a><strong>形成高并发系统的必要条件</strong></h3><p><strong>◎高性能：</strong>性能代表一个系统的并行处理能力，在同样的硬件设备条件下，性能越高，越能节约硬件资源；同时性能关乎用户体验，如果系统响应时间过长，用户就会产生抱怨。</p><p><strong>◎高可用性：</strong>系统可以长期稳定、正常地对外提供服务，而不是经常出故障、宕机、崩溃。</p><p><strong>◎可扩展性：</strong>系统可以通过水平扩容的方式，从容应对请求量的日渐递增乃至突发的请求量激增。</p><p>我们可以将形成高并发系统的必要条件类比为一个篮球运动员的各项属性：“高性能”相当于这个球员在赛场上的表现力强，“高可用性”相当于这个球员在赛场上总可以稳定发挥，“可扩展性”相当于这个球员的未来成长性好。</p><p><strong>高并发系统的衡量指标</strong></p><h4 id="1-高性能指标"><a href="#1-高性能指标" class="headerlink" title="1. 高性能指标"></a><strong>1. 高性能指标</strong></h4><p>一个很容易想到的可以体现系统性能的指标是，在一段时间内系统的平均响应时间。例如，在一段时间内有10000个请求被成功响应，那么在这段时间内系统的平均响应时间是这10000个请求响应时间的平均值。</p><p>然而，平均值有明显的硬伤并在很多数据统计场景中为大家所调侃。假设你和传奇篮球巨星姚明被分到同一组，你的身高是174cm，姚明的身高是226cm，那么这组的平均身高是2m！这看起来非常不合理。假设在10000个请求中有9900个请求的响应时间分别是1ms，另外100个请求的响应时间分别是100ms，那么平均响应时间仅为1.99ms，完全掩盖了那100个请求的100ms响应时间的问题。平均值的主要缺点是易受极端值的影响，这里的极端值是指偏大值或偏小值——当出现偏大值时，平均值将会增大；当出现偏小值时，平均值将会减小。</p><p>笔者推荐的系统性能的衡量指标是响应时间PCTn统计方式，PCTn表示请求响 应时间按从小到大排序后第n分位的响应时间。假设在一段时间内100个请求的响应时间从小到大排序如图所示，则第99分位的响应时间是100ms，即PCT99&#x3D; 100ms。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/PW0wIHxgg3kOkTPoPAr4hibU1UzUVsKg2tQruDR4cyliaic6QlVKSvjFMw9bVJlSuywW51hczIaQ3uB1adRXjGOkw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>分位值越大，对响应时间长的请求越敏感。比如统计10000个请求的响应时间：</p><p>◎PCT50&#x3D;1ms，表示在10000个请求中50%的请求响应时间都在1ms以内。</p><p>◎PCT99&#x3D;800ms，表示在10000个请求中99%的请求响应时间都在800ms以内。</p><p>◎PCT999&#x3D;1.2s，表示在10000个请求中99.9%的请求响应时间都在1.2s以内。</p><p>从笔者总结的经验数据来看，请求的平均响应时间&#x3D;200ms，且PCT99&#x3D;1s的高并发系统基本能够满足高性能要求。如果请求的响应时间在200ms以内，那么用户不会感受到延迟；而如果请求的响应时间超过1s，那么用户会明显感受到延迟。</p><h4 id="2-高可用性指标"><a href="#2-高可用性指标" class="headerlink" title="2. 高可用性指标"></a><strong>2. 高可用性指标</strong></h4><p>可用性&#x3D;系统正常运行时间&#x2F;系统总运行时间，表示一个系统正常运行的时间占比，也可以将其理解为一个系统对外可用的概率。我们一般使用N个9来描述系统的可用性如何，如表所示。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/PW0wIHxgg3kOkTPoPAr4hibU1UzUVsKg2stWwyc9UN5PY33xWAkR2w0hRguae7icvIVBUCb3LiaQg2NPgpRRtR58w/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>高可用性要求系统至少保证3个9或4个9的可用性。在实际的系统指标监控中，很多公司会取3个9和4个9的中位数：99.95%（3个9、1个5），作为系统可用性监控的阈值。当监控到系统可用性低于99.95%时及时发出告警信息，以便系统维护者可以及时做出优化，如系统可用性补救、扩容、分析故障原因、系统改造等。</p><h4 id="3-可扩展性指标"><a href="#3-可扩展性指标" class="headerlink" title="3. 可扩展性指标"></a><strong>3. 可扩展性指标</strong></h4><p>面对到来的突发流量，我们明显来不及对系统做架构改造，而更快捷、有效的做法是增加系统集群中的节点来水平扩展系统的服务能力。可扩展性&#x3D;吞吐量提升比例&#x2F;集群节点增加比例。在最理想的情况下，集群节点增加几倍，系统吞吐量就能增加几倍。一般来说，拥有70%～80%可扩展性的系统基本能够满足可扩展性要求。</p><p><strong>高并发场景分类</strong></p><p>我们使用计算机实现各种业务功能，最终将体现在对数据的两种操作上，即读和写，于是高并发请求可以被归类为高并发读和高并发写。比如有的业务场景读多写少，需要重点解决高并发读的问题；有的业务场景写多读少，需要重点解决高并发写的问题；而有的业务场景读多写多，则需要同时解决高并发读和高并发写的问题。将高并发场景划分为高并发读场景和高并发写场景，是因为在这两种场景中往往有不同的高并发解决方案。</p><hr><p><strong>数据库读&#x2F;写分离</strong></p><p>大部分互联网应用都是读多写少的，比如刷帖的请求永远比发帖的请求多，浏览商品的请求永远比下单购买商品的请求多。数据库承受的高并发请求压力，主要来自读请求。我们可以把数据库按照读&#x2F;写请求分成专门负责处理写请求的数据库（写库）和专门负责处理读请求的数据库（读库），让所有的写请求都落到写库，写库将写请求处理后的最新数据同步到读库，所有的读请求都从读库中读取数据。这就是数据库读&#x2F;写分离的思路。</p><p>数据库读&#x2F;写分离使大量的读请求从数据库中分离出来，减少了数据库访问压力，缩短了请求响应时间。</p><p><strong>读&#x2F;写分离架构</strong></p><p>我们通常使用数据库主从复制技术实现读&#x2F;写分离架构，将数据库主节点Master作为“写库”，将数据库从节点Slave作为“读库”，一个Master可以与多个Slave连接，如图所示。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/PW0wIHxgg3kOkTPoPAr4hibU1UzUVsKg2cib2X6fOvlu35U5MGlqZ6oe8eeSWK1G2ZWSyNg2LW74ozZKJKibbIrpQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>市面上各主流数据库都实现了主从复制技术。</p><h3 id="读-x2F-写请求路由方式"><a href="#读-x2F-写请求路由方式" class="headerlink" title="读&#x2F;写请求路由方式"></a><strong>读&#x2F;写请求路由方式</strong></h3><p>在数据库读&#x2F;写分离架构下，把写请求交给Master处理，而把读请求交给Slave处理，那么由什么角色来执行这样的读&#x2F;写请求路由呢？一般可以采用如下两种方式。</p><h4 id="1-基于数据库Proxy代理的方式"><a href="#1-基于数据库Proxy代理的方式" class="headerlink" title="1. 基于数据库Proxy代理的方式"></a><strong>1. 基于数据库Proxy代理的方式</strong></h4><p>在业务服务和数据库服务器之间增加数据库Proxy代理节点（下文简称Proxy），业务服务对数据库的一切操作都需要经过Proxy转发。Proxy收到业务服务的数据库操作请求后，根据请求中的SQL语句进行归类，将属于写操作的请求（如insert&#x2F;delete&#x2F;update语句）转发到数据库Master，将属于读操作的请求（如select语句）转发到数据库任意一个Slave，完成读&#x2F;写分离的路由。开源项目如中心化代理形式的MySQL-Proxy和MyCat，以及本地代理形式的MySQL-Router等都实现了读&#x2F;写分离功能。</p><h4 id="2-基于应用内嵌的方式"><a href="#2-基于应用内嵌的方式" class="headerlink" title="2. 基于应用内嵌的方式"></a><strong>2. 基于应用内嵌的方式</strong></h4><p>基于应用内嵌的方式与基于数据库Proxy代理的方式的主要区别是，它在业务服务进程内进行请求读&#x2F;写分离，数据库连接框架开源项目如gorm、shardingjdbc等都实现了此形式的读&#x2F;写分离功能。</p><h3 id="主从延迟与解决方案"><a href="#主从延迟与解决方案" class="headerlink" title="主从延迟与解决方案"></a><strong>主从延迟与解决方案</strong></h3><p>数据库读&#x2F;写分离架构依赖数据库主从复制技术，而数据库主从复制存在数据复制延迟（主从延迟），因此会导致在数据复制延迟期间主从数据的不一致，Slave获取不到最新数据。针对主从延迟问题有如下三种解决方案。</p><h4 id="1-同步数据复制"><a href="#1-同步数据复制" class="headerlink" title="1. 同步数据复制"></a><strong>1. 同步数据复制</strong></h4><p>数据库主从复制默认是异步模式，Master在写完数据后就返回成功了，而不管Slave是否收到此数据。我们可以将主从复制配置为同步模式，Master在写完数据后，要等到全部Slave都收到此数据后才返回成功。</p><p>这种方案可以保证数据库每次写操作成功后，Master和Slave都能读取到最新数据。这种方案相对简单，将数据库主从复制修改为同步模式即可，无须改造业务服务。</p><p>但是由于在处理业务写请求时，Master要等到全部Slave都收到数据后才能返回成功，写请求的延迟将大大增加，数据库的吞吐量也会有明显的下滑。这种方案的实用价值较低，仅适合在低并发请求的业务场景中使用。</p><h4 id="2-强制读主"><a href="#2-强制读主" class="headerlink" title="2. 强制读主"></a><strong>2. 强制读主</strong></h4><p>不同的业务场景对主从延迟的容忍性不一样。例如，用户a刚刚发布了一条状态，他浏览个人主页时应该展示这条状态，这个场景不太能容忍主从延迟；而好友用户b此时浏览用户a的个人主页时，可以暂时看不到用户a最新发布的状态，这个场景可以容忍主从延迟。我们可以对业务场景按照主从延迟容忍性的高低进行划分，对于主从延迟容忍性高的场景，执行正常的读&#x2F;写分离逻辑；而对于主从延迟容忍性低的场景，强制将读请求路由到数据库Master，即强制读主。</p><h4 id="3-会话分离"><a href="#3-会话分离" class="headerlink" title="3. 会话分离"></a><strong>3. 会话分离</strong></h4><p>比如某会话在数据库中执行了写操作，那么在接下来极短的一段时间内，此会话的读请求暂时被强制路由到数据库Master，与“强制读主”方案中的例子很像，保证每个用户的写操作立刻对自己可见。暂时强制读主的时间可以被设定为略高于数据库完成主从数据复制的延迟时间，尽量使强制读主的时间段覆盖主从数据复制的实际延迟时间。</p><hr><p><strong>本地缓存</strong></p><h3 id="-1"><a href="#-1" class="headerlink" title=""></a></h3><p>在计算机世界中，缓存（Cache）无处不在，如CPU缓存、DNS缓存、浏览器缓存等。值得一提的是，Cache在我国台湾地区被译为“快取”，更直接地体现了它的用途：快速读取。缓存的本质是通过空间换时间的思路来保证数据的快速读取。</p><p>业务服务一般需要通过网络调用向其他服务或数据库发送读数据请求。为了提高数据的读取效率，业务服务进程可以将已经获取到的数据缓存到本地内存中，之后业务服务进程收到相同的数据请求时就可以直接从本地内存中获取数据返回，将网络请求转化为高效的内存存取逻辑。这就是本地缓存的主要用途。在本书后面的核心服务设计篇中会大量应用本地缓存，本节先重点介绍本地缓存的技术原理。</p><p><strong>基本的缓存淘汰策略</strong></p><p>虽然缓存使用空间换时间可以提高数据的读取效率，但是内存资源的珍贵决定了本地缓存不可无限扩张，需要在占用空间和节约时间之间进行权衡。这就要求本地缓存能自动淘汰一些缓存的数据，淘汰策略应该尽量保证淘汰不再被使用的数据，保证有较高的缓存命中率。基本的缓存淘汰策略如下。</p><p><strong>◎FIFO（First In First Out）策略：</strong>优先淘汰最早进入缓存的数据。这是最简单的淘汰策略，可以基于队列实现。但是此策略的缓存命中率较低，越是被频繁访问的数据是越早进入队列的，于是会被越早地淘汰。此策略在实践中很少使用。</p><p><strong>◎LFU（Least Frequently Used）策略：</strong>优先淘汰最不常用的数据。LFU策略会为每条缓存数据维护一个访问计数，数据每被访问一次，其访问计数就加1，访问计数最小的数据是被淘汰的目标。此策略很适合缓存在短时间内会被频繁访问的热点数据，但是最近最新缓存的数据总会被淘汰，而早期访问频率高但最近一直未被访问的数据会长期占用缓存。</p><p><strong>◎LRU（Least Recent Used）策略：</strong>优先淘汰缓存中最近最少使用的数据。此策略一般基于双向链表和哈希表配合实现。双向链表负责存储缓存数据，并总是将最近被访问的数据放置在尾部，使缓存数据在双向链表中按照最近访问时间由远及近排序，每次被淘汰的都是位于双向链表头部的数据。哈希表负责定位数据在双向链表中的位置，以便实现快速数据访问。此策略可以有效提高短期内热点数据的缓存命中率，但如果是偶发性地访问冷数据，或者批量访问数据，则会导致热点数据被淘汰，进而降低缓存命中率。</p><p>LRU策略和LFU策略的缺点是都会导致缓存命中率大幅下降。近年来，业界出现了一些更复杂、效果更好的缓存淘汰策略，比如W-TinyLFU策略。</p><hr><p><strong>分布式缓存</strong></p><h3 id="-2"><a href="#-2" class="headerlink" title=""></a></h3><p>由于本地缓存把数据缓存在服务进程的内存中，不需要网络开销，故而性能非常高。但是把数据缓存到内存中也有较多限制，举例如下。</p><p><strong>◎无法共享：</strong>多个服务进程之间无法共享本地缓存。</p><p><strong>◎编程语言限制：</strong>本地缓存与程序绑定，用Golang语言开发的本地缓存组件不可以直接为用Java语言开发的服务器所使用。</p><p><strong>◎可扩展性差：</strong>由于服务进程携带了数据，因此服务是有状态的。有状态的服务不具备较好的可扩展性。</p><p><strong>◎内存易失性：</strong>服务进程重启，缓存数据全部丢失。</p><p>我们需要一种支持多进程共享、与编程语言无关、可扩展、数据可持久化的缓存，这种缓存就是分布式缓存。</p><h3 id="分布式缓存选型"><a href="#分布式缓存选型" class="headerlink" title="分布式缓存选型"></a><strong>分布式缓存选型</strong></h3><p>主流的分布式缓存开源项目有Memcached和Redis，两者都是优秀的缓存产品，并且都具有缓存数据共享、与编程语言无关的能力。不过，相对于Memcached而言，Redis更为流行，主要体现如下。</p><p><strong>◎数据类型丰富：</strong>Memcached仅支持字符串数据类型缓存，而Redis支持字符串、列表、集合、哈希、有序集合等数据类型缓存。</p><p><strong>◎数据可持久化：</strong>Redis通过RDB机制和AOF机制支持数据持久化，而Memcached没有数据持久化能力。</p><p><strong>◎高可用性：</strong>Redis支持主从复制模式，在服务器遇到故障后，它可以通过主从切换操作保证缓存服务不间断。Redis具有较高的可用性。</p><p><strong>◎分布式能力：</strong>Memcached本身并不支持分布式，因此只能通过客户端，以一致性哈希这样的负载均衡算法来实现基于Memcached的分布式缓存系统。而Redis有官方出品的无中心分布式方案Redis Cluster，业界也有豆瓣Codis和推特Twemproxy的中心化分布式方案。</p><p>由于Redis支持丰富的数据类型和数据持久化，同时拥有高可用性和高可扩展性，因此它成为大部分互联网应用分布式缓存的首选。</p><h3 id="如何使用Redis缓存"><a href="#如何使用Redis缓存" class="headerlink" title="如何使用Redis缓存"></a><strong>如何使用Redis缓存</strong></h3><p>使用Redis缓存的逻辑如下。</p><p>（1）尝试在Redis缓存中查找数据，如果命中缓存，则返回数据。</p><p>（2）如果在Redis缓存中找不到数据，则从数据库中读取数据。</p><p>（3）将从数据库中读取到的数据保存到Redis缓存中，并为此数据设置一个过期时间。</p><p>（4）下次在Redis缓存中查找同样的数据，就会命中缓存。</p><p>将数据保存到Redis缓存时，需要为数据设置一个合适的过期时间，这样做有以下两个好处。</p><p>◎如果没有为缓存数据设置过期时间，那么数据会一直堆积在Redis内存中，尤其是那些不再被访问或者命中率极低的缓存数据，它们一直占据Redis内存会造成大量的资源浪费。设置过期时间可以使Redis自动删除那些不再被访问的缓存数据，而对于经常被访问的缓存数据，每次被访问时都重置过期时间，可以保证<strong>缓存命中率高。</strong></p><p>◎当数据库与Redis缓存由于各种故障出现了数据不一致的情况时，过期时间是一个很好的兜底手段。例如，设置缓存数据的过期时间为10s，那么数据库和Redis缓存即使出现数据不一致的情况，最多也就持续10s。过期时间可以保证数据库和Redis缓存仅在此时间段内有数据不一致的情况，因此可以保证<strong>数据的最终一致性。</strong></p><p>在上述逻辑中，有一个极有可能带来风险的操作：某请求访问的数据在Redis缓存中不存在，此请求会访问数据库读取数据；而如果有大量的请求访问数据库，则可能导致数据库崩溃。Redis缓存中不存在某数据，只可能有两种原因：一是在Redis缓存中从未存储过此数据，二是此数据已经过期。下面我们就这两种原因来做有针对性的优化。</p><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a><strong>缓存穿透</strong></h3><p>当用户试图请求一条连数据库中都不存在的非法数据时，Redis缓存会显得形同虚设。</p><p>（1）尝试在Redis缓存中查找此数据，如果命中，则返回数据。</p><p>（2）如果在Redis缓存中找不到此数据，则从数据库中读取数据。</p><p>（3）如果在数据库中也找不到此数据，则最终向用户返回空数据</p><p>可以看到，Redis缓存完全无法阻挡此类请求直接访问数据库。如果黑客恶意持续发起请求来访问某条不存在的非法数据，那么这些非法请求会全部穿透Redis缓存而直接访问数据库，最终导致数据库崩溃。这种情况被称为“缓存穿透”。</p><p>为了防止出现缓存穿透的情况，当在数据库中也找不到某数据时，可以在Redis缓存中为此数据保存一个空值，用于表示此数据为空。这样一来，之后对此数据的请求均会被Redis缓存拦截，从而阻断非法请求对数据库的骚扰。</p><p>不过，如果黑客访问的不是一条非法数据，而是大量不同的非法数据，那么此方案会使得Redis缓存中存储大量无用的空数据，甚至会逐出较多的合法数据，大大降低了Redis缓存命中率，数据库再次面临风险。我们可以使用布隆过滤器来解决缓存穿透问题。</p><p>布隆过滤器由一个固定长度为m的二进制向量和k个哈希函数组成。当某数据被加入布隆过滤器中后，k个哈希函数为此数据计算出k个哈希值并与m取模，并且在二进制向量对应的N个位置上设置值为1；如果想要查询某数据是否在布隆过滤器中，则可以通过相同的哈希计算后在二进制向量中查看这k个位置值：</p><p>◎如果有任意一个位置值为0，则说明被查询的数据一定不存在；</p><p>◎如果所有的位置值都为1，则说明被查询的数据可能存在。之所以说可能存在，是因为哈希函数免不了会有数据碰撞的可能，在这种情况下会造成对某数据的误判，不过可以通过调整m和k的值来降低误判率。</p><p>虽然布隆过滤器对于“数据存在”有一定的误判，但是对于“数据不存在”的判定是准确的。布隆过滤器很适合用来防止缓存穿透：将数据库中的全部数据加入布隆过滤器中，当用户请求访问某数据但是在Redis缓存中找不到时，检查布隆过滤器中是否记录了此数据。如果布隆过滤器认为数据不存在，则用户请求不再访问数据库；如果布隆过滤器认为数据可能存在，则用户请求继续访问数据库；如果在数据库中找不到此数据，则在Redis缓存中设置空值。虽然布隆过滤器对“数据存在”有一定的误判，但是误判率较低。最后在Redis缓存中设置的空值也很少，不会影响Redis缓存命中率。</p><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a><strong>缓存雪崩</strong></h3><p>如果在同一时间Redis缓存中的数据大面积过期，则会导致请求全部涌向数据库。这种情况被称为“缓存雪崩”。缓存雪崩与缓存穿透的区别是，前者是很多缓存数据不存在造成的，后者是一条缓存数据不存在导致的。</p><p>缓存雪崩一般有两种诱因：大量数据有相同的过期时间，或者Redis服务宕机。第一种诱因的解决方案比较简单，可以在为缓存数据设置过期时间时，让过期时间的值在预设的小范围内随机分布，避免大部分缓存数据有相同的过期时间。第二种诱因取决于Redis的可用性，选取高可用的Redis集群架构可以极大地降低Redis服务宕机的概率。</p><hr><p><strong>高并发读场景总结：CQRS</strong></p><p>无论是数据库读&#x2F;写分离、本地缓存还是分布式缓存，其本质上都是读&#x2F;写分离，这也是在微服务架构中经常被提及的CQRS模式。CQRS（Command Query Responsibility Segregation，命令查询职责分离）是一种将数据的读取操作与更新操作分离的模式。query指的是读取操作，而command是对会引起数据变化的操作的总称，新增、删除、修改这些操作都是命令。</p><h3 id="CQRS的简要架构与实现"><a href="#CQRS的简要架构与实现" class="headerlink" title="CQRS的简要架构与实现"></a><strong>CQRS的简要架构与实现</strong></h3><h3 id="为了避免引入微服务领域驱动设计的相关概念，下图给出了CQRS的简要架构。"><a href="#为了避免引入微服务领域驱动设计的相关概念，下图给出了CQRS的简要架构。" class="headerlink" title="为了避免引入微服务领域驱动设计的相关概念，下图给出了CQRS的简要架构。"></a>为了避免引入微服务领域驱动设计的相关概念，下图给出了CQRS的简要架构。</h3><p><img src="https://mmbiz.qpic.cn/mmbiz_png/PW0wIHxgg3kOkTPoPAr4hibU1UzUVsKg2dladKjFx9dFgJp2LmqE1PCo9zvMgPftvkAtO4WRibadn6ntClbtxibjQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>（1）当业务服务收到客户端发起的command请求（即写请求）时，会将此请求交给写数据存储来处理。</p><p>（2）写数据存储完成数据变更后，将数据变更消息发送到消息队列。</p><p>（3）读数据存储负责监听消息队列，当它收到数据变更消息后，将数据写入自身。</p><p>（4）当业务服务收到客户端发起的query请求（即读请求）时，将此请求交给读数据存储来处理。</p><p>（5）读数据存储将此请求希望访问的数据返回。</p><p>写数据存储、读数据存储、数据传输通道均是较为宽泛的代称，其中写数据存储和读数据存储在不同的高并发场景下有不同的具体指代，数据传输通道在不同的高并发场景下有不同的形式体现，可能是消息队列、定时任务等。</p><p>◎对于数据库读&#x2F;写分离来说，写数据存储是 Master，读数据存储是 Slave，消息队列的实现形式是数据库主从复制。</p><p>◎对于分布式缓存场景来说，写数据存储是数据库，读数据存储是 Redis 缓存，消息队列的实现形式是使用消息中间件监听数据库的binlog数据变更日志。</p><p>无论是何种场景，都应该为写数据存储选择适合高并发写入的存储系统，为读数据存储选择适合高并发读取的存储系统，消息队列作为数据传输通道要足够健壮，保证数据不丢失。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;通用的高并发架构设计&quot;&gt;&lt;a href=&quot;#通用的高并发架构设计&quot; class=&quot;headerlink&quot; title=&quot;通用的高并发架构设计&quot;&gt;&lt;/a&gt;通用的高并发架构设计&lt;/h1&gt;&lt;p&gt;关键词：读&amp;#x2F;写分离、数据缓存、缓存更新、CQRS、数据分片、异步写</summary>
      
    
    
    
    <category term="技术小栈" scheme="http://ai.mak.cn/categories/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/"/>
    
    
    <category term="架构" scheme="http://ai.mak.cn/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>conda、pip、anaconda、miniconda、miniforge、mambaforge 区分</title>
    <link href="http://ai.mak.cn/2024/07/14/python/conda%E3%80%81pip%E3%80%81anaconda%E3%80%81miniconda%E3%80%81miniforge%E3%80%81mambaforge%20%E5%8C%BA%E5%88%86/"/>
    <id>http://ai.mak.cn/2024/07/14/python/conda%E3%80%81pip%E3%80%81anaconda%E3%80%81miniconda%E3%80%81miniforge%E3%80%81mambaforge%20%E5%8C%BA%E5%88%86/</id>
    <published>2024-07-13T16:00:00.000Z</published>
    <updated>2024-12-18T08:21:52.462Z</updated>
    
    <content type="html"><![CDATA[<h1 id="conda、pip、anaconda、miniconda、miniforge、mambaforge-区分"><a href="#conda、pip、anaconda、miniconda、miniforge、mambaforge-区分" class="headerlink" title="conda、pip、anaconda、miniconda、miniforge、mambaforge 区分"></a>conda、pip、anaconda、miniconda、miniforge、mambaforge 区分</h1><p><strong>核心属性和本质：</strong></p><ul><li><strong>conda</strong> 和 <strong>pip</strong> 的本质是包管理工具，它们帮助用户管理和安装软件包。</li><li><strong>anaconda</strong>、<strong>miniconda</strong>、<strong>miniforge</strong> 和 <strong>mambaforge</strong> 的本质是环境管理工具，它们提供了一套完整的工具来管理编程环境。</li></ul><p><strong>来个比较容易理解的比喻</strong>：<br> 在一个巨大的图书馆里，有各种各样的书，你想去借书看。这个图书馆就像是一个编程语言的世界，而书籍就是各种各样的代码库和工具。<br> <strong>conda</strong> 是一个聪明的图书管理员，它不仅能帮你找到书，还能告诉你哪些书是相互关联的，确保你借的每本书都能很好地一起工作。它不仅管理Python的书籍，还管理其他语言的书籍。<br> 解释：一个开源的包管理系统和环境管理系统，可以用来安装、运行和升级包和它们的依赖关系。它支持多种语言。</p><p><strong>pip</strong> 是另一个图书管理员，但它专注于Python的书籍。它很擅长找到你想要的Python书籍，但有时候它不太关心这些书是否能很好地相互协作。<br> 解释：是Python的默认包管理工具，专为python打造，用于安装和管理Python库。</p><p><strong>anaconda</strong> 是一个巨大的书架，上面预先放好了很多最常用的书籍，这样你就不用每次都去找图书管理员了。它特别适合那些不想花太多时间挑选书籍的人。<br> 解释：是一个发行版，由Anaconda公司开发，里面除了conda，还包含了Python以及许多科学计算相关的包。</p><p><strong>miniconda</strong> 是一个更小的书架，上面只有几本你开始阅读时必须的书籍。如果你需要更多的书，你可以去找conda图书管理员帮你。<br> 解释：是anaconda的一个轻量级版本，只包含conda和其依赖项，没有预装其他任何包。Miniconda的优势在于它的体积较小，安装过程更快，用户可以根据需要自行选择和安装所需的包。</p><p><strong>miniforge</strong> 和 <strong>mambaforge</strong> 是类似于miniconda的两个不同品牌的小书架，但它们来自不同的制造商。它们提供了一些不同的特性，比如更快的书籍检索速度（mambaforge）或者更多地支持开源书籍（miniforge）。<br> 解释：miniforge是一个社区驱动的miniconda替代品，与Miniconda相比，提供了更多的编译器和开发工具，适用于更复杂的环境和依赖关系。社区持续在维护和更新，所以一般用这个就足够了。<br> mambaforge脱胎于Miniforge，做了一些优化，以更高的效率实现了和conda 同样的功能，对conda中低效的部分进行了重写。不过从 23 年 9 月份开始，Mambaforge 已经不鼓励使用了，可以放弃。</p><p>mambaforge的官方申明：</p><blockquote><p>Mambaforge（Discouraged as of September 2023）<br> With the <a href="https://link.juejin.cn/?target=https://link.zhihu.com/?target=https://github.com/conda-forge/miniforge/releases/tag/23.3.1-0">release</a> of Miniforge3-23.3.1-0, that incorporated the changes in <a href="https://link.juejin.cn/?target=https://link.zhihu.com/?target=https://github.com/conda-forge/miniforge/pull/277">#277</a>, the packages and configuration of Mambaforge and Miniforge3 are now <strong>identical</strong>. The only difference between the two is the name of the installer and, subsequently, the default installation directory. Given its wide usage, there are no plans to deprecate Mambaforge. If at some point we decide to deprecate Mambaforge, it will be appropriately announced and communicated with sufficient time in advance.<br> As of September 2023, the new usage of Mambaforge is thus discouraged. Bug reports specific to Mambaforge will be closed as won’t fix.</p></blockquote><p>意思就是，Miniforge已经把 Mambaforge 的功能给合并过来了，虽然目前Mambaforge还能用，不过不推荐，随时可能弃用，而且里面的 bug 也不会修了。</p><p>总结一下，绝大部分用户使用Miniforge 即可，常用做法是，conda 命令创建虚拟环境，conda install 安装 torch 包，剩下的包交给 pip 来搞定，兼具安全和高效。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;conda、pip、anaconda、miniconda、miniforge、mambaforge-区分&quot;&gt;&lt;a href=&quot;#conda、pip、anaconda、miniconda、miniforge、mambaforge-区分&quot; class=&quot;headerl</summary>
      
    
    
    
    <category term="技术小栈" scheme="http://ai.mak.cn/categories/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/"/>
    
    
    <category term="python" scheme="http://ai.mak.cn/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>怎样读书，才算对得起自己？</title>
    <link href="http://ai.mak.cn/2024/07/07/%E6%9D%82%E8%AE%B0/%E6%80%8E%E6%A0%B7%E8%AF%BB%E4%B9%A6%EF%BC%8C%E6%89%8D%E7%AE%97%E5%AF%B9%E5%BE%97%E8%B5%B7%E8%87%AA%E5%B7%B1%EF%BC%9F/"/>
    <id>http://ai.mak.cn/2024/07/07/%E6%9D%82%E8%AE%B0/%E6%80%8E%E6%A0%B7%E8%AF%BB%E4%B9%A6%EF%BC%8C%E6%89%8D%E7%AE%97%E5%AF%B9%E5%BE%97%E8%B5%B7%E8%87%AA%E5%B7%B1%EF%BC%9F/</id>
    <published>2024-07-06T16:00:00.000Z</published>
    <updated>2024-12-18T08:12:41.179Z</updated>
    
    <content type="html"><![CDATA[<p>怎样读书，才算对得起自己？</p><blockquote><p>节选自：得到头条 | 360期</p></blockquote><p>今天，我将从两个话题出发，为你提供知识服务。第一个是，423世界读书日特刊。第二个是，法国巴黎恢复服务员赛跑。</p><p>先来看今天的第一条。今天是4月23日，世界读书日，也是咱们得到的破万卷节。你大概率上能看到好多人在谈论读书的方法，或者推荐这一年的重磅书。这些信息都很有价值，建议你有空去看看。</p><p>回到今天的节目，咱们换个角度，把姿态放轻松点，权当是同学之间互相交流。我想跟你说说，我昨天早上一个小时，在得到电子书随意刷书，获得的收获。没错，就是早上一个小时，在得到电子书的新书榜上随手翻翻。</p><p>有人可能会问，只是随手翻翻，能有多大的收获？你别说，收获还不少。接下来就跟你汇报一下我这一个小时乱翻书的收获。主要也是想跟你交流一下，乱翻书，快刷书，是不是也算一件很有趣的事？</p><p>好，咱们正式开始。这一个小时，我主要有三个收获。</p><p>第一，是安顿感。也就是，以前某些觉得很沉重的事，突然变得轻松了。</p><p>比如，昨天，得到电子书的新书榜上，有本书排名很靠前，复旦大学的经济学者，梁捷老师写的《表层的真理》。这是一本普通人了解经济学的入门书。刚翻开前言部分，就看到一个好玩的故事。</p><p>说的是，曾经有经济学家专门研究非洲的足球比赛。他们主要想搞清楚，踢足球，是怎么影响非洲人的国家认同的。我们都知道，非洲的很多国家是由部落组成的。尽管这些国家已经建成几十年，但很多人对国家其实没什么认同感，他们始终觉得，自己是某个部落的人。这也导致，很多国家内部，经常发生部落冲突，死伤惨重。</p><p>那么，<strong>怎么让大家建立国家认同呢？几位经济学家就去调查数据。结果发现，足球是个特别关键的因素。</strong> 在足球比赛之前你问当地人，说你觉得自己是某个国家的人，还是某个部落的人？他们大概率会回答，我是部落的人。但是，在足球比赛结束你再去问，会有很多人改变想法，觉得自己是某个国家的人。尤其这个国家的足球队取得胜利，会有37%的人改变想法，从部落认同转变为国家认同。有资格参加非洲杯的国家，他们的国内冲突，要比没有资格参加非洲杯的国家，少9%。</p><p>这个感觉就好比，一个公司里，就算AB两个部门矛盾再深，一旦整个公司派出球队，跟别的公司比赛，这两个部门的关系也会好转很多。说白了，想团结团队，就去组织足球赛。</p><p>但是，这个故事，还不是这本《表层的真理》的核心。作者是想通过这个故事跟你说，你看，这就是现在的经济学家们正在研究的事。艰深吗？枯燥吗？并没有。因此，别对经济学犯怵。</p><p>你看，到这一步，我就有了两个选择。我可以接着读这本书，看更多有趣的故事。我也可以顺手就把这个故事转发给身边刚毕业的朋友，然后跟他说，学点经济学吧，你看，经济学多好玩啊。总之，读这本书的短短几分钟，肯定不亏，对得起自己。</p><p>第二个收获是，重逢。也就是，<strong>很多自己经历过的事，你读书时会发现，原来作者也有一模一样的经历，就像在大街上突然遇见多年不见的朋友</strong>。</p><p>比如，在新书榜上，有本书叫《吃着吃着就老了》，作者是著名的纪录片导演，也是《风味人间》的总导演陈晓卿老师。里面主要说的是他自己这些年的跟吃有关的回忆。书里面有几段说的是他工作时，单位附近的餐馆。</p><p>为什么说惊喜？因为我过去跟陈晓卿老师，就在同一栋大楼里办公。尽管没见过面，但他讲的餐馆，我正好都吃过。这个时候你再看书里的内容，就多了一层微妙的感受。</p><p>比如，说到单位楼下新开的连锁饼店，陈晓卿老师说，馅饼还行，但老板胆子大，还做老友粉，味道不好评价。但对我来说，我第一次吃老友粉这个东西，就在这家店。要不是后来去南宁吃到正宗的，我还一直觉得老友粉就是楼下饼店的样子。</p><p>再比如，说到北京的基辅罗斯，是家俄罗斯餐厅。也熟悉，我去那参加过朋友的婚礼，里面有俄罗斯人唱歌表演。顺着玉渊潭公园南门一路往西走就是。假如是晚上一个人走，还有点打怵。这条路总给人种灯下黑的感觉。</p><p>你看，作者讲的是他的回忆。但读者从中读到的，可能是自己经历过的事。</p><p>你看，到这里，我又有两个选择。继续读，能读到更多的故事。但就此打住也行，就像好久不见的朋友重逢。即使只是畅聊几句，也觉得很尽兴。这个感觉是不是很奇妙？</p><p>第三个收获是，不同。也就是，<strong>能看到很多不同的观点。这些观点你未必同意，但是，你会因为知道它而感到有趣。会觉得原来某件事，还可以从这个角度去思考</strong>。</p><p>比如，得到电子书有本最近上线的新书，叫《百岁生活》。作者是一位日本的精神科医生，叫和田秀树。书很薄，只有5万多字。看的人也不多。但是翻开之后，还是能发现一点不一样的东西。</p><p>比如，这本书里一直强调一个概念，叫幸龄。作者一直说，假如一个人能活到80岁以上，这就是幸运，就别想着整天去治病了。因为这会儿身体很多机能在衰退，有可能会因为治了这个毛病，导致其他的问题。这时假如身体出毛病，目标就不是根治，轻易也别做手术，而是想办法让自己能尽可能舒服地活着。这位和田秀树还举了很多日本的数据。比如有的地方因为特殊原因，医院停运了一段时间。结果这段时间离世的80岁以上老人，反而减少了等等。</p><p>这个观点一定对吗？未必。估计很多人也不会同意。但是，这本书至少给了我们一个提醒，就是在面对疾病时，系统的健康观很重要。不能只思考某个局部，而是要尽量全面地考虑自己的健康状况。</p><p>你看，读到这，我又有两个选择。一是继续读下去，看看这位作者还说了什么。二是带着这个提醒，转身就走，去读别的书。总之，至少读这本书的几分钟不白费，对得起自己。</p><p>好，关于昨天早上的刷书收获，咱们先说到这。注意，我们可不是想说，一定要按照某种方法读书。而是想告诉你，<strong>随手乱翻书，其实是一件很好玩，也很有收获的事。假如你现在有类似的感受，别犹豫，也来试试</strong>。同时，423前后，也是咱们得到的破万卷节。得到电子书有优惠活动，优惠力度很大，趁现在别错过。</p><p>再来看今天的第二条。前段时间，法国巴黎恢复了一项奇怪的体育比赛，服务员赛跑。也就是，穿着制服的男女服务员，手托餐盘，餐盘里放一个羊角面包、一个空咖啡杯和一杯水，从巴黎市政厅出发，沿环线跑完2公里赛程。</p><p>这本来是巴黎的传统活动，有100多年的历史。但最近13年一直停办，直到今年，又恢复了举办。</p><p>一方面，是在为夏天的巴黎奥运会造势，另一方面，这个比赛也有强烈的代表意义。咖啡馆是巴黎的标志之一。巴黎市市长伊达尔戈说，大大小小的咖啡馆是“巴黎的灵魂”。比如最著名的花神咖啡馆，15世纪就开业了。据说海明威在这里写了《太阳照常升起》。毕加索在这里的玻璃上作过画。萨特和波伏瓦也每天在这里畅谈，1943年萨特在这里写完了代表作《存在与虚无》。</p><p>其实，直到今天，在咖啡馆写作也特别流行。比如，奥斯卡最佳影片《寄生虫》的导演和编剧奉俊昊，就特别喜欢在咖啡馆写作，而且他会找一个角落，特意背对人群，这样，既能享受咖啡馆的环境，又能让自己专注于手头的任务。</p><p>顺着这个话题，咱们就来说说，一个写作者，怎么写才能写得更快更多？前段时间，美国专栏作家托德·布里森专门写文章做了分享，他给很多美国大媒体供过稿，还每天给读者写一份电子报，算是很高产了。假如你也是一名创作者，尤其是持续创作者，接下来的这三个技巧，你可以做个参考。</p><p><strong>第一个技巧是，给自己设定限制</strong>。说得具体点，就是把电脑电源拔掉。</p><p>这是布里森从一次咖啡馆写作中得来的。他去咖啡店写稿，原本计划集中精力写4小时。但是坐下之后他发现忘了带电源，剩余电量只够写一个多小时。于是，他集中注意力，用一个小时就写完了稿子。这篇稿子，最后成了他2020年最受欢迎的一篇文章。</p><p>你看， 有时候拥有无限的保障，可能反而会模糊你的注意力。因此有时候，需要把自己放在一个没有兜底的环境里。有了这个限制之后，没准反而会提高效率。</p><p><strong>第二个技巧是，不要永远只盯着一篇稿子，你可以尝试同时面对三篇，每20分钟切换一次</strong>。</p><p>布里森说，这个技巧来自奥斯卡得主，《乔乔兔》的编剧塔伊加·维迪提。维迪提完成这部剧本，用了六年时间，听起来很久，但这六年里，他还同时完成了很多其他剧本。方法就是，不同项目同时开展，经常切换。具体到每天的写作上，你可以设置一个20分钟的闹钟，同时写三篇稿子，每20分钟切换一次。当你切回第一个项目的时候，过去了40分钟，这个时间，不至于让你忘了之前的内容，也能让你产生一些新的想法。</p><p><strong>第三个技巧比较细节，跟打字这个动作有关，说的是，眼睛不要看屏幕，手里不要停，一口气把自己的想法打下来</strong>。</p><p>眼睛不看屏幕，是因为，盯着屏幕上的单词，会过多占用你的注意力，有时候你看着自己写的东西，纠结一个用词或者一个句子，速度就会被大大拖慢。布里森建议，确定好光标的位置，然后开始打字，尽可能少看屏幕。假如你用台式机写作，可以把显示器关掉，假如你用笔记本写作，就把屏幕压低。</p><p>写错了也无所谓，关键是，快速把你大脑里的句子写下来，等写完了之后再统一检查。布里森认为，要把写初稿当成一场冲刺，而不是马拉松，一鼓作气地写完，比什么都重要。</p><p>在这里，引用美国科幻作家雷·布拉德伯里的一句话，他一生写了超过500部作品，最有名的一句口号就是，你的直觉知道该写什么，因此别阻挡它。</p><p>最后，总结一下，今天说了两个话题。</p><p>第一，关于怎样阅读？读书不只是为了对书负责，更是为了对人负责，对自己负责。乱翻书，快刷书，往往能获得意外之喜。</p><p>第二，关于怎样书写？关键在于，不让书写这个动作干扰思考。就像刚才说的，你的直觉知道应该写什么，因此别阻挡它。</p><p>这两个话题，一个是关于阅读，一个是关于书写。顺着这两个话题，最后还有个特别分享。前不久，脱不花老师给我推荐了一首诗，说很适合在423这天读一读。这首诗的来历很特别。今年10月，NASA准备往木卫二发射一颗探测器，木卫二也叫欧罗巴，因此这枚探测器就叫欧罗巴快船。有趣的是，这回NASA请桂冠诗人阿达·利蒙专门给木卫二写了一首诗，刻在了欧罗巴快船上，诗的名字叫《赞美神秘》。</p><p>你看，这个事是不是也反映了一个真相。这就是，<strong>哪怕在宇宙深处，只要有人类在，那么有两件事就会始终存在，这就是，阅读与书写</strong>。</p><p>下面是这首诗的全文，我使用的是网络上Tina与大鸣两位老师翻译的版本，翻译得很精彩。</p><blockquote><p>色深邃，如浓墨写意天空。仰望熟悉的满天星斗，脱口而出我们的祈愿。从地球了解太空，仿佛阅读一本关于宇宙的书，准确无误，专业易懂。然而，苍穹之下，仍有未解之谜。鲸鱼的歌声，风中摇动的树枝上，鸣鸟的对歌吟唱。我们是心怀敬畏的生灵，好奇于一切美好、叶子和花开，悲伤和快乐，阳光和阴影。使我们联系在一起的不是黑暗，也不是遥远冰冷的空间，而是水的馈赠。每一滴雨水。每一条小溪，像似每根血管，和每一次的脉搏。木卫二，我们恰巧也由水而生。源自于浩瀚而瞩目的海洋。我们的构成也充满奇迹，有着伟大而平凡的爱，有着小而未知的世界。更有穿越黑暗，探究宇宙的呼唤。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;怎样读书，才算对得起自己？&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;节选自：得到头条 | 360期&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天，我将从两个话题出发，为你提供知识服务。第一个是，423世界读书日特刊。第二个是，法国巴黎恢复服务员赛跑。&lt;/p&gt;
&lt;p&gt;先来看</summary>
      
    
    
    
    <category term="杂记" scheme="http://ai.mak.cn/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
    <category term="杂记" scheme="http://ai.mak.cn/tags/%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>针对不同层次进行性能测试的监控</title>
    <link href="http://ai.mak.cn/2024/07/06/%E6%B5%8B%E8%AF%95/%E9%92%88%E5%AF%B9%E4%B8%8D%E5%90%8C%E5%B1%82%E6%AC%A1%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E7%9A%84%E7%9B%91%E6%8E%A7/"/>
    <id>http://ai.mak.cn/2024/07/06/%E6%B5%8B%E8%AF%95/%E9%92%88%E5%AF%B9%E4%B8%8D%E5%90%8C%E5%B1%82%E6%AC%A1%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E7%9A%84%E7%9B%91%E6%8E%A7/</id>
    <published>2024-07-05T16:00:00.000Z</published>
    <updated>2024-12-18T07:58:02.740Z</updated>
    
    <content type="html"><![CDATA[<h1 id="针对不同层次进行性能测试的监控"><a href="#针对不同层次进行性能测试的监控" class="headerlink" title="针对不同层次进行性能测试的监控"></a>针对不同层次进行性能测试的监控</h1><p>在执行性能测试的过程中，监控服务端的资源消耗等也是必备内容，监控的结果是帮助测试发现问题的眼睛。然而在实操过程中大家喜欢用JMeter 工具提供的插件进行监控，但是并不推荐使用这种方式，原因如下：</p><ul><li>指标相对简单且固定，结果数据粗糙且界面显示并不是很友好；</li><li>较大地增加了客户端压测机的资源开销，影响性能测试结果；</li><li>特定环境下，在服务器上安装插件是不被允许的，会很不方便。</li></ul><p>所以在这里，我们先来聊一下监控要点；</p><h1 id="一、层次清晰"><a href="#一、层次清晰" class="headerlink" title="一、层次清晰"></a><strong>一、层次清晰</strong></h1><p>从执行一次性能测试来看，需要监控的内容有很多，重点是要能理清楚不同的监控类型，以及分别能够解决什么问题？</p><h2 id="1、硬件层"><a href="#1、硬件层" class="headerlink" title="1、硬件层"></a><strong>1、硬件层</strong></h2><p>硬件层是最容易想到的一个层面，一般包含了 <strong>CPU 的使用率</strong>、<strong>内存使用率</strong>、<strong>磁盘</strong>和<strong>网络读写速度</strong>等，通过这些指标能够反馈出系统运行的基本情况，以及不同的 TPS 量级会消耗多少硬件资源。</p><h2 id="2、系统层"><a href="#2、系统层" class="headerlink" title="2、系统层"></a><strong>2、系统层</strong></h2><p><strong>系统层监控</strong>包括<strong>连接请求数</strong>、<strong>拒绝数</strong>、<strong>丢包率</strong>、<strong>请求超时</strong>等，相对于基础的硬件监控而言，<strong>这些指标更能够反映出目前系统存在的瓶颈</strong>，从而为根因问题的定位提供有力的线索。</p><h2 id="3、链路层"><a href="#3、链路层" class="headerlink" title="3、链路层"></a><strong>3、链路层</strong></h2><p><strong>链路层是直接面向架构和代码的</strong>，它的监控能够帮助我们更加准确地看到<strong>代码执行了哪些函数</strong>，<strong>涉及哪些服务</strong>，并且能够较为清晰地<strong>看到函数之间的调用耗时</strong>，还可以帮助<strong>定位代码存在的问题</strong>。</p><h2 id="4、业务层"><a href="#4、业务层" class="headerlink" title="4、业务层"></a><strong>4、业务层</strong></h2><p><strong>业务层监控本意是帮助判断用户输入是否合规，代码逻辑是否健壮</strong>。对于性能测试而言，业务层的监控可以帮助我们发现脚本参数问题以及高并发下业务逻辑运行是否正常等，比如随着测试的进行，可能会存在商品库存不足的情况。如果有业务层面的监控，当库存低于某阈值时，可以进行一定的提示以规避此类问题。</p><h1 id="二、定向深入"><a href="#二、定向深入" class="headerlink" title="二、定向深入"></a><strong>二、定向深入</strong></h1><p>首先我们通过基本的监控可以获得一些异常点，比如 CPU 高了、磁盘在等待，这些说白了是表象问题。就比如说某位同事今天没来，通过没来这个现象并不能直接下定论说他生病了。对于监控也是这样，是否有定位根因问题的手段，CPU 高了，需不需要进行线程分析，需要哪些权限和定位工具，这些在监控部署时都需要考虑到。</p><h2 id="1、CPU"><a href="#1、CPU" class="headerlink" title="1、CPU"></a><strong>1、CPU</strong></h2><p>top 是我们查看各个进程的资源占用状况最常用的命令，如下代码所示，这个命令简单却包含很大的信息量。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">top - 18:17:47 up 158 days,  9:32,  2 users,</span><br><span class="line"></span><br><span class="line">load average: 0.07, 0.15, 0.21</span><br><span class="line"></span><br><span class="line">Tasks: 154 total,   1 running, 152 sleeping,   0 stopped,   1 zombie</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">%</span><span class="language-bash">Cpu(s):  3.9 us,  1.3 sy,  0.0 ni, 94.6 <span class="built_in">id</span>,  0.2 wa,  0.0 hi,  0.0 si,  0.0 st</span></span><br><span class="line"></span><br><span class="line">KiB Mem :  8010676 total,   337308 free,  6036100 used,  1637268 buff/cache</span><br><span class="line"></span><br><span class="line">KiB Swap:        0 total,        0 free,        0 used.  1223072 avail Mem</span><br></pre></td></tr></table></figure><p>从以上的信息中，我们来介绍几个常用的重点指标</p><h3 id="（1）load-average"><a href="#（1）load-average" class="headerlink" title="（1）load average"></a><strong>（1）load average</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load average: 0.07, 0.15, 0.21</span><br></pre></td></tr></table></figure><p>三个数字都是代表进程队列的长度，从左到右分别表示一分钟、 五分钟和十五分钟的数据，数字越小压力值就越低，数字越大则压力越高，然而这个数值多小算小呢？多大算大呢？以单核处理器为例，打个比方就像收费站的一个 ETC 通道一样：</p><ul><li><strong>0</strong> 表示没有任何车辆需要通过；</li><li>从 <strong>0 到 1</strong> 可以认为很流畅，车辆不需要任何等待就可以通过；</li><li><strong>1</strong> 表示正好在这个通道可接受范围之内；</li><li><strong>超过 1</strong> 就已经有车辆在后面排队了。</li></ul><p>所以理想情况下，希望平均负载值在 1 以下。如果是 1 就代表目前没有可用资源了。在实际情况中，很多运维会把理想负载设置在 0.7 以下，这也是业内的一个“<strong>经验值</strong>”。</p><p>上面说的是一个单核处理器的情况，多核 CPU 的话，负载数值 &#x2F; CPU 核数在 0.00~1.00 之间表示正常，理想值也是在 0.7 以内。</p><h3 id="（2）CPU状态"><a href="#（2）CPU状态" class="headerlink" title="（2）CPU状态"></a><strong>（2）CPU状态</strong></h3><p>从 top 中你也可以看到每种类型进程消耗的 CPU 时间百分比，如下所示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">%</span><span class="language-bash">Cpu(s):  3.9 us,  1.3 sy,  0.0 ni, 94.6 <span class="built_in">id</span>,  0.2 wa,  0.0 hi,  0.0 si,  0.0 st</span></span><br></pre></td></tr></table></figure><ul><li><strong>us</strong> 列显示了用户进程所花费 CPU 时间的百分比。这个数值越高，说明用户进程消耗的 CPU 时间越多，可以用来分析代码中的 CPU 消耗热点。</li><li><strong>sy</strong> 列表示系统进程消耗的 CPU 时间百分比。</li><li><strong>ni</strong> 列表示改变优先级的进程占用 CPU 的百分比。</li><li><strong>id</strong> 列表示 CPU 处于空闲状态的时间百分比。</li><li><strong>wa</strong> 列显示了 I&#x2F;O 等待所占用的 CPU 时间的百分比，这里 wa 的参考值为 0.5，如果长期高于这个参考值，需要注意是否存在磁盘瓶颈。</li><li><strong>hi</strong> 列表示硬件中断占用 CPU 时间百分比。</li><li><strong>si</strong> 列表示软件中断占用 CPU 时间百分比。</li><li><strong>st</strong> 列表示当系统运行在虚拟机中时，当前虚拟机在等待 CPU 为它服务的时间；</li></ul><p>在已经输入 top 的情况下再输入数字 1，可以查看 CPU 的核数和每个核的运行状态。如下图是两核 CPU 的运行状态。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">%</span><span class="language-bash">Cpu0  :  3.0 us,  1.7 sy,  0.0 ni, 95.3 <span class="built_in">id</span>,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">%</span><span class="language-bash">Cpu1  :  2.4 us,  1.0 sy,  0.0 ni, 96.6 <span class="built_in">id</span>,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span></span><br></pre></td></tr></table></figure><h2 id="2、内存"><a href="#2、内存" class="headerlink" title="2、内存"></a><strong>2、内存</strong></h2><p>最常见的是通过 free 来查看 Linux 内存使用情况。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@JD ~]# free -m</span><br><span class="line"></span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line"></span><br><span class="line">Mem:           7822        5917         302         373        1602        1195</span><br><span class="line"></span><br><span class="line">Swap:             0           0           0</span><br></pre></td></tr></table></figure><p>通过单词的意思我们也能大概看出来 total、used、free 表示什么，它们分别是总的<strong>物理内存大小、已经被使用的物理内存和空闲的物理内存值</strong>是多少。</p><h2 id="3、磁盘"><a href="#3、磁盘" class="headerlink" title="3、磁盘"></a><strong>3、磁盘</strong></h2><h3 id="（1）iostat"><a href="#（1）iostat" class="headerlink" title="（1）iostat"></a><strong>（1）iostat</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> [root@JD ~]# iostat -x</span><br><span class="line"></span><br><span class="line">Linux 3.10.0-514.el7.x86_64 (JD)        01/18/2021      _x86_64_        (2 CPU)</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line"></span><br><span class="line">           5.24    0.00    1.57    0.07    0.00   93.12</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line"></span><br><span class="line">vda               0.00     0.29    0.57    5.30    20.50   630.14   221.82     0.07   11.53   59.83    6.36   1.18   0.69</span><br></pre></td></tr></table></figure><p>通过这个命令你能看到磁盘实时运行的情况，一般可以优先看 idle、util 和 svctm 这几列的数值：</p><ul><li><strong>idle</strong> 代表磁盘空闲百分比；</li><li><strong>util</strong> 接近 100%，表示磁盘产生的 I&#x2F;O 请求太多，I&#x2F;O 系统已经满负荷在工作，该磁盘可能存在瓶颈；</li><li><strong>svctm</strong> 代表平均每次设备 I&#x2F;O 操作的服务时间 (毫秒)。</li></ul><h3 id="（2）iotop"><a href="#（2）iotop" class="headerlink" title="（2）iotop"></a><strong>（2）iotop</strong></h3><p>iotop 这个命令并不是 linux 原生的，需要安装，以 CentOS 7.0 为例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@JD ~]# yum -y install iotop</span><br></pre></td></tr></table></figure><p>安装完成之后，直接输入 iotop，示意如下，就能清楚地看到哪些进程在消耗磁盘资源。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">6448 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % ifrit-agent</span><br><span class="line"></span><br><span class="line">14647 be/4 root        0.00 B/s    7.70 K/s  0.00 %  0.00 % java -Dserver.port=9080</span><br></pre></td></tr></table></figure><h2 id="4、网络"><a href="#4、网络" class="headerlink" title="4、网络"></a><strong>4、网络</strong></h2><h3 id="（1）netstat"><a href="#（1）netstat" class="headerlink" title="（1）netstat"></a><strong>（1）netstat</strong></h3><p>netstat 能提供 TCP 和 UDP 的连接状态等统计信息，可以简单判断网络是否存在堵塞。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@JD ~]# netstat</span><br><span class="line"></span><br><span class="line">Active Internet connections (w/o servers)</span><br><span class="line"></span><br><span class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State</span><br><span class="line"></span><br><span class="line">tcp        0      1 JD:49190                169.254.169.250:http    FIN_WAIT1</span><br><span class="line"></span><br><span class="line">tcp        0      0 JD:39444                169.254.169.254:http    TIME_WAIT</span><br><span class="line"></span><br><span class="line">tcp        0      0 JD:us-srv               worker-18.:sentinel-ent ESTABLISHED</span><br></pre></td></tr></table></figure><ul><li><strong>Proto：</strong>协议名（可以 TCP 协议或者 UDP 协议）。</li><li><strong>recv-Q：</strong>网络接收队列还有多少请求在排队。</li><li><strong>send-Q：</strong>网络发送队列有多少请求在排队。</li></ul><blockquote><p><strong>recv-Q 和 send-Q</strong> 如果长期不为 0，很可能存在网络拥堵，这个是判断网络瓶颈的重要依据。</p></blockquote><ul><li><strong>Foreign Address：</strong>与本机端口通信的外部 socket。</li><li><strong>State：</strong>TCP 的连接状态。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;针对不同层次进行性能测试的监控&quot;&gt;&lt;a href=&quot;#针对不同层次进行性能测试的监控&quot; class=&quot;headerlink&quot; title=&quot;针对不同层次进行性能测试的监控&quot;&gt;&lt;/a&gt;针对不同层次进行性能测试的监控&lt;/h1&gt;&lt;p&gt;在执行性能测试的过程中，监控服务端的</summary>
      
    
    
    
    <category term="技术小栈" scheme="http://ai.mak.cn/categories/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/"/>
    
    
    <category term="测试" scheme="http://ai.mak.cn/tags/%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>Langchain-Chatchat大语言模型本地知识库</title>
    <link href="http://ai.mak.cn/2024/06/30/ai/Langchain-Chatchat%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93/"/>
    <id>http://ai.mak.cn/2024/06/30/ai/Langchain-Chatchat%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93/</id>
    <published>2024-06-29T16:00:00.000Z</published>
    <updated>2024-12-18T07:14:06.939Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Langchain-Chatchat大语言模型本地知识库"><a href="#Langchain-Chatchat大语言模型本地知识库" class="headerlink" title="Langchain-Chatchat大语言模型本地知识库"></a>Langchain-Chatchat大语言模型本地知识库</h2><blockquote><p>链接：<a href="https://juejin.cn/post/7305572311812751371">https://juejin.cn/post/7305572311812751371</a> 来源：稀土掘金</p></blockquote><ul><li><a href="https://github.com/chatchat-space/Langchain-Chatchat">https://github.com/chatchat-space/Langchain-Chatchat</a></li></ul><p>Langchain-Chatchat是一种利用 langchain 思想实现的基于本地知识库的问答应用，目标期望建立一套对中文场景与开源模型支持友好、可离线运行的知识库问答解决方案。</p><p>💡Langchain-Chatchat建立了全流程可使用开源模型实现的本地知识库问答应用，使用基于 Streamlit 的 WebUI 进行操作。 <img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fd0aeef1d58043b5acb630ea8ca82b2c~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1664&h=904&s=154826&e=png&b=fcfcfc" alt="img"></p><p>⛓️ Langchain-Chatchat实现原理如下图所示，过程包括加载文件 -&gt; 读取文本 -&gt; 文本分割 -&gt; 文本向量化 -&gt; 问句向量化 -&gt; 在文本向量中匹配出与问句向量最相似的 top k个 -&gt; 匹配出的文本作为上下文和问题一起添加到 prompt中 -&gt; 提交给 LLM生成回答。 <img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/602aad3c063343f9859e3218f2faebb9~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1262&h=792&s=42649&e=png&b=fefefe" alt="img"></p><p>学术Fun将上述工具制作成一键启动包，内置chatglm3模型，点击即可使用，避免大家配置Python环境出现各种问题，下载地址： <a href="https://link.juejin.cn/?target=https://xueshu.fun/3278/">xueshu.fun&#x2F;3278&#x2F;</a>，<code>在此页面右侧区域点击下载！</code></p><p><code>注意电脑配置如下</code>：</p><ul><li>windows 10&#x2F;11</li><li><code>8G显存以上英伟达显卡</code></li></ul><h2 id="下载使用教程"><a href="#下载使用教程" class="headerlink" title="下载使用教程"></a>下载使用教程</h2><ul><li>下载压缩包 下载地址： <a href="https://link.juejin.cn/?target=https://xueshu.fun/3278/">xueshu.fun&#x2F;3278&#x2F;</a>，<code>在此页面右侧区域点击下载！</code></li><li>解压，解压后，最好路径和我的保持一致，<code>D:\AI\Langchain-ChatGLM</code>,如下图所示，双击<code>启动.exe</code>文件运行</li></ul><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ed68fff2413c46f1be2df610c5fc952e~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1647&h=1957&s=124411&e=png&b=ffffff" alt="img"></p><ul><li>启动过程中，会联网更新streamlit包，包很小只有10几兆，更新streamlit包是防止有的同学没有解压到和我本地一致的目录，会出现streamlit命令找不到的错误，启动完成后浏览器会自动打开使用界面，如下所示，本地访问地127.0.0.1:8501</li></ul><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7a759e002a934b128e2eabfbaad968b8~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=3164&h=1825&s=124939&e=png&b=fdfdfd" alt="img"></p><h3 id="本地知识库使用"><a href="#本地知识库使用" class="headerlink" title="本地知识库使用"></a>本地知识库使用</h3><ul><li>按照下图步骤，建立本地知识库</li></ul><ol><li>点击知识库管理</li><li>新建知识库</li></ol><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0ac324e79d0a4c4b8853ab9ecedb8b85~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=3240&h=1177&s=128148&e=png&b=fbfbfb" alt="img"></p><ol><li>新建知识库名称，不支持中文</li><li>填写知识库简介</li><li>点击新建 <img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/643bce05021443c08da606786bea686d~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=3135&h=1168&s=102393&e=png&b=fbfbfb" alt="img"></li><li>上传知识库文件，支持格式如图中所示</li><li>点击添加文件到知识库</li></ol><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c7ca0ed6c95445379f3d13bac5539b4e~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=3268&h=1474&s=150063&e=png&b=fbfbfb" alt="img"></p><h3 id="使用知识库问答"><a href="#使用知识库问答" class="headerlink" title="使用知识库问答"></a>使用知识库问答</h3><ol><li>选择对话</li><li>选择知识库问题对话模式</li><li>选择刚刚建立的知识库名称</li><li>输入内容进行知识库对话，对话内容会从上传的知识库文件中索引 <img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c42e87581e22479d991e0a09225108e7~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=3085&h=1606&s=166025&e=png&b=fdfdfd" alt="img"></li></ol><h3 id="联网问答功能"><a href="#联网问答功能" class="headerlink" title="联网问答功能"></a>联网问答功能</h3><p>还支持联网在线搜索问答，使用方式见下图： <img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/32de74065e5747eeb73d72b67a21522a~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=3312&h=1752&s=388767&e=png&b=fcfcfc" alt="img"></p><p>)</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Langchain-Chatchat大语言模型本地知识库&quot;&gt;&lt;a href=&quot;#Langchain-Chatchat大语言模型本地知识库&quot; class=&quot;headerlink&quot; title=&quot;Langchain-Chatchat大语言模型本地知识库&quot;&gt;&lt;/a&gt;La</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="深度学习" scheme="http://ai.mak.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>基于大模型的智能问答 - LangChain</title>
    <link href="http://ai.mak.cn/2024/06/15/ai/LangChain%20%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E9%97%AE%E7%AD%94/"/>
    <id>http://ai.mak.cn/2024/06/15/ai/LangChain%20%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%BA%E8%83%BD%E9%97%AE%E7%AD%94/</id>
    <published>2024-06-14T16:00:00.000Z</published>
    <updated>2024-12-18T07:16:57.242Z</updated>
    
    <content type="html"><![CDATA[<h1 id="LangChain-基于大模型的智能问答"><a href="#LangChain-基于大模型的智能问答" class="headerlink" title="LangChain 基于大模型的智能问答"></a>LangChain 基于大模型的智能问答</h1><p> 在构建基于大模型的智能问答系统时，LangChain 提供了一个强大的框架，支持各种模块来帮助开发者构建更复杂、更智能的语言处理应用。以下是构建此类系统的一些关键组件和步骤。</p><p>模型接入：使用 LangChain 支持的模型，通过 API 接入外部模型，或利用 <strong>api-for-open-llm</strong> 框架调用 本地llm模型。</p><p>向量库与嵌入模型：利用 Milvus 向量库和嵌入模型（如 m3e 向量模型）来增强问答系统的检索能力，使其能够从大量文本数据中快速检索相关信息。</p><p>链式调用和代理行动决策：使用 LangChain 的链（Chains）和代理（Agents）模块来构建复杂的问答逻辑，使系统能够根据用户输入做出连贯的决策并提供相关的回答。</p><p>提示词写法：根据需要编写适当的提示词，以引导模型提供准确的回答。可以使用 XML 标记来定义上下文和历史记录，以便模型更好地理解问题和背景。</p><p>通过以上步骤，可以构建一个基于大模型的智能问答系统，该系统能够理解用户的问题并提供准确、相关的回答。此外，通过不断优化模型、提示词和检索策略，可以进一步提高问答系统的性能和用户体验。</p><p><strong>langchain&#x2F;dify的智能体</strong></p><p>Langchain支持各种模型的接入、提示词管理、基于向量库的检索增强、索引优化、链式调用和代理行动决策，适用于创建自治代理、模拟、个人助理、问答系统、聊天机器人、数据查询、代码理解、API交互、信息提取、文本摘要和模型评估等多种应用场景。</p><p>dify则是国内开源的一个agent平台，类似于带界面的Langchain。</p><p><strong>m﻿ilvus向量库</strong></p><p>Milvus是在2019年创建的，其唯一目标是存储、索引和管理由深度神经网络和其他机器学习（ML）模型生成的大规模嵌入向量。</p><p>作为一个专门设计用于处理输入向量查询的数据库，它能够处理万亿级别的向量索引。与现有的关系型数据库主要处理遵循预定义模式的结构化数据不同，Milvus从底层设计用于处理从非结构化数据转换而来的嵌入向量。Milvus使得向应用中添加相似性搜索变得容易。</p><p><strong>嵌入模型</strong></p><p>嵌入模型（Embedding Model）是一种在自然语言处理（NLP）和机器学习中广泛使用的技术，旨在将高维的稀疏数据（如单词、句子或图像）转换为低维的密集向量表示。这种向量表示能够捕捉到数据的语义信息和结构特征，使得计算机能够更有效地处理和分析数据。</p><p>在NLP中，单词嵌入（Word Embedding）是最常见的嵌入模型之一。它将每个单词映射到一个固定长度的实数向量，使得语义上相似的单词在向量空间中也相互接近。这种表示方式可以有效地减少数据的维度，并捕捉单词之间的语义关系，如同义词、反义词和上下文相关性。</p><p>嵌入模型通常通过无监督学习方法从大量文本数据中学习得到，如Word2Vec、GloVe和fastText等。这些模型利用单词的共现信息和上下文关系来学习单词的向量表示。</p><p>除了单词嵌入，还有句子嵌入（Sentence Embedding）、段落嵌入（Paragraph Embedding）和图像嵌入（Image Embedding）等，它们分别用于将句子、段落和图像转换为密集向量表示，以便进行后续的机器学习任务，如文本分类、情感分析、图像识别等。</p><p>目前中文嵌入模型效果较好的推荐m3e向量模型。</p><p><strong>本地自有模型&#x2F;外部模型接口</strong></p><p>本地部署可以使用api-for-open-llm，该项目是一个开源框架，提供了统一的后端接口，使得以 OpenAI ChatGPT API 的方式调用各类开源大模型变得简单。</p><p>它支持流式响应、文本嵌入模型、langchain 的各类功能，并允许通过简单修改环境变量将开源模型作为 ChatGPT 的替代模型。此外，该项目还支持加载自行训练的 lora 模型，以及 vLLM 推理加速和处理并发请求，为各类应用提供强大的后端支持。</p><p>接口的话推荐使用gemini，在今年5月份之前gemini还是可以免费使用的。</p><p><strong>提示词写法</strong></p><p>以基于知识库的官网问答系统的提示词为例，下面是一个写好的提示词样例：</p><p>在XML标记中使用以下上下文作为您学到的知识。{上下文}</p><p>当回答用户:-如果你不知道，就说你不知道。</p><p>-如果你不知道，当你不确定，要求澄清。</p><p>避免提到你是从上下文中获得信息的。并根据用户提问的语言进行回答。</p><p>下面是人与助手之间的聊天历史记录，位于&lt;历史&gt;{聊天记录} XML标记中。</p><p><strong>总结</strong></p><p>基于大模型的智能问答系统利用 LangChain 框架和相关技术，如 Milvus 向量库和嵌入模型，提供了一个强大的解决方案，用于构建理解自然语言并提供准确回答的系统。通过集成不同的模型、管理提示词、利用向量检索和链式调用，这个系统能够处理复杂的用户查询，并根据上下文提供相关的信息。此外，系统的灵活性和可扩展性使得开发者可以根据特定需求定制和优化问答逻辑，从而提高用户体验和满意度。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;LangChain-基于大模型的智能问答&quot;&gt;&lt;a href=&quot;#LangChain-基于大模型的智能问答&quot; class=&quot;headerlink&quot; title=&quot;LangChain 基于大模型的智能问答&quot;&gt;&lt;/a&gt;LangChain 基于大模型的智能问答&lt;/h1&gt;&lt;</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="深度学习" scheme="http://ai.mak.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Three.js 开源组件</title>
    <link href="http://ai.mak.cn/2024/06/02/%E5%89%8D%E7%AB%AF/Three.js%20%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/"/>
    <id>http://ai.mak.cn/2024/06/02/%E5%89%8D%E7%AB%AF/Three.js%20%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/</id>
    <published>2024-06-01T16:00:00.000Z</published>
    <updated>2024-12-18T01:31:10.176Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Three-js-开源组件"><a href="#Three-js-开源组件" class="headerlink" title="Three.js 开源组件"></a>Three.js 开源组件</h1><p><code>Three.js</code> 是一款基于 <code>WebGL</code> 的强大 <code>JavaScript</code> 库，让浏览器中的 <code>3D</code> 图形创建与显示变得前所未有的简单。</p><p>通过精心设计的 API，Three.js 成功地降低了 <code>WebGL</code> 的<code>复杂性</code>，使得即使是没有深厚技术背景的开发者也能轻松打造出令人惊艳的 <code>3D 场景</code>、<code>模型</code>、<code>动画</code>以及<code>粒子系统</code>。</p><p>虽然 Three.js 目的是为了简化开发者创建和显示 3D 图形的难度，但对于初学者来说，上手仍然可能会有一定的<code>挑战性</code>。这主要是因为以下几个方面的原因：</p><ul><li><strong>技术门槛</strong>：尽管 Three.js 简化了 WebGL 的复杂性，但它仍然涉及到<code>图形学</code>、&#96;&#96;线性代数、<code>3D 编程</code>等相对复杂的概念。对于没有相关背景知识的开发者来说，理解这些概念可能需要一定的时间和努力。</li><li><strong>API 学习曲线</strong>：Three.js 提供了一个<code>庞大的 API</code>，涵盖了从场景创建、物体渲染到光照、动画等多个方面。初学者需要花费一定的时间去熟悉这些 API，并了解它们的使用方法和最佳实践。</li><li><strong>编程经验</strong>：编写 3D 应用程序通常比编写传统的 2D 应用程序&#96;&#96;更加复杂，需要处理更多的数据和对象。因此，具备一定的编程经验和逻辑思维能力会更有助于上手 Three.js。</li><li><strong>资源获取</strong>：找到高质量的<code>教程</code>、<code>示例代码</code>和<code>项目模板</code>对于初学者来说非常重要。然而，网络上的资源可能质量参差不齐，需要花费一定的时间和精力进行筛选和学习。</li></ul><p>今天就来给大家推荐两个开源项目合集，带你快速入门 <code>Three.js</code>！！！</p><h2 id="vis-three"><a href="#vis-three" class="headerlink" title="vis-three"></a><strong>vis-three</strong></h2><blockquote><p>开源地址：<code>https://github.com/vis-three</code></p></blockquote><p><code>vis-three</code> 是一款基于 three.js 的<code>组装式</code>前端 3D 开发框架，为了解决 three.js 相关项目开发的<code>代码组织</code>问题，降低功能代码间的耦合，提高功能复用性，提高扩展能力，vis-three 提出了<code>功能插件</code>化概念，采用了<code>插件化</code>的组织形式，vis-three 的核心引擎提供功能插件的拔插能力，对各模块各功能进行解耦开发，持续集成，兼容拓展。</p><blockquote><ul><li>演示地址：<code>https://vis-three.github.io/exhibition-hall//SimpleSmartCity/index.html</code></li></ul></blockquote><blockquote><ul><li>演示地址：<code>https://vis-three.github.io/exhibition-hall//easyFactory/index.html</code></li></ul></blockquote><h2 id="icegl-three-vue-tres"><a href="#icegl-three-vue-tres" class="headerlink" title="icegl-three-vue-tres"></a><strong>icegl-three-vue-tres</strong></h2><blockquote><p>开源地址：<code>https://gitee.com/ice-gl/icegl-three-vue-tres</code></p></blockquote><p><code>icegl-three-vue-tres</code> 是 <code>icegl 图形学社区</code> 出品，一款让你的三维可视化项目快速落地的开源框架并且永久开源免费商用。</p><p>icegl 图形学社区提供了上百个 Threejs <code>可视化案例</code>供开发者学习，并且有免费完善的 WebGL 从入门到实战的<code>教程</code>，帮助大家快速上手。</p><p>案例展示：</p><blockquote><ul><li>演示地址：<code>https://opensource.icegl.cn/#/plugins/digitalCity/roadLines</code></li></ul></blockquote><blockquote><ul><li>演示地址：<code>https://opensource.icegl.cn/#/plugins/simpleGIS/mapBuildings</code></li></ul></blockquote><blockquote><ul><li>演示地址：<code>https://opensource.icegl.cn/#/plugins/industry4/deviceLightReflector</code></li></ul></blockquote><p>参考连接:</p><ul><li><a href="https://github.com/vis-three/vis-three">https://github.com/vis-three/vis-three</a></li><li><a href="https://gitee.com/ice-gl/icegl-three-vue-tres">https://gitee.com/ice-gl/icegl-three-vue-tres</a></li><li><a href="https://icegl.cn/">https://icegl.cn/</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Three-js-开源组件&quot;&gt;&lt;a href=&quot;#Three-js-开源组件&quot; class=&quot;headerlink&quot; title=&quot;Three.js 开源组件&quot;&gt;&lt;/a&gt;Three.js 开源组件&lt;/h1&gt;&lt;p&gt;&lt;code&gt;Three.js&lt;/code&gt; 是一款基</summary>
      
    
    
    
    <category term="前端" scheme="http://ai.mak.cn/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="js" scheme="http://ai.mak.cn/tags/js/"/>
    
  </entry>
  
  <entry>
    <title>深入理解Transformer</title>
    <link href="http://ai.mak.cn/2024/05/18/ai/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/"/>
    <id>http://ai.mak.cn/2024/05/18/ai/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Transformer%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/</id>
    <published>2024-05-17T16:00:00.000Z</published>
    <updated>2024-12-17T09:56:05.262Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深入理解Transformer"><a href="#深入理解Transformer" class="headerlink" title="深入理解Transformer"></a>深入理解Transformer</h1><blockquote><p>作者：得物技术<br>链接：<a href="https://juejin.cn/post/7358743626166222874">https://juejin.cn/post/7358743626166222874</a><br>来源：稀土掘金</p></blockquote><blockquote><ul><li>本文深入介绍了 Transformer 技术原理，包括注意力机制、架构设计、Token 处理、编解码器工作流程等，还讲解了 Transformer-XL 提升上下文长度的方法，分享了 Transformer 相关应用，如 BERT 掩词填充、BART 文本摘要等，并提供了参考文档。</li></ul></blockquote><p>谷歌在2017年发布Transformer架构的论文时，论文的标题是：Attention Is All You Need。重点说明了这个架构是基于注意力机制的。</p><h2 id="一、什么是注意力机制"><a href="#一、什么是注意力机制" class="headerlink" title="一、什么是注意力机制"></a><strong>一</strong>、<strong>什么是注意力机制</strong></h2><p>在深入了解Transformer的架构原理之前，我们首先要了解下，什么是注意力机制。人类的大脑对于信息的获取也存在注意力机制，下面我举几个简单的例子：<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0012f40763e84cc8baa4a6063c572357~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=293&s=137911&e=png&b=daf9fe" alt="图片">从上面的图片中，我们可能更容易关注，颜色更深的字、字号更大的字，另外像“震惊”这种吸引人眼球的文案也非常容易吸引人的关注。我们知道在海量的互联网信息中，往往那些起着“标题党”的文章更能吸引人的注意，从而达到吸引流量的目的，这是一种简单粗暴的方式。另外在大量的同质化图片中，如果有一张图片它的色彩、构图等都别出一格，那你也会一眼就能注意到它，这也是一种简单的注意力机制。假设有以下这两段文字，需要翻译成英文：<strong>1、我在得物上买了最新款的苹果，体验非常好。</strong> <strong>2、我在得物上买了阿克苏的苹果，口感非常好。</strong> 我们人类能很快注意到第一段文字中的苹果是指苹果手机，那么模型在翻译时就需要把他翻译成iPhone，而第二段文字中的苹果就是指的苹果这种水果，模型翻译时就需要将他翻译成apple。人类的大脑为什么能分辨出这两个苹果是指代的不同的意思呢？原因就是人类的大脑能从上下文中获取到关键信息，从而帮助我们理解每种苹果是什么意思。其实说到这里，我们就已经揭开了Transformer架构的核心，即注意力机制的原理：从文本的上下文中找到需要注意的关键信息，帮助模型理解每个字的正确含义。但是实际的实现方式又是非常复杂的。接下来让我们一起深入理解下Transformer的架构原理。</p><h2 id="二、Transformer架构设计"><a href="#二、Transformer架构设计" class="headerlink" title="二、Transformer架构设计"></a><strong>二</strong>、<strong>Transformer架构设计</strong></h2><p>Transformer的架构设计如下图所示：<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/59a5ad40a7f348feb23baf45a07b2dfe~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=672&h=1066&s=16767&e=png&b=fff6df" alt="图片"><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3ee0296b74bc4dd5ad99c446d3c8c115~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=680&h=980&s=241104&e=png&b=fdf7f7" alt="图片">Transformer架构中有两个核心的组件Encoder和Decoder，左边的这张图是Transformer架构的一个简单表示形式，右边的这张图是Transformer架构的一个完整表示形式，其中有一个重要的Multi-Head Attention组件，称为注意力层。Transformer架构中的两个核心的组件Encoder和Decoder，每个组件都可以单独使用，具体取决于任务的类型：</p><ul><li>Encoder-only models: 适用于需要理解输入的任务，如句子分类和命名实体识别。</li><li>Decoder-only models: 适用于生成任务，如文本生成。</li><li>Encoder-decoder models 或者 sequence-to-sequence models: 适用于需要根据输入进行生成的任务，如翻译或摘要。</li></ul><h2 id="三、理解Transformer中的Token"><a href="#三、理解Transformer中的Token" class="headerlink" title="三、理解Transformer中的Token"></a><strong>三</strong>、<strong>理解Transformer中的Token</strong></h2><p>因为模型是无法直接处理文本的，只能处理数字，就跟ASCII码表、Unicode码表一样，计算机在处理文字时也是先将文字转成对应的字码，然后为每个字码编写一个对应的数字记录在表中，最后再处理。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ab0e81aa7c724b89862bc74f56667b48~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=713&h=368&s=231277&e=png&b=eeee80" alt="图片"></p><p><strong>将文本拆分成token</strong></p><p>所以模型在处理文本时，第一步就是先将文本转换成对应的字码，也就是大模型中的token，但是怎么将文本转换成对应的token却是一个复杂的问题，在Transformers(HuggingFace提供的一个对Transformer架构的具体实现的组件库)中提供了专门的Tokenizer分词器来实现这个任务，一般来说有以下几种方式：</p><p><strong>基于单词的分词器</strong></p><p>第一种标记器是基于单词的(word-based)。它通常很容易设置和使用，只需几条规则，并且通常会产生不错的结果。例如，在下图中，目标是将原始文本拆分为单词，并为每个单词找到一个映射的数字表达：将文本拆分成单词，也有很多不同的方式，比如通过空格来拆分、通过标点符号来拆分。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/093a0cc2b57e4b878bc43d525fb555b1~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=234&s=28625&e=png&b=ffffff" alt="图片">如果我们想使用基于单词的标记器(tokenizer)完全覆盖一种语言，我们需要为语言中的每个单词都创建一个数字标记，这将生成大量的标记。除此之外，还可能存在一些无法覆盖的单词，因为单词可能存在很多的变种情况，比如：dogs是dog的变种，running是run的变种。如果我们的标识符中没有覆盖所有的单词，那么当出现一个未覆盖的单词时，标记器将无法准确知道该单词的数字标记是多少，进而只能标记为未知：UNK。如果在文本转换的过程中有大量的文本被标记为UNK，那么也将影响后续模型推理。</p><p><strong>基于字符的标记器</strong></p><p>为了减少未知标记数量的一种方法是使用更深一层的标记器(tokenizer)，即基于字符的(character-based)标记器(tokenizer)。基于字符的标记器(tokenizer)将文本拆分为字符，而不是单词。这有两个主要好处：</p><ul><li>词汇量要小得多。</li><li>未知的标记(token)要少得多，因为每个单词都可以从字符构建。</li></ul><p>但是这里也出现了一些关于空格和标点符号的问题：<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/678e68a6a5f3414a946017eede9d777d~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=77&s=15103&e=png&b=f4efff" alt="图片">这种方法也不是完美的。由于现在表示是基于字符而不是单词，因此人们可能会争辩说，从直觉上讲，它的意义不大：每个字符本身并没有多大意义，而单词就是这种情况。然而，这又因语言而异；例如，在中文中，每个字符比拉丁语言中的字符包含更多的信息。另一件要考虑的事情是，我们的模型最终会处理大量的词符(token)：虽然使用基于单词的标记器(tokenizer)，单词只会是单个标记，但当转换为字符时，它很容易变成 10 个或更多的词符(token)。为了两全其美，我们可以使用结合这两种方法的第三种技术：<strong>子词标记化(subword tokenization)</strong> 。</p><p><strong>基于子词的标记器</strong></p><p>子词分词算法依赖于这样一个原则，<strong>即不应将常用词拆分为更小的子词，而应将稀有词分解为有意义的子词。</strong> 例如，“annoyingly”可能被认为是一个罕见的词，可以分解为“annoying”和“ly”。这两者都可能作为独立的子词出现得更频繁，同时“annoyingly”的含义由“annoying”和“ly”的复合含义保持。下面这张图，展示了基于子词标记化算法，如何标记序列“Let’s do tokenization!”：<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/56d7c23fbcfa4978bb05d6b485b51514~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=79&s=19357&e=png&b=f4efff" alt="图片">这些子词最终提供了很多语义含义：例如，在上面的示例中，“tokenization”被拆分为“token”和“ization”，这两个具有语义意义同时节省空间的词符(token)（只需要两个标记(token)代表一个长词）。这使我们能够对较小的词汇表进行相对较好的覆盖，并且几乎没有未知的标记。</p><p><strong>向量、矩阵、张量</strong></p><p>了解完token之后，我们还要了解下向量、矩阵和张量的概念，因为他们是大模型计算中基础的数据结构。</p><p><strong>向量(Vector)</strong></p><p>向量是一个有序的数字列表，通常用来表示空间中的点或者方向。在数学中，向量可以表示为一个列向量或行向量，具体取决于上下文。例如，一个三维空间中的点可以用一个三维列向量表示，如 <strong>v</strong>&#x3D;[x,y,z]T，其中 x,y,z 是实数。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3c4d6e10f7c749bbac754abd7a0fed51~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=580&h=148&s=2904&e=png&b=b1dd9f" alt="图片"></p><p><strong>矩阵(Matrix)</strong></p><p>矩阵是一个二维数组，由行和列组成，可以被视为向量的一个特例。矩阵在数学中用于表示线性变换、系统方程的系数等。矩阵的维度通常表示为 m×n，其中 m 是行数，n 是列数。例如，一个 4×3 的矩阵有四行三列。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3e8c534a55e44f8e91289aad7224bfac~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=320&h=418&s=2874&e=png&b=dcdde0" alt="图片"></p><p><strong>张量(Tensor)</strong></p><p>张量是一个多维数组，可以看作是向量和矩阵的更底层的表示，向量和矩阵是张量的特例。例如向量是一维的张量，矩阵是二维的张量。张量可以有任意数量的维度，而不仅仅是一维（向量）或二维（矩阵）。张量在物理学中用来表示多维空间中的物理量，如应力、应变等。在深度学习中，张量用于表示数据和模型参数的多维结构。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8b49f57afd704065b77f84befd690645~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=376&h=308&s=17035&e=png&b=f3c890" alt="图片"></p><p><strong>将token转换成向量</strong></p><p>在获取到token之后，再将每个token映射为一个数字，当然了，Transformer能够处理的数据，并不是简单的1&#x2F;2&#x2F;3这样的数字，而是一种向量数据，如下图所示：<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/aa5c6f8c2cd646d98330eaf04fb13dea~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=776&h=282&s=6746&e=png&b=ffffff" alt="图片"></p><p><strong>将向量转换成嵌入</strong></p><p>得到向量之后，再将向量转换成词嵌入，也就是我们所熟知的embeddings。在Transformer模型中，编码器接收的词嵌入（embeddings）可以被视为矩阵。这些词嵌入是将输入序列中的每个token映射到一个固定维度的向量空间中的结果。每个词嵌入都是一个向量，而这些向量按顺序排列形成一个矩阵。具体来说，如果你有一个句子或序列，其中包含了N个token，每个token都被映射到一个d维的向量空间中，那么你将得到一个N×d的矩阵，其中N是序列的长度，d是嵌入向量的维度。这个矩阵就是词嵌入矩阵，它是一个二维张量，因为它具有两个维度：序列长度（时间步长）和嵌入维度。在Transformer模型的编码器中，这个嵌入矩阵首先会通过一个线性层（可选）进行处理，然后添加位置编码（positional encoding），最后输入到自注意力（self-attention）和前馈网络（feed-forward network）等组件中进行进一步的处理，具体细节我接下来会进行详细解释。总结来说，编码器接收的词嵌入是一个矩阵，这个矩阵可以被视为一个二维张量，其中包含了序列中每个词的d维向量表示。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f92ebed94e1f43e99a85449e0b1cb216~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=562&s=181589&e=png&b=dafcfe" alt="图片"></p><h2 id="四、理解Transformer的编解码器"><a href="#四、理解Transformer的编解码器" class="headerlink" title="四、理解Transformer的编解码器"></a><strong>四</strong>、<strong>理解Transformer的编解码器</strong></h2><p>下面让我们以文本翻译来深入理解Transformer中的Encoder和Decoder是怎样工作的，假设我们有以下这个翻译任务，输入是一段法文，输出是英文。整个流程是Transformer将输入的input，经过Encoders处理后，将结果投递到Decoders中处理，最后输出翻译后的结果。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8288479eccc94453b9cfdf9d048f9c65~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=697&h=422&s=32125&e=png&b=fdfaf9" alt="图片">但是实际在Transformer的内部，是由多个独立的Encoder和Decoder组成的，这里我们使用6个做验证，当然我们也可以使用其他数量的Encoder和Decoder，笔者怀疑6个是经过验证后相对折中的一个值。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/eefd8b316e414ad193183072eaaa62e1~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=900&h=610&s=104117&e=png&b=fdfbfa" alt="图片">这6个Encoder和Decoder在结构上都是相同的，但是Encoder和Decoder的内部还有更细分的组件：每一层的Encoder由2个子组件组成：自注意力层和前馈网络层，<strong>其中文本的输入会先流入自注意力层，正是由于自注意力层的存在，帮助Encoder在对特定文本进行遍历时，能够让Encoder观察到文本中的其他单词</strong>。然后自注意力层的结果被输出到前馈网络层。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bca0128b67d54c8caf9630f707ca9100~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=749&h=339&s=27550&e=png&b=ffffff" alt="图片">每一层的Decoder由3个子组件组成：除了自注意力层、前馈网络层，<strong>在两者之间还有一个编解码注意力层，这个组件主要是帮助Decoder专注于输入句子的相关部分</strong>。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f873eb1637ac46d8ab79952502b65af4~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=877&h=291&s=34928&e=png&b=ffffff" alt="图片"></p><h2 id="五、理解Token在编码器中的流转"><a href="#五、理解Token在编码器中的流转" class="headerlink" title="五、理解Token在编码器中的流转"></a><strong>五</strong>、<strong>理解Token在编码器中的流转</strong></h2><p>现在我们已经知道了Transformer模型中的核心组件Encoder和Decoder，接下来我们来看Token在Transformer中是怎么流转的，换句话说Encoder和Decoder是怎么处理Token的。拿最开始的法文翻译的例子，模型将文本转换token后，紧接着就是将每个token转换成向量表达，在下图中，我们用x1、x2、x3这样的box来表示每个token的向量：<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0f6062eb2df44c88b6ae3afa6dcb054b~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=773&h=138&s=21424&e=png&b=ffffff" alt="图片">得到每个token的向量之后，从最底层的Encoder开始，每个token会沿着自己的路径从下往上流转，经过每一个Encoder，对每个Encoder来说，共同点是他们接收的向量的维度都是相同的，为了保证这一点，所有的token都需要被embedding成相同大小的向量。</p><p><strong>对Token进行位置编码</strong></p><p>在流经每个Encoder时，向量都会从自注意力层流向前馈层，如下图所示：<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c25b413c86074abd8d2597cfef9539dd~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=903&h=590&s=52118&e=png&b=fff8f7" alt="图片">这里需要注意的是，<strong>不同位置的向量在进入自注意力层的时候，相互之间是有依赖关系的，这就是注意力层需要关注的上下文的信息。</strong> 而当自注意力层处理后的向量进入前馈层后，前馈层是可以并行计算以提升性能的，因为在前馈层中向量之间不存在依赖关系。每个向量在经过Encoder处理后，得到的仍然是一个相同大小的向量，然后再提交给下一个Encoder进行处理。</p><p>为什么说不同位置的向量相互之间是有依赖关系的呢？我们可以想象一下，如果不关注一整个句子中token的位置信息，那么翻译出来的结果是不准确的，比如：</p><ol><li><strong>Sam is always looking for trouble</strong></li><li><strong>Trouble is always looking for Sam</strong></li></ol><p>为了让模型知道每个token的位置信息，传统的RNN网络的做法是，顺序处理每个token，这样在处理当前token时，可以往前查看已经处理过的token的信息，但是缺点是所有的token节点都共用一套相同的参数，即下图中的：</p><p>U：输入参数</p><p>W：隐藏参数</p><p>V：输出参数</p><p><strong>由于RNN的窗口较小，这种方案带来的问题是，当token数变大时，模型无法参考更早之前已经参考过的token，这样就会造成上下文记忆丢失。</strong> <img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c3478560935041b38b8802ca67062ad0~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=864&h=353&s=98342&e=png&b=fefefe" alt="图片">那么Transformer是怎么对token进行位置编码的呢？首先我们知道每个token会被转换成512维(或更高的维度)的向量，比如：[0.12142,0.34181,….,-0.21231] 可以将这个向量分为两个部分，奇数和偶数部分。奇数部分使用cos函数，加上当前token的位置信息pos，通过cos编码得到一个奇数编码值；偶数部分使用sin函数，加上当前token的位置信息pos，通过sin编码得到一个偶数编码值；<strong>最后拿token的embeddings和pos的embeddings相加，得到位置编码后的positional input embeddings。</strong> <img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1f11e50479854b6fa1ddfa8268c9a0a5~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=877&h=676&s=129759&e=png&b=010101" alt="图片"><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/56f435fdbe9a4b7d92a3a1533a78c030~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=884&h=681&s=129345&e=png&b=010101" alt="图片"></p><p><strong>自注意力机制</strong></p><p>有了位置编码的信息后，模型将接收经过位置编码的embeddings输入，为了方便描述，我们把token换成更简单的文本，如下图所示，Encoder在接收到两个向量之后，通过自注意力层，将原始向量转换成携带了自注意力值的向量，也就是图中的z1和z2。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b5778c1edfc64a4c9c42621c79f69f5b~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=657&s=64603&e=png&b=fff9f8" alt="图片"></p><p><strong>计算注意力值</strong></p><p>那z1和z2这两个向量是怎么得到的呢？原论文中给出了计算公式：<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/82707b451c4442b09b2c468889eea6c2~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=440&h=82&s=7578&e=png" alt="图片">这个公式是用来计算注意力值的，借助了Q、K、V这三个矩阵：首先通过Q矩阵**和转置后的K矩阵转置相乘，得到结果后再除以dk的开平方，再通过softmax函数得到一个归一化的结果，最后将归一化的结果和矩阵V相乘就得到了表示注意力值的矩阵。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8e8a8de27d5f4abe9094fa5003b39776~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=893&h=349&s=14389&e=png&b=ffffff" alt="图片">这里的Q、K、V三个矩阵(查询矩阵、键矩阵、值矩阵)是通过原始token的embedding矩阵计算得到的，具体的方法是，先训练出三个矩阵：Wq,Wk,Wv, 然后使用embedding处理后的X矩阵和这三个矩阵相乘得到：</p><p><strong>Q&#x3D;Wq * X</strong></p><p><strong>K&#x3D;Wk * X</strong></p><p><strong>V&#x3D;Wv * X</strong></p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/050c3ab21ac1434ea7f2b3d92b75e1cf~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=581&h=658&s=13223&e=png&b=ffffff" alt="图片"><strong>需要注意的是我们embedding输入原本是向量，并不是矩阵，这里是将所有的向量打包之后，形成了一个矩阵，方便矩阵之间的计算。</strong> 下面我们一步步了解下注意力值是怎么计算的，使用原始的embedding，而不是打包后的矩阵，<strong>首先模型将会为句子中的每个token都计算出一个score分数，这个分数表示了该token对句子中其他token的关注程度，分数越高关注度越高。</strong> <img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/770bcbac42004c0eb9f8b14e05e06f84~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=697&s=87041&e=png&b=ffffff" alt="图片">但是需要注意的是这里计算得到的中间向量q、k、v的维度是<strong>64维</strong>，小于Encoder接收的输入向量的维度，这是一个经过计算后得到的相对稳定的数值。如下图所示，当我们在计算Tinking这个token的注意力值时，会依次计算出Thinking对其他token(在这里也就是Thinking和Machines)的注意力值，计算token1对其他各个token的score的方式是：q1 与 k1 做点积，q1 与 k2 做点积。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/87a6ccfaa33e4973844d82aa126df4bc~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=685&h=358&s=20465&e=png&b=ffffff" alt="图片">得到每个score后，再把score除以K向量维度的平方根也就是√64&#x3D;8，然后将结果通过Softmax进行归一化，得到一个0<del>1之间的概率值，所有的归一化的加和值等于1。![图片](<a href="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6c612b31ae464ce592b2f17a644dfba3">https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6c612b31ae464ce592b2f17a644dfba3</a></del>tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w&#x3D;867&amp;h&#x3D;546&amp;s&#x3D;35500&amp;e&#x3D;png&amp;b&#x3D;ffffff)最后将Softmax的值，与V向量相乘，得到自注意力层的输出结果向量：z1和z2，需要注意的是相乘的过程中会将不相关的token的关注度降低。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/39f75aa4e9e44189bbd34c6d023baff4~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=786&h=747&s=40925&e=png&b=ffffff" alt="图片">到这里其实已经把Encoder是怎么计算每个token对句子中其他token的注意力值的方法解释清楚了，下面我们用一张图从更高的层面来观察这个过程，假设我们想要翻译下面这个句子：<strong>The animal didn’t cross the street because it was too tired.</strong> 句子中的it是表示什么呢，是animal还是street？模型就是通过自注意力值来确定的，当对it进行编码时，Encoder会对句子中的每个token都计算一遍注意力值，模型会将it更关注的“The animal”编码到it中。这样模型在后续的处理过程中就能知道it指代的是“The animal”。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e33ed7ffc7e1414c840370969f5fc3c6~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=437&h=413&s=33175&e=png&b=fef7f6" alt="图片"></p><p><strong>多头注意力机制</strong></p><p>论文中通过引入多个Encoder形成了一种“多头注意力”的机制，对自注意力层进行了能力的提升，主要包括：</p><ol><li>多头注意力扩展了模型关注不同位置的能力</li><li>多头注意力为自注意力层提供了多个子空间</li></ol><p>Transformer模型使用了8个注意力头，所以在计算每个Encoder的输出时，我们会得到8个z向量。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6b3bea63f03b486297ff4804f1365afc~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=638&s=43187&e=png&b=ffffff" alt="图片"><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b0ce1bd6398842b7b2b82e3f37868a88~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1018&h=483&s=30082&e=png&b=ffffff" alt="图片">但是前馈层只能接收1个z向量，所以我们还需要将这8个z向量做压缩得到1个向量，具体的做法是将这8个z向量链接起来，然后乘以一个附加的权重矩阵Wo，最后得到z向量，如下图所示：<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e3d0c0449f7d491c90d043ceda3171d9~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=597&s=68367&e=png&b=ffffff" alt="图片">最后我们用一张完整的大图来描述下在多个Encoder下，注意力值的计算过程，也就是多头注意力机制：<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6661db08ea6b4e468b83abf6f5863120~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=605&s=128979&e=png&b=ffffff" alt="图片">下面我们可以看下，在多头注意力机制下，在编码it这个token时，模型在注意哪些其他的token：<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0628d2f3618346ad92352ec43ba1dcf8~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=438&h=395&s=35228&e=png&b=fdf8f8" alt="图片"><strong>可以看到其中一个头(橙色)更关注“The Animal”，因为这两个token对应的橙色更深，另外一个头(绿色)则更关注“tired”，因为这两个token对应的绿色更深。</strong></p><p><strong>残差网络</strong></p><p>首先我们了解下什么是残差网络，残差网络（Residual Network，简称ResNet）是一种深度卷积神经网络（CNN）架构，由Microsoft Research Asia的Kaiming He**等人在2015年提出。ResNet的核心思想是通过引入“残差学习”（residual learning）来解决深度神经网络训练中的退化问题（degradation problem）。在传统的深度神经网络中，随着网络层数的增加，理论上网络的表示能力应该更强，但实际上，过深的网络往往难以训练，性能反而不如层数较少的网络。这种现象被称为“退化问题”，即随着网络深度的增加，网络的准确率不再提升，甚至下降。ResNet通过引入“跳跃连接”（skip connections）或“捷径连接”（shortcut connections）来解决这个问题。在ResNet中，输入不仅传递给当前层，还直接传递到后面的层，跳过一些中间层。这样，后面的层可以直接学习到输入与输出之间的残差（即差异），而不是学习到未处理的输入。这种设计允许网络学习到恒等映射（identity mapping），即输出与输入相同，从而使得网络可以通过更简单的路径来学习到正确的映射关系。在Transformer模型中，残差网络的使用主要是为了解决自注意力机制（self-attention）带来的问题。Transformer模型完全基于注意力机制，没有卷积层，但其结构本质上也是深度网络。在Transformer中，每个编码器（encoder）和解码器（decoder）层都包含自注意力和前馈网络，这些层的参数量非常大，网络深度也很容易变得很深。使用残差连接可以帮助Transformer模型更有效地训练深层网络。在Transformer的自注意力层中，输入通过自注意力和前馈网络后，与原始输入相加，形成残差连接。这种设计使得网络即使在增加更多层数时，也能保持较好的性能，避免了退化问题。总结来说，残差网络在Transformer模型中的应用解决了以下几个问题：</p><ol><li><strong>缓解退化问题：</strong> 通过残差学习，使得网络即使在增加层数时也能保持或提升性能。</li><li><strong>加速收敛：</strong> 残差连接提供了梯度的直接路径，有助于梯度在深层网络中的传播，加速训练过程。</li><li><strong>提高表示能力：</strong> 允许网络学习更复杂的函数，同时保持对简单函数的学习能力。</li></ol><p>Transformer模型的成功部分归功于残差连接的设计，这使得它能够构建更深、更强大的模型，从而在自然语言处理（NLP）和计算机视觉等领域取得了显著的成果。<strong>可以使用下面这张图来解释残差网络，原始向量x在经过自注意力层之后得到z向量，为了防止网络过深带来的退化问题，Transformer模型使用了残差网络，具体做法是使用计算得到的z矩阵，在和原始输入的x矩阵做残差链接，即图中的X+Z，然后使用LayerNorm函数进行层归一化，计算得到新的z向量，然后输入到前馈层。</strong> <img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8a8c412a4463458a87d04c47092172e4~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=712&h=666&s=59798&e=png&b=fffbfa" alt="图片">将 <strong>Add &amp; Normalize</strong> 简化之后表示为如下：<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1d54dcf5be99426c9eeb12dd416070b2~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=666&h=483&s=48032&e=png&b=fffcfc" alt="图片"></p><p><strong>前馈网络</strong></p><p>归一化后的残差输出，被送入点对点前馈网络进行进一步处理，点对点前馈网络是几个线性层，中间有ReLU激活函数，将点对点输出的结果与前馈网络的输入进行相加做残差链接，然后再做进一步的归一化。点对点前馈网络主要用于进一步处理注意力的输出，让结果具有更丰富的表达。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7c325276afe5419c9309efb34bce9480~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=936&h=716&s=116576&e=png&b=000000" alt="图片">到这里编码器就已经介绍完了，编码器输出的结果中携带了每个token的相关注意力信息，将用以帮助解码器在解码过程中关注输入中的特定的token信息。</p><h2 id="六、理解Token在解码器中的流转"><a href="#六、理解Token在解码器中的流转" class="headerlink" title="六、理解Token在解码器中的流转"></a><strong>六</strong>、<strong>理解Token在解码器中的流转</strong></h2><p>每个解码器拥有与编码器相似的结构但也有不同的地方，它有两个多头注意力层，一个点对点前馈网络层，并且在每个子层之后都有残差链接和层归一化。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/12979fcd9e1d4c1ba44e0ffd0d4281c9~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=470&h=1306&s=124247&e=png&b=fefefe" alt="图片">解码器是自回归的，它将前一个Decoder输出的结果和来自编码器输出的注意力信息当做解码器的输入。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b32f24652d7d47a4b6e48e523ddcbae0~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=614&s=174102&e=png&b=fff7f4" alt="图片">这里我们需要了解清楚，解码器的先前的输出结果是怎么得到的，即解码器的第一个输出结果从哪得到的。在Transformer模型的训练过程中，解码器的第一个输出序列通常是根据特定的起始标记（start token）或者一个预先定义的初始状态得到的。这个起始标记是一个特殊的符号，它标志着输出序列的开始。以下是解码器如何获得第一个输出序列的详细过程：<strong>1. 起始标记：</strong> 在训练阶段，解码器的输入序列通常以一个起始标记（例如）开始。这个标记是一个预定义的词汇表中的词，它告诉解码器输出序列的生成即将开始。<strong>2. 初始化状态：</strong> 解码器在开始生成输出之前，会接收到编码器的输出，即编码器的上下文向量。这些上下文向量包含了输入序列（如源语言文本）的信息。在某些情况下，解码器的初始状态也可以通过一个额外的向量（如位置编码）来初始化，以提供序列中每个位置的信息。<strong>3. 自注意力机制：</strong> 在第一个时间步，解码器使用自注意力机制处理起始标记。由于此时没有之前的输出，自注意力机制会关注起始标记本身，以及可能的位置编码。<strong>4. 编码器-解码器注意力：</strong> 解码器接着使用编码器-解码器注意力机制来关注编码器的输出。这允许解码器在生成第一个输出时就利用到输入序列的信息。<strong>5. 输出层：</strong> 解码器的输出层将上述步骤得到的向量转换为概率分布，这个分布表示了词汇表中每个词作为第一个输出的概率。<strong>6. 选择第一个输出：</strong> 在训练阶段，解码器可能会使用强制策略，这意味着解码器的第一个输出会直接使用目标序列中的第一个词。在推理阶段，解码器会根据概率分布选择概率最高的词作为第一个输出。<strong>7. 迭代生成：</strong> 一旦获得了第一个输出，解码器就会将其作为下一个时间步的输入，并重复上述过程来生成后续的输出序列。在实际应用中，解码器的第一个输出序列的生成方式可能会根据具体的任务和模型配置有所不同。例如，在某些情况下，解码器可能会接收到一个完整的前缀序列，而不是单一的起始标记，这在文本摘要任务中较为常见。在这种情况下，解码器会基于这个前缀序列来生成剩余的输出序列。</p><p><strong>Masked多头注意力机制</strong></p><p>需要注意的是解码器中的第一层是一个特殊的多头注意力层，是一个执行了mask的注意力层，因为解码器是自回归的，并且依次生成结果token，我们需要防止它在处理某个token时，对未来的token进行处理，<strong>原因是模型在训练的时候，是不知道未来输出的token是什么的，为了保证训练过程和解码的过程的一致性，我们需要让解码器在计算某个token的注意力值的时候，只关注这个句子中已经出现过的token，而屏蔽掉句子中当前token之后的其他token的信息。</strong> 可以通过以下这张图来描述Mask的过程，当解码器在处理it时，应该把it之后的所有token屏蔽掉。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1032e811031e4b0191c6a429b8c3aeef~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=928&h=832&s=201434&e=png&b=fcf9f9" alt="图片"></p><p><strong>计算注意力值</strong></p><p>在解码器中计算注意力值时，是用Encoder最后的输出，和每一个Decoder进行交互，这就需要Decoder中的第二层Encoder-Decoder Attention。每个Decoder计算出结果之后，再作为输入传递给下一个Decoder。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1777def6d9af4fe9963659f73ce518c3~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=703&s=111525&e=png&b=ffffff" alt="图片"></p><p><strong>线性分类器&amp;Softmax</strong></p><p>当最后一个Decoder计算完毕后，解码器得到了一个输出结果的向量数据。我们如何把它变成一个词呢？这就是最后一个 Linear 层的工作，后面是 Softmax 层。线性层是一个简单的全连接神经网络，它将解码器产生的向量投影到一个更大的向量中，称为 logits 向量。假设我们的模型知道从训练数据集中学习的 10,000 个独特的英语单词。这将使 logits 向量有 10,000 个单元格宽——每个单元格对应一个唯一单词的分数，这就是我们解释线性层模型输出的方式。然后，softmax 层将这些分数转换为概率（全部为正，全部加起来为 1.0）。选择概率最高的单元格，并生成与其关联的单词作为该时间步的输出。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/94a8e0c600e14c91900fe9d2f916134e~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=869&h=561&s=53732&e=png&b=fffefe" alt="图片"></p><p><strong>编解码器的协同工作</strong></p><p>现在让我们看看编码器和解码器之间是如何协同工作的。编码器首先处理输入的文本token，然后输出一组注意力向量 K 和 V。这些向量将由每个解码器在其“编码器-解码器注意力”层中使用，这有助于解码器关注输入序列中的特定token的位置信息，具体计算注意力值的方法跟编码器中是一样的，<strong>需要注意的是，这里的K、V矩阵来自于编码器的输出，而Q矩阵来自于解码器的输入。</strong> <img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cb7c17840eec47bfbbe9ff960c9b0736~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=671&s=121710&e=png&b=fefcfc" alt="图片">重复回归以上的步骤，直到出现结束符号的标识，表示解码器已完成其输出。每个步骤的输出在下一个时间步骤中被反馈到底部解码器，并且解码器像编码器一样向上反馈其解码结果。就像我们对编码器输入所做的那样，我们将位置编码嵌入并添加到这些解码器输入中以指示每个单词的位置。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/94d20a1917514e9db702c64ffd4e9811~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=603&s=110156&e=png&b=fefcfc" alt="图片">至此，已经分析完Transformer的编码器和解码器的全流程了。</p><h2 id="七、Transformer-XL怎样提升上下文长度"><a href="#七、Transformer-XL怎样提升上下文长度" class="headerlink" title="七、Transformer-XL怎样提升上下文长度"></a><strong>七</strong>、<strong>Transformer-XL怎样提升上下文长度</strong></h2><p>传统的Transformer模型中，上下文长度是固定的，主要有以下几个原因：</p><ol><li><strong>计算效率：</strong> 在最初的设计中，Transformer模型是为了处理序列到序列的任务，如机器翻译。对于这类任务，输入序列（如源语言句子）和输出序列（如目标语言句子）通常具有相似的长度，因此固定上下文长度可以简化模型设计，提高计算效率。</li><li><strong>模型复杂度：</strong> Transformer模型的核心是自注意力机制，该机制在计算时需要对序列中的每个元素进行成对的比较，以计算注意力权重。如果上下文长度不固定，那么每次添加或删除元素时，都需要重新计算整个序列的注意力权重，这会导致计算复杂度和内存需求急剧增加。</li><li><strong>训练稳定性：</strong> 固定长度的上下文可以提供稳定的训练环境，有助于模型学习到更加一致和可靠的表示。如果上下文长度不固定，模型可能需要在每次迭代中适应新的序列长度，这可能会影响训练的稳定性和模型的收敛速度。</li><li><strong>硬件限制：</strong> 在实际应用中，硬件资源（如GPU内存）是有限的。固定长度的上下文可以确保模型在任何时候都不会超出硬件资源的限制，从而避免因资源不足而导致的训练中断。</li><li><strong>模型泛化：</strong> 固定长度的上下文允许模型在训练时学习到特定长度范围内的依赖关系，这有助于模型在实际应用中泛化到类似的序列长度上。</li></ol><p>然而，固定上下文长度也带来了一些限制，特别是在处理长序列时，模型无法捕获超过固定长度的依赖关系，这限制了模型在某些任务（如长文本生成和理解）上的性能。为了解决这个问题，Transformer-XL等模型通过引入新的机制来允许处理更长的上下文，从而在不牺牲计算效率的情况下捕获更长期的依赖关系。国产开源公司月之暗面的大模型产品kimi，能够处理长达20万字的超长上下文，那么他是怎么做到的呢，核心是他的模型在Transformer的基础上做了扩展，实现了自己的Transformer-XL架构。Transformer-XL通过引入两个关键的技术改进来提升token上下文长度的处理能力：片段递归机制（segment-level recurrence）和相对位置编码机制（relative positional encoding）。</p><ol><li><strong>片段递归机制：</strong> 在传统的Transformer模型中，由于上下文长度是固定的，模型无法捕获超过预定义上下文长度的长期依赖性。Transformer-XL通过引入循环机制来解决这个问题。具体来说，它不再从头开始计算每个新片段的隐藏状态，而是重复使用之前片段中获得的隐藏状态，并将这些状态作为当前片段的“记忆”。这样，信息就可以在不同片段之间传递，从而捕获更长的依赖关系。这种机制允许模型在不引起时间混乱的前提下，超越固定长度去学习依赖性，同时解决了上下文碎片化问题。</li><li><strong>相对位置编码机制：</strong> 在Transformer-XL中，为了能够在不造成时间混乱的情况下重复使用状态，引入了相对位置编码的概念。相对位置编码与传统的绝对位置编码不同，它只编码token之间的相对位置关系，而不是token与固定起始点的绝对位置。这种编码方式使得模型能够在处理长序列时更有效地利用位置信息，并且可以泛化至比在训练过程中观察到的长度更长的注意力长度。</li></ol><p>通过这两种机制，Transformer-XL显著提升了模型在处理长序列时的性能。</p><h2 id="八、Transformer相关应用分享"><a href="#八、Transformer相关应用分享" class="headerlink" title="八、Transformer相关应用分享"></a><strong>八</strong>、<strong>Transformer相关应用分享</strong></h2><p><strong>使用BERT做掩词填充</strong></p><p>BERT（Bidirectional Encoder Representations from Transformers）是一种预训练语言表示模型，由Google AI在2018年提出。BERT的核心创新在于利用Transformer架构的编码器部分来学习文本数据的深层次双向表示。这种表示能够捕捉到文本中词汇的上下文关系，从而在多种自然语言处理（NLP）任务中取得了显著的性能提升。以下是BERT模型的一些关键特点：<strong>双向上下文理解：</strong> 与之前的单向语言模型不同，BERT通过在预训练阶段使用掩码语言模型（Masked Language Model, MLM）任务，学习了词汇在句子中的双向上下文信息。这意味着模型能够同时考虑一个词前后的词汇来理解其含义。<strong>预训练和微调：</strong> BERT采用了两阶段的训练策略。在预训练阶段，BERT在大量文本数据上进行无监督学习，学习语言的通用模式。在微调阶段，BERT可以通过少量标注数据针对特定任务进行有监督学习，以适应各种NLP任务，如情感分析、问答系统、命名实体识别等。<strong>Transformer架构：</strong> BERT基于Transformer的编码器部分，这是一种注意力机制（Attention Mechanism）的架构，它允许模型在处理序列数据时考虑序列中所有位置的信息。<strong>大规模预训练：</strong> BERT在非常大的文本语料库上进行预训练，这使得模型能够学习到丰富的语言知识。预训练的规模和质量对模型性能有重要影响。<strong>多样化的任务适应性：</strong> 通过微调，BERT可以适应多种不同的NLP任务，而不需要对模型架构进行大的修改。这使得BERT成为了一个灵活且强大的工具。BERT的推出标志着NLP领域的一个重大进展，它在多项NLP任务上刷新了记录，并催生了一系列基于BERT的改进模型，如RoBERTa、ALBERT、DistilBERT等。这些模型在不同的方面对BERT进行了优化，以提高性能、减少计算资源消耗或改善特定任务的表现。以下是使用BERT做掩词填充的示例，输入一段文本，让模型预测出下一个被掩盖的词：<a href="https://link.juejin.cn/?target=https://huggingface.co/google-bert/bert-base-uncased!%5B%E5%9B%BE%E7%89%87">huggingface.co&#x2F;google-bert…</a>](<a href="https://link.juejin.cn/?target=https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5872dfd6621145abbcd888a90d28f7e4~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image%23?w=755&h=477&s=42042&e=png&b=ffffff">p3-juejin.byteimg.com&#x2F;tos-cn-i-k3…</a>)</p><p><strong>使用BART做文本摘要</strong></p><p>BART（Bidirectional and Auto-Regressive Transformers）是一种先进的自然语言处理（NLP）模型，它结合了BERT（Bidirectional Encoder Representations from Transformers）和GPT（Generative Pre-trained Transformer）的特点，用于文本理解和生成任务。BART模型特别擅长处理不同类型的文本噪声和序列变换，使其在多种NLP任务中表现出色。<strong>设计原理和结构</strong></p><p>BART是基于Transformer架构的自编码自回归模型。它通过两个主要步骤进行预训练：</p><ol><li>使用任意噪声函数破坏文本（例如，随机打乱句子顺序、删除或遮蔽token）。</li><li>模型学习重建原始文本。</li></ol><p>这种预训练方式使得BART能够有效地处理文本生成、翻译和理解等任务。BART的编码器是双向的，能够捕捉文本的前后文信息，而解码器是自回归的，能够基于前面的输出生成后续的内容。<strong>应用</strong>BART在多种NLP任务上取得了显著的成绩，包括但不限于：</p><ul><li>文本摘要</li><li>机器翻译</li><li>对话生成</li><li>问答系统</li><li>文本分类</li></ul><p><strong>与其他模型的对比</strong>与其他预训练模型相比，BART在处理文本生成任务时尤其出色。它在自然语言理解任务中也有很好的表现，与BERT和GPT等模型相比，BART在多个基准数据集上取得了竞争性或更好的结果。<strong>预训练和微调</strong>BART模型通过大量的文本数据进行预训练，然后在特定任务上进行微调。预训练阶段，模型学习如何从噪声文本中恢复原始文本，而微调阶段则是针对特定任务调整模型参数，以优化任务性能。以下是使用BART做文本摘要的应用示例：<a href="https://link.juejin.cn/?target=https://huggingface.co/facebook/bart-large-cnn!%5B%E5%9B%BE%E7%89%87">huggingface.co&#x2F;facebook&#x2F;ba…</a>](<a href="https://link.juejin.cn/?target=https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6ed7a1c38b024c40814d3f6e3a658338~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image%23?w=708&h=615&s=111417&e=png&b=fefefe">p3-juejin.byteimg.com&#x2F;tos-cn-i-k3…</a>)</p><p><strong>使用DistilBERT做问答</strong></p><p>DistilBERT是一种轻量级的BERT模型，它通过知识蒸馏（knowledge distillation）技术从预训练的BERT模型中学习知识。这种方法的核心思想是使用一个较小的BERT模型作为“学生”模型，而原始的、较大的BERT模型则充当“教师”模型。在训练过程中，学生模型尝试复制教师模型的输出，以此来学习教师模型的知识。<strong>主要特点和优势</strong> <strong>模型大小和效率：</strong> DistilBERT的模型大小和参数量都比原始的BERT模型小，这使得它在资源受限的环境中（如移动设备）更加实用。它的推理速度也比BERT快，因为它需要处理的参数更少。<strong>知识蒸馏：</strong> DistilBERT使用了一种称为“软目标”的知识蒸馏方法。在这种方法中，学生模型不仅学习来自训练数据的标签，还学习教师模型的输出，这些输出被视为附加的、软性的标签。<strong>保持性能：</strong> 尽管DistilBERT的模型大小减小了，但它仍然保持了与原始BERT模型相当的性能，特别是在自然语言理解任务上。<strong>灵活性：</strong> DistilBERT保留了BERT模型的基本架构，包括Transformer的串联层，这使得它可以很容易地适应各种下游任务。<strong>结构和训练</strong>DistilBERT的结构相对简单，它仅保留了BERT的6层Transformer，删除了token type embedding和pooler层。在训练过程中，它使用了一种称为“模型压缩”的技术，通过这种方法，模型的层数被减半，同时从教师模型的层初始化学生模型的层。<strong>应用场景</strong>由于其较小的模型大小和较快的推理速度，DistilBERT适用于需要快速处理和低资源消耗的NLP任务，例如文本分类、情感分析、问答系统和语言模型等。总的来说，DistilBERT是一个高效的BERT变体，它通过知识蒸馏技术实现了模型的压缩，同时保持了良好的性能，特别适合在资源受限的环境中使用。以下是是使用DistilBERT做问答的实例：<a href="https://link.juejin.cn/?target=https://huggingface.co/distilbert/distilbert-base-uncased-distilled-squad!%5B%E5%9B%BE%E7%89%87">huggingface.co&#x2F;distilbert&#x2F;…</a>](<a href="https://link.juejin.cn/?target=https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/03d3a52d36404160aaa932cf8bee79b6~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image%23?w=657&h=627&s=119134&e=png&b=fdfdfd">p3-juejin.byteimg.com&#x2F;tos-cn-i-k3…</a>)</p><p><strong>使用T5做文本翻译</strong></p><p>T5模型，全称为“Text-to-Text Transfer Transformer”，是由Google Research团队开发的一种自然语言处理（NLP）模型。T5模型的核心思想是将所有NLP任务统一转换为文本到文本（Text-to-Text）的格式，从而可以使用同一个模型和训练过程来处理多种不同的任务，如翻译、摘要、问答等。<strong>主要特点和优势</strong> <strong>统一的框架：</strong> T5模型通过将任务转换为文本到文本的格式，简化了不同NLP任务的处理方式。例如，对于翻译任务，输入可以是“translate English to German: [English text]”，输出则是翻译后的文本。基于Transformer架构：T5模型采用了Transformer的encoder-decoder架构，这是一种高效的网络结构，特别适合处理序列数据。<strong>预训练和微调：</strong> T5模型首先在大规模的数据集上进行预训练，学习语言的通用表示，然后可以针对特定任务进行微调，以优化任务性能。<strong>广泛的应用场景：</strong> T5模型可以应用于多种NLP任务，包括但不限于文本分类、命名实体识别、情感分析、机器翻译和对话生成等。<strong>高效的计算能力：</strong> T5模型的设计允许它高效地处理大规模数据集，并且具有强大的并行处理能力。<strong>训练和应用</strong>T5模型在训练时使用了一种称为“C4”的大规模数据集，这个数据集由经过清洗的Common Crawl数据组成。模型通过不同的预训练目标和策略进行训练，包括自回归、自编码和文本重排等。在应用方面，T5模型的强大语言表示能力和广泛的应用场景使其成为NLP领域的一个重要工具。它可以通过微调来适应不同的领域和任务，从而在多个NLP任务上取得优异的性能。T5模型通过其创新的Text-to-Text框架和基于Transformer的架构，在自然语言处理领域提供了一种新的解决方案，能够处理多种复杂的语言任务，并且具有很好的扩展性和适应性。以下是使用T5做文本翻译的示例：<a href="https://link.juejin.cn/?target=https://huggingface.co/google-t5/t5-base!%5B%E5%9B%BE%E7%89%87">huggingface.co&#x2F;google-t5&#x2F;t…</a>](<a href="https://link.juejin.cn/?target=https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4b35f058ef3646969c0ba292300f0ebb~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image%23?w=666&h=451&s=33125&e=png&b=ffffff">p3-juejin.byteimg.com&#x2F;tos-cn-i-k3…</a>)</p><p><strong>使用GPT-2写小说</strong></p><p>GPT-2（Generative Pre-trained Transformer 2）是由OpenAI开发的自然语言处理（NLP）模型，它是GPT系列模型的第二代。GPT-2在自然语言理解和生成方面表现出色，能够生成连贯、相关且多样化的文本。这个模型在发布时因其生成文本的质量和多样性而受到广泛关注。<strong>主要特点和优势</strong> <strong>大规模预训练：</strong> GPT-2通过在大规模的互联网文本数据集上进行预训练，学习到了丰富的语言模式和知识。这种预训练使得模型能够理解和生成自然语言文本。<strong>Transformer架构：</strong> GPT-2基于Transformer模型架构，这是一种依赖于自注意力（self-attention）机制的深度学习架构，非常适合处理序列数据，如文本。<strong>无监督学习：</strong> GPT-2采用无监督学习方法，通过预测下一个词的任务来预训练模型。这种训练方式不依赖于标注数据，使得模型能够学习到更广泛的语言知识。<strong>生成能力：</strong> GPT-2特别擅长文本生成任务，能够生成连贯、有逻辑的段落和文章，甚至能够模仿特定的写作风格。<strong>多样性：</strong> GPT-2能够处理多种语言任务，包括文本生成、翻译、问答、摘要等。<strong>版本和规模</strong>GPT-2有多个版本，不同版本之间主要区别在于模型的大小和参数数量。例如，最小的版本有1.17亿个参数，而最大的版本（GPT-2 1.5 Billion）有15亿个参数。随着模型规模的增加，性能和生成文本的质量也相应提高。<strong>应用场景</strong>GPT-2可以应用于多种场景，如聊天机器人、文本摘要、内容创作辅助、语言翻译等。它的生成能力使得在创意写作、新闻生成和其他需要自然语言生成的领域中具有潜在的应用价值。<strong>挑战和限制</strong>尽管GPT-2在生成文本方面表现出色，但它也面临一些挑战和限制，包括生成文本的偏见问题、事实准确性问题以及潜在的滥用风险。因此，OpenAI在发布GPT-2时采取了谨慎的态度，逐步放开对模型的访问权限。总的来说，GPT-2是一个强大的NLP模型，它在文本生成和理解方面的能力使其成为自然语言处理领域的一个重要里程碑。以下是使用GPT-2做文本生成的示例：<a href="https://link.juejin.cn/?target=https://huggingface.co/openai-community/gpt2!%5B%E5%9B%BE%E7%89%87">huggingface.co&#x2F;openai-comm…</a>](<a href="https://link.juejin.cn/?target=https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/05b480b976be4351a9aee2ddf51a6a75~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image%23?w=688&h=391&s=39014&e=png&b=ffffff">p3-juejin.byteimg.com&#x2F;tos-cn-i-k3…</a>%E5%AE%8C%E6%95%B4%E7%9A%84%E4%BD%93%E9%AA%8C%E5%9C%B0%E5%9D%80%EF%BC%9Ahttps%3A%2F%2Ftransformer.huggingface.co%2Fdoc%2Fgpt2-large%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E8%BE%93%E5%85%A5%E4%B8%80%E6%AE%B5%E5%B0%8F%E8%AF%B4%E7%9A%84%E5%BC%80%E5%A4%B4%EF%BC%8C%E6%AF%94%E5%A6%82%EF%BC%9AAs) aliens entered our planet，然后Transformer就会依据我们输入的文本，自动脑补剩下的小说情节。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1d3275388f85411382c53e30e252401c~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=655&s=159877&e=png&b=fefefe" alt="图片">那Transformer是怎么做到的呢？如下图所示，Transformer在生成每一个token时，会参考前面所有的token，并生成与之相符的token，这样循环往复就能生成完整的一段内容。<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6b73860b769a4d43bfa7ebff36d232fb~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=336&s=39118&e=png" alt="图片"></p><h2 id="九、参考文档"><a href="#九、参考文档" class="headerlink" title="九、参考文档"></a><strong>九</strong>、<strong>参考文档</strong></h2><p><a href="https://link.juejin.cn/?target=https://arxiv.org/pdf/1706.03762.pdfhttps://jalammar.github.io/illustrated-transformer/https://www.bilibili.com/video/BV1ih4y1J7rx">arxiv.org&#x2F;pdf&#x2F;1706.03…</a></p><p>*<strong>文&#x2F;</strong> 逅弈</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;深入理解Transformer&quot;&gt;&lt;a href=&quot;#深入理解Transformer&quot; class=&quot;headerlink&quot; title=&quot;深入理解Transformer&quot;&gt;&lt;/a&gt;深入理解Transformer&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;作者：得物</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="深度学习" scheme="http://ai.mak.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Transformer 总结</title>
    <link href="http://ai.mak.cn/2024/05/02/ai/Transformer%20%E6%80%BB%E7%BB%93/"/>
    <id>http://ai.mak.cn/2024/05/02/ai/Transformer%20%E6%80%BB%E7%BB%93/</id>
    <published>2024-05-01T16:00:00.000Z</published>
    <updated>2024-12-17T09:39:51.434Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Transformer-总结"><a href="#Transformer-总结" class="headerlink" title="Transformer 总结"></a>Transformer 总结</h1><p>在大模型发展历程中，有两个比较重要点：第一，Transformer 架构。它是模型的底座，但 Transformer 不等于大模型，但大模型的架构可以基于 Transformer；第二，GPT。严格意义上讲，GPT 可能不算是一个模型，更像是一种预训练范式，它本身模型架构是基于 Transformer，但 GPT 引入了“预测下一个词”的任务，即不断通过前文内容预测下一个词。之后，在大量的数据上进行学习才达到大模型的效果。</p><p>之所以说 Transformer 架构好，是因为 Transformer 能够解决之前自然语言处理中最常用的 RNN 的一些核心缺陷，具体来看：一是，难以并行化，反向传播过程中需要计算整个序列；二是，长时依赖关系建模能力不够强；三是，模型规模难以扩大。</p><p>那么，Transformer 具体是如何工作的？</p><p>首先，是对输入进行标识符化，基于单词形式，或字母，或字符子串，将输入文本切分成几个 token，对应到字典中的 ID 上，并对每个 ID 分配一个可学习的权重作为向量表示，之后就可以针对做训练，这是一个可学习的权重。</p><p>在输入 Transformer 结构之后，其核心的有自注意力模块和前向传播层。而在自注意力模块中，Transformer 自注意力机制建模能力优于 RNN 序列建模能力。因此，有了 Transformer 架构后，基本上就解决了运行效率和训练很大模型的问题。</p><p>基于 Transformer 架构的主流语言大模型主要有以下几种：</p><p>一是，自编码模型，如 BERT，简单讲就是给到一句话，然后把这句话的内容挖空，当问及挖空的内容时，就把内容填回去，这其实是典型地用来做一个自然语言理解的任务，但做生成任务是非常弱的；</p><p>二是，自回归模型，如 GPT，它是通过不断地预测下一个词，特点是只能从左到右生成，而看不到后面的内容。GPT-1 最后接了一个 Linear 层做分类或选题题等任务，到了 GPT-2 ，已经将一些选择任务或者分类任务全部都变成文本任务，统一了生成的范式；</p><p>三是，编码器-解码器模型，如 T5，它的输入和输出是分为比较明显的两块内容，或者是问答式，或者序列到序列的转换型的任务；</p><p>四是，通用语言模型，如 GLM，该模型结合了自回归和自编码两种形式的模型，举个例子，“123456”是一串输入的序列，现在把 “3”、“5”、“6” 挖空，让模型去学习，那么，挖空以后换成一个 “ mask token” 告诉模型这个地方遮掉了一些内容，现在需要去预测出来遮掉的内容。</p><p>与 BERT 不同的是，GLM 把自回归和自编码方式进行结合后，挖出来的内容直接拼到了文本的后面，然后加上一个 “ start token”，告诉模型现在是开始生成了，开始做填空任务了，然后把标准答案 “5”、“6” 放在 “ star token”后面让它去预测，直到预测到 “end token”，它就知道这个填空已经结束了。这个过程称为自回归填空式的任务，整个计算流程还是自回归式，但它不断预测下一个词，既实现了填空的功能，又能看到上下文内容。此外，相比于 GPT 模型，GLM 采用了一个双向注意力的机制。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Transformer-总结&quot;&gt;&lt;a href=&quot;#Transformer-总结&quot; class=&quot;headerlink&quot; title=&quot;Transformer 总结&quot;&gt;&lt;/a&gt;Transformer 总结&lt;/h1&gt;&lt;p&gt;在大模型发展历程中，有两个比较重要点：第一，</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="深度学习" scheme="http://ai.mak.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>前端组件汇总</title>
    <link href="http://ai.mak.cn/2024/04/27/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF%E7%BB%84%E4%BB%B6%E6%B1%87%E6%80%BB/"/>
    <id>http://ai.mak.cn/2024/04/27/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF%E7%BB%84%E4%BB%B6%E6%B1%87%E6%80%BB/</id>
    <published>2024-04-26T16:00:00.000Z</published>
    <updated>2024-12-17T09:29:25.247Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前端组件汇总"><a href="#前端组件汇总" class="headerlink" title="前端组件汇总"></a>前端组件汇总</h1><h2 id="菜单"><a href="#菜单" class="headerlink" title="菜单"></a>菜单</h2><ul><li><a href="https://github.com/zeratulmdq/vue-accordion">vue-accordion</a>-适用于 Vue.js 的简单手风琴导航菜单组件。</li><li><a href="https://github.com/euvl/vue-js-dropdown">vue-js-dropdown</a>-Vue.js 2 下拉菜单组件。轻巧，易于使用和扩展，无外部缺陷。</li><li><a href="https://github.com/vouill/vue-slideout">vue-slideout</a>-流行的库[slideout]的 Vue 实现(<a href="https://github.com/Mango/slideout">https://github.com/Mango/slideout</a>)</li><li><a href="https://github.com/AshleyLv/vue-quick-menu">vue-quick-menu</a>-这是基于 vue.js2 的 Web 导航组件。</li><li><a href="https://github.com/michitaro/vue-menu">@ hscmap &#x2F; vue-menu</a>-vue2 的菜单&#x2F;上下文菜单组件。</li><li><a href="https://github.com/classicalcondition/vue-router-nav">vue-router-nav</a>-简约的响应式导航栏，呈现 vue-router 的路线。</li><li><a href="https://github.com/hjl19911127/vue-drawer-layout">vue-drawer-layout</a>-一个简单的 DrawerLayout 组件(例如 Android)具有 Vue.js。</li><li><a href="https://github.com/RGRU/vue-simple-menu">vue-simple-menu</a>-具有一组基本功能的简单菜单组件，在 80％的情况下足够</li><li><a href="https://github.com/MisRob/vue-tree-navigation">vue-tree-navigation</a>-具有 vue-router 支持的 Vue.js 2 树导航</li><li><a href="https://github.com/borisbutenko/bp-vuejs-dropdown">bp-vuejs-dropdown</a>-Vuejs &#x3D;&gt; 2 下拉菜单。易于使用，无需外部，可选。</li><li><a href="https://github.com/Lunrtick/vue-bulma-accordion">vue-bulma-accordion</a>-简单，易于配置的手风琴或具有 Bulma 自定义样式的可折叠样式或内置的可用图标</li><li><a href="https://github.com/TerryZ/v-selectmenu">v-selectmenu</a>-针对 Vue2 的简单，容易和高度定制的菜单解决方案。</li><li><a href="https://github.com/mbj36/vue-burger-menu">vue-burger-menu</a>-具有不同 CSS 动画的画布外边栏 Menu 组件。</li><li><a href="https://github.com/JonathanDn/vue-dropdown">vue-dynamic-dropdown</a>-一个高度可定制的，易于使用的优雅下拉组件</li><li><a href="https://github.com/johndatserakis/vue-navigation-bar">vue-navigation-bar</a>-适用于您的 Vue 项目的简单，漂亮的导航栏。</li><li><a href="https://github.com/romainsimon/vue-simple-search-dropdown">vue-simple-search-dropdown</a>-一个没有外部依赖关系的简单可搜索输入下拉组件</li><li><a href="https://github.com/Innologica/vue-dropdown-menu">@ innologica &#x2F; vue-dropdown-menu</a>-Vue 的下拉菜单组件。任何元素都可以是下拉触发器，任何内容都可以下拉内容。</li><li><a href="https://github.com/Dimon24021993/vue-menu-aim">vue-menu-aim</a>-菜单三角形选择，又名亚马逊</li></ul><h2 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h2><ul><li><a href="https://github.com/manju16832003/v-minusplusinput">minus-plus-input</a>-带正负号的数字输入；包含在 Vue.js v1 和 v2 中。</li><li><a href="https://github.com/Keiwen/vue-integer-plusminus">vue-integer-plusminus</a>-带有 vue 2 增量和减量按钮的整数输入。</li><li><a href="https://github.com/JayeshLab/vue-numeric-input">vue-numeric-input</a>-带有控件的数字输入组件。</li><li><a href="https://github.com/Seokky/vue-number-smarty">vue-number-smarty</a>-数字输入可以在聚焦字段时更改滚动值。</li><li><a href="https://github.com/Seokky/vuetify-number-smarty">vuetify-number-smarty</a>-数字输入可在字段聚焦时更改滚动值(Vuetify.js 实现)。</li></ul><h2 id="轮播"><a href="#轮播" class="headerlink" title="轮播"></a>轮播</h2><ul><li><a href="https://github.com/shhdgit/vue-easy-slider">vue-easy-slider</a>-Vue.js 的滑块组件。</li><li><a href="https://github.com/lsycxyj/vue-l-carousel">vue-l-carousel</a>-Vue.js v2.x +的响应式轮播(即滑块或滑动)组件。</li><li><a href="https://github.com/surmon-china/vue-awesome-swiper">vue-awesome-swiper</a>-Vue.js(1.x〜2.x)的 Swiper(slide)组件。</li><li><a href="https://github.com/vue-bulma/lory">vue-lory</a>-基于 lory 的 Vue 滑块组件。</li><li><a href="https://github.com/staskjs/vue-slick">vue-slick</a>-Slick-carousel 的 Vue 组件。</li><li><a href="https://github.com/drewjbartlett/vue-flickity">vue-flickity</a>-Flickity.js 的 Vue 组件。</li><li><a href="https://github.com/wlada/vue-carousel-3d">vue-carousel-3d</a>-Vue Carousel 3D-Vue.js 美观，灵活且受触摸支持的 3D Carousel。</li><li><a href="https://github.com/SSENSE/vue-carousel">vue-carousel</a>-适用于 Vue.js 的灵活，响应迅速，触摸友好的轮播。</li><li><a href="https://github.com/OrangeXC/vue-coverflow">vue-coverflow</a>-vue2.x Coverflow 组件。</li><li><a href="https://github.com/lukaszflorczak/vue-agile">vue-agile</a>–受 Slick 启发的轮播组件，仅以 Vue.js 和 Vanilla JS 编写。</li><li><a href="https://github.com/viktorlarsson/vue-tiny-slider">vue-tiny-slider</a>–由 ganlanyuan 创建的轮播组件，用 Vue.js 编写。没有 jQuery。适用于 IE8 +。</li><li><a href="https://github.com/mubaidr/vue-swimlane">vue2-text-swimlane</a>-用于 Vue.js 的 Text Swimlane 插件</li><li><a href="https://github.com/rap2hpoutre/vue-picture-swipe">vue-picture-swipe</a>-Vue Picture Swipe Gallery(具有缩略图，延迟加载和轻扫的图像画廊)由 photowipe 支持。</li><li><a href="https://github.com/sainf/vue2-siema">vue2-siema</a>-非常小的 Siema 转盘&#x2F;滑块库的插件包装。</li><li><a href="https://github.com/deulos/vue-flux">vue-flux</a>-带有 20 个炫酷过渡的图片滑块。</li><li><a href="https://github.com/antonreshetov/vue-glide">vue-glide</a>- [Glide.js]上方的 Vue 滑块和轮播组件(<a href="https://github.com/glidejs/glide">https://github.com/glidejs/glide</a>)</li><li><a href="https://github.com/s950329/vue-owl-carousel">vue-owl-carousel</a>- [Owl Carousel 2]的 Vue 组件(<a href="https://owlcarousel2.github.io/OwlCarousel2/">https://owlcarousel2.github.io/OwlCarousel2/</a>)</li><li><a href="https://github.com/antoniandre/vueper-slides">vueper-slides</a>-适用于 Vue JS 的易于触摸且响应迅速的幻灯片&#x2F;轮播。</li><li><a href="https://github.com/loo41/vuc">vue-canvas-carousel</a>- [vuc-carousel]的 Vue 画布组件(<a href="http://vuc.tianchenyong.top/#/carousel">http://vuc.tianchenyong.top/#/carousel</a>)</li><li><a href="https://github.com/baianat/hooper">胡珀</a>-针对 Vue 优化的可自定义的可访问轮播滑块</li><li><a href="https://github.com/ChristophAnastasiades/Lingallery">语言</a>-Vue 的简单图像库组件，在下面显示带有缩略图的大图像</li><li><a href="https://github.com/dreambo8563/vue-piece-slider">vue-piece-slider</a>-动画幻灯片的碎片化外观</li><li><a href="https://github.com/leepyng/vue2-photo-carousel">vue2-photo-carousel</a>-Vue2 的照片轮播组件</li></ul><h2 id="图表"><a href="#图表" class="headerlink" title="图表"></a>图表</h2><ul><li><a href="https://github.com/bbonnin/vue-morris">vue-morris</a>-VueJS 组件包装了 Morris.js。</li><li><a href="https://github.com/haydenbbickerton/vue-charts">vue-charts</a>-适用于 Vue.js 的 Google Charts 插件。</li><li><a href="https://github.com/apertureless/vue-chartjs">vue-chartjs</a>-Chart.js 的 Vue.js 包装器。</li><li><a href="https://github.com/hchstera/vue-charts">hchs-vue-charts</a>-基于 ChartJs 的 Vue2.0 包装器。</li><li><a href="https://github.com/Justineo/vue-echarts">vue-echarts</a>-Vue.js 的 ECharts 组件。</li><li><a href="https://github.com/QingWei-Li/vue-trend">vuetrend</a>-Vue.js 的简洁优雅火花线。</li><li><a href="https://github.com/weizhenye/vue-highcharts">vue-highcharts</a>-Vue 的 Highcharts 组件。</li><li><a href="https://github.com/xlsdg/vue-echarts-v3">vue-echarts-v3</a>-ECharts.js(v3.x +)的 Vue.js(v2.x +)组件包装。</li><li><a href="https://github.com/lakb248/vue-chartist">vue-chartist</a>-Chartist 的 Vue.js 2.0 组件包装。</li><li><a href="https://github.com/fireyy/g2-vue">g2-vue</a>-用于在 Vue 组件中轻松使用 G2 的工厂包装。</li><li><a href="https://github.com/DeviaVir/vue-bar">vuebars</a>-适用于 Vue.js 的简洁优雅的火花棒。</li><li><a href="https://github.com/emiliorizzo/vue-d3-network">vue-d3-network</a>-使用 d3-force 绘制网络图形的 Vue 组件</li><li><a href="https://github.com/alexcode/vue2vis">vue2vis</a>- <a href="http://visjs.org/">Visjs</a>的 Vue2 包装器。</li><li><a href="https://github.com/chryb/vue-c3">vue-c3</a>-用于 c3 图表的可重用 vue 组件</li><li><a href="https://github.com/d2bjs/vue-d2b">vue-d2b</a>-d2b 图表的 Vue 组件。(包括轴，饼图，sankey 和森伯斯特图)</li><li><a href="https://github.com/SeregPie/VueChart">VueChart</a>-一个非常简单的 Chart Vue 包装器。</li><li><a href="https://github.com/ankane/vue-chartkick">vue-chartkick</a>-用一行 Vue 创建漂亮的 JavaScript 图表</li><li><a href="https://github.com/ignoreintuition/d3vue">d3vue</a>-用于在 VueJS 中创建反应性数据可视化的 D3 插件</li><li><a href="https://github.com/JustSteveKing/vue2-frappe">vue2-frappe</a>-VueJS 的 Frappe Charts 的简单包装</li><li><a href="https://github.com/devstark-com/vue-google-charts">vue-google-charts</a>-Google Charts lib 的反应性 Vue.js 包装器</li><li><a href="https://github.com/juijs/vue-graph">vue-graph</a>-数据可视化库，用于 Vue.js 中的仪表板实现</li><li><a href="https://github.com/David-Desmaisons/Vue.D3.sunburst">vue.d3.sunburst</a>-基于 D3.js 的反应性旭日形组件</li><li><a href="https://github.com/ignoreintuition/v-chart-plugin">v-chart-plugin</a>-一个可定制的组件，用于添加绑定到组件数据的 D3 图表。</li><li><a href="https://github.com/jqwidgets/vue/tree/master/chart">vue-jqxchart</a>-具有饼图，气泡，甜甜圈，线，条，栏，面积，瀑布，极地和蜘蛛系列的制图组件。</li><li><a href="https://github.com/nhnent/toast-ui.vue-chart">toast-ui.vue-chart</a>- [TOAST UI 图表]的 Vue 包装器(<a href="http://ui.toast.com/tui">http://ui.toast.com/tui</a> -图表&#x2F;)。</li><li><a href="https://github.com/apexcharts/vue-apexcharts">vue-apexcharts</a>- [ApexCharts]的 Vue.js 组件(<a href="https://github.com/apexcharts/apexcharts.js)%E3%80%82">https://github.com/apexcharts/apexcharts.js)。</a></li><li><a href="https://github.com/mazipan/vue-doughnut-chart">vue-doughnut-chart</a>-Vue.js 的甜甜圈图组件。</li><li><a href="https://github.com/ElemeFE/v-charts">v-charts</a>-基于 Vue2.x 和 Echarts 的图表组件。</li><li><a href="https://github.com/dumptyd/vue-css-donut-chart">vue-css-donut-chart</a>-用于绘制纯 CSS 甜甜圈图的轻量级 Vue 组件。</li><li><a href="https://github.com/dmtrbrl/vue-trend-chart">vue-trend-chart</a>-Vue.js 的简单趋势图</li><li><a href="https://github.com/keller-mark/vueplotlib">vueplotlib</a>-声明性，交互式，链接的绘图组件</li><li><a href="https://github.com/amroessam/vgauge">vgauge</a>-GaugeJS 的 Vue 包装器-创建漂亮的量规</li><li><a href="https://github.com/David-Desmaisons/vue-plotly">vue-plotly</a>- <a href="https://plot.ly/javascript/">plotly.js</a>声明性图表库的包装，随附 20 图表类型，包括 3D 图表，统计图和 SVG 地图。</li><li><a href="https://github.com/greghub/vue-funnel-graph-js">vue-funnel-graph-js</a>-Vue.js 的漏斗图绘制库。创建垂直和水平动画 SVG 漏斗图，并添加标签，值，图例和其他信息。</li><li><a href="https://github.com/djaxho/pure-vue-chart">pure-vue-chart</a>-在没有任何图表库相关性的情况下实现的轻量级 vue 图表</li></ul><h2 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h2><ul><li><a href="https://github.com/egoist/vue-timeago">vue-timeago</a>-Vue 的一个很小的 timeago 组件。</li><li><a href="https://github.com/saman/vue-moment-jalaali">vue-moment-jalaali</a>-针对您的 Vue.js 项目的 Jalaali Moment.js 过滤器。</li><li><a href="https://github.com/sagarkbhatt/vuejs-countdown-timer">vue-countdown-timer</a>-添加了时区转换支持。</li><li><a href="https://github.com/f/vue-analog-clock-range">vue-analog-clock-range</a>-显示时差的模拟时钟范围。</li><li><a href="https://github.com/julon/vue-moment-lib">vue-moment-lib</a>-使用相同的 momentjs API 的简单 Vue.js 2.0 MomentJS 库(过滤器和全局变量)。</li><li><a href="https://github.com/getanwar/vuejs-countdown">vuejs-countdown</a>-适用于 vue js 2.0 的简单倒数计时器组件</li><li><a href="https://github.com/philipjkim/vue2-flip-countdown">vue2-flip-countdown</a>-Vue 2.x 具有倒转效果的倒数计时器</li><li><a href="https://github.com/pablosirera/timeline-vuejs">timeline-vuejs</a>-Vue 的简约时间表</li><li><a href="https://github.com/mlinquan/vue-awesome-countdown">vue-awesome-countdown</a>-Vue 2.5.0+具有高性能和高精度的倒计时插件。官方网站：<a href="https://vac.js.org/">https://vac.js.org</a></li><li><a href="https://github.com/bestvist/vue-clock2">vue-clock2</a>-显示 Vue 的时钟组件。</li><li><a href="https://github.com/P3trur0/vuemodoro">vuemodoro</a>-Pomodoro 计时器作为单个文件 Vue 组件。</li></ul><h2 id="日历"><a href="#日历" class="headerlink" title="日历"></a>日历</h2><ul><li><a href="https://github.com/Wanderxx/vue-fullcalendar">vue-fullcalendar</a>-Vue 日历 fullCalendar。无需 jQuery。安排事件管理。</li><li><a href="https://github.com/GeoffZhu/vue-event-calendar">vue-event-calendar</a>-Vue2 的简单事件日历，除 Vue2 外没有其他依赖项。</li><li><a href="https://github.com/FranckFreiburger/vue-calendar-picker">vue-calendar-picker</a>-用于事件显示，时段选择和日期选择器的轻量级日历组件。</li><li><a href="https://github.com/KimWooHyun/vue-lunar-calendar">vue-lunar-calendar</a>-农历的 vue 组件。使用 Moment.js 进行日期操作。</li><li><a href="https://github.com/richardtallent/vue-simple-calendar">vue-simple-calendar</a>-基于 Flexbox 的 Vue 月历功能；支持多日活动，本地化，节日表情符号，拖放。没有依赖关系。</li><li><a href="https://github.com/Trekels/vue2-calendar">vue2-calendar</a>-一个简单的完整日历组件，旨在灵活而轻巧。</li><li><a href="https://github.com/tuhe32/vue-jLunar-datePicker">vue-jlunar-datepicker</a>-具有节日和节气的中国农历日期选择器组件。</li><li><a href="https://github.com/CroudSupport/vue-fullcalendar">vue-full-calendar</a>-Vue 1 和 2 的完整<a href="https://fullcalendar.io/">fullcalendar.io</a>包装器</li><li><a href="https://github.com/nathanreyes/v-calendar">v-calendar</a>-动画日历&#x2F;日期选择器，显示简单和重复日期的区域，指标和日弹出窗口。</li><li><a href="https://github.com/laleshii/vue-infinite-calendar">vue-infinite-calendar</a>-Vue 2 的简单无限日历实现</li><li><a href="https://github.com/kylin-z/vue-calendar">vue-calendar</a>-适用于 Vue 2.1.5+的简单日历组件，支持自定义内容。没有依赖关系。</li><li><a href="https://github.com/kitwon/vue2-event-calendar">vue2-event-calendar</a>-Vue2 的事件日历，支持自定义事件项和日历标题。</li><li><a href="https://github.com/leepyng/vue-datepicker-infinite">vue2-datePicker-infinite</a>-Vue2 的无限 datePicker，易于使用且没有依赖性。</li><li><a href="https://github.com/icai/vue2-calendar">vue2-slot-calendar</a>-vue 2 日历，支持月球或日期事件的日期选择器组件，引导程序样式。</li><li><a href="https://github.com/stormseed/quasar-calendar">quasar-calendar</a>-使用 Quasar 框架的 vue.js 日历，可实现每月，多天和议程视图。</li><li><a href="https://github.com/mengxiong10/vue2-datepicker">vue2-datepicker</a>-Vue2 的漂亮 datepicker &#x2F; datetimepicker 组件</li><li><a href="https://github.com/enrian/vue-pikaday">vue-pikaday</a>- <a href="https://github.com/dbushell/Pikaday">Pikaday</a>datepicker 的 VueJS 包装器组件</li><li><a href="https://github.com/lkmadushan/vue-tuicalendar">vue-tuicalendar</a>- <a href="https://github.com/nhnent/tui.calendar">tui.calendar</a>日历的 VueJS 包装器组件</li><li><a href="https://github.com/jqwidgets/vue/tree/master/scheduler">vue-jqxscheduler</a>-VueJS Scheduler 组件。</li><li><a href="https://github.com/nhnent/toast-ui.vue-calendar">toast-ui.vue-calendar</a>- [TOAST UI 日历]的 Vue 包装器(<a href="http://ui.toast.com/tui">http://ui.toast.com/tui</a> -日历)。</li><li><a href="https://github.com/ManukMinasyan/vue-functional-calendar">vue-functional-calendar</a>-基于 Vue 的轻量级高性能日历组件(日期选择器，日期范围)。</li><li><a href="https://github.com/antoniandre/vue-cal">vue-cal</a>-Vue JS 完整日历，无依赖项，无 BS。🤘。</li><li><a href="https://github.com/liloow/vue-draggableCal">vue-draggableCal</a>-不是普通的日期选择器。一个 Vuejs 可拖动的日期选择器，具有全新的响应式设计，可移动使用且具有 0 个依赖项，已压缩 17kb</li><li><a href="https://github.com/nono1526/vue-material-year-calendar">vue-material-year-calendar</a>-Vue2 的全年(每页 12 个月)日历。使用 dayjs。</li><li><a href="https://github.com/codesthq/vuelendar">vuelendar</a>-用 VueJS 编写的简洁日历</li></ul><h2 id="地图"><a href="#地图" class="headerlink" title="地图"></a>地图</h2><ul><li><a href="https://github.com/xkjyeah/vue-google-maps">vue2-google-maps</a>-Google Maps 组件，用于带有 2 向数据绑定的 vue。</li><li><a href="https://github.com/KoRiGaN/Vue2Leaflet">vue2-leaflet</a>-传单地图的 Vue 2 组件。</li><li><a href="https://github.com/phegman/vue-mapbox-gl">vue-mapbox-gl</a>-Mapbox GL JS 的 Vue 2.x 组件</li><li><a href="https://github.com/PNKBizz/vue-yandex-map">vue-yandex-maps</a>-Yandex Maps 的 Vue 2.x 组件</li><li><a href="https://github.com/Dafrok/vue-baidu-map">vue-baidu-map</a>-百度地图的 Vue 2.x 组件。</li><li><a href="https://github.com/voluntadpear/vue-choropleth">vue-choropleth</a>-Vue 2.x 组件，用于显示一个 Choropleth 贴图。</li><li><a href="https://github.com/ghettovoice/vuelayers">vuelayers</a>-Vue 2 组件可与 OpenLayers 一起使用。</li><li><a href="https://github.com/Akryum/vue-googlemaps">vue-googlemaps</a>-Vue 2.x 组件，用于集成 Google Maps。</li><li><a href="https://github.com/eperedo/vue-static-map">vue-static-map</a>-Vue 2.x 简单组件，可生成静态 Google 地图</li><li><a href="https://github.com/soal/vue-mapbox">vue-mapbox</a>-Mapbox GL JS 库周围的 Vue 2.x 包装器，提供了与地图交互的途径。</li></ul><h2 id="音频视频"><a href="#音频视频" class="headerlink" title="音频视频"></a>音频视频</h2><ul><li><a href="https://github.com/SevenOutman/vue-aplayer">Vue-APlayer</a>-：cake：用于 Vue 2.x 的易于配置的音乐播放器。</li><li><a href="https://github.com/shershen08/vuejs-sound-player">vue-audio</a>-音频标签包装器；Vue 2.x 的声音播放器组件</li><li><a href="https://github.com/sinchang/vue-dplayer">vue-dplayer</a>-基于 DPlayer 的 Vue 2.x 视频播放器组件。</li><li><a href="https://github.com/chrishurlburt/vue-canvasvideo">vue-canvasvideo</a>-一个 Vue 2.x 组件，用于在 iOS &#x2F; Safari 上播放视频背景和自动播放视频。</li><li><a href="https://github.com/petsgre/music">vue-music</a>-基于 html5&#96;&#96;的 Vue 组件。</li><li><a href="https://github.com/staskobzar/vue-audio-visual">vue-audio-visual</a>-Vue HTML5 音频可视化组件。</li><li><a href="https://github.com/redxtech/vue-plyr">vue-plyr</a>-一组用于 plyr 视频和音频播放器的 Vue 组件。</li><li><a href="https://github.com/TerryZ/v-playback">v-playback</a>-一个 Vue2 插件，可简化视频播放。</li><li><a href="https://github.com/grishkovelli/vue-audio-recorder">vue-audio-recorder</a>-Vue.js 的音频记录器。它允许在服务器上创建，播放，下载和存储记录</li><li><a href="https://github.com/johndatserakis/vue-video-section">vue-video-section</a>-Vue 的简单视频标头&#x2F;部分组件。适用于视频背景并在其上叠加内容。</li></ul><h2 id="无限滚动"><a href="#无限滚动" class="headerlink" title="无限滚动"></a>无限滚动</h2><ul><li><a href="https://github.com/PeachScript/vue-infinite-loading">vue-infinite-loading</a>-适用于 Vue.js 1.0 和 Vue.js 2.0 的无限滚动插件。</li><li><a href="https://github.com/egoist/vue-mugen-scroll">vue-mugen-scroll</a>-Vue.js 的无限滚动组件 2。</li><li><a href="https://github.com/ElemeFE/vue-infinite-scroll">vue-infinite-scroll</a>-vue.js 的无限滚动指令。</li><li><a href="https://github.com/lookstudios/vue-loop">vue-loop</a>-Vue.js 2 的无限内容循环组件。</li><li><a href="https://github.com/wangdahoo/vue-scroller">vue-scroller</a>-Vue.js 2 的无限内容循环组件，包括诸如“拉动刷新”，“无限加载”之类的功能，’snaping-scroll’。</li><li><a href="https://github.com/legeneek/vue-infinite-list">vue-infinite-list</a>-无限列表 mixin 可以为 Vue.js 2 回收 dom</li><li><a href="https://github.com/biigpongsatorn/vue-infinite-slide-bar">vue-infinite-slide-bar</a>-∞ 无限滑动条组件。</li><li><a href="https://github.com/zuolei828/vue-virtual-infinite-scroll">vue-virtual-infinite-scroll</a>-基于 Iscroll 的 vue2 组件，支持具有高性能滚动，无限负载和拉动的大数据列表刷新。</li></ul><h2 id="拉动刷新"><a href="#拉动刷新" class="headerlink" title="拉动刷新"></a>拉动刷新</h2><ul><li><a href="https://github.com/lakb248/vue-pull-refresh">vue-pull-refresh</a>-拉动刷新 Vue.js 2.0 的组件。</li><li><a href="https://github.com/stackjie/vue-pull-to">vue-pull-to</a>-下拉刷新和上拉为 Vue.js 组件加载了更多内容并无限滚动。</li><li><a href="https://github.com/bedlate/vue-data-loading">vue-data-loading</a>-另一个用于无限滚动和向下&#x2F;向上加载数据的组件。</li><li><a href="https://github.com/duyanpeng/vue-quick-loadmore">vue-quick-loadmore</a>-Vue 的下拉刷新和上拉无限滚动插件。</li></ul><h2 id="降价"><a href="#降价" class="headerlink" title="降价"></a>降价</h2><ul><li><a href="https://github.com/miaolz123/vue-markdown">vue-markdown</a>-适用于 Vue 的强大，高速 Markdown 解析器。</li><li><a href="https://github.com/hinesboy/mavonEditor">vue-mavonEditor</a>-基于 Vue 的降价编辑器，支持多种个性化功能。</li><li><a href="https://github.com/Vivify-Ideas/vue-simple-markdown">vue-simple-markdown</a>-适用于 Vue 的简单，高速 Markdown 解析器。</li><li><a href="https://github.com/F-loat/vue-simplemde">vue-simplemde</a>- <a href="https://github.com/sparksuite/simplemde-markdown-editor">simplemde</a>的包装。不论是初学者还是专家，都可轻松编辑。具有内置的自动保存和拼写检查功能。</li><li><a href="https://github.com/nhnent/toast-ui.vue-editor">toast-ui.vue-editor</a>- [TOAST UI 编辑器]的 Vue 包装器(<a href="http://ui.toast.com/tui">http://ui.toast.com/tui</a> -编辑)。</li></ul><h2 id="PDF"><a href="#PDF" class="headerlink" title="PDF"></a>PDF</h2><ul><li><a href="https://github.com/FranckFreiburger/vue-pdf">vue-pdf</a>-基于 mozilla 的 PDF.js 的 pdf 查看器</li><li><a href="https://github.com/arkokoley/pdfvuer">pdfvuer</a>-Vue 的 PDF 查看器，使用 Mozilla 的 PDF.js 和文本支持。<a href="https://blog.koley.in/pdfvuer/">演示</a></li></ul><h2 id="树"><a href="#树" class="headerlink" title="树"></a>树</h2><ul><li><a href="https://github.com/David-Desmaisons/Vue.D3.tree">Vue.D3.tree</a>-基于[D3.js]的树状视图(<a href="https://d3js.org/">https://d3js.org/</a>)</li><li><a href="https://github.com/arvidkahl/vue-json-tree-view">vue-json-tree-view</a>-Vue.js 的 JSON 树视图组件。</li><li><a href="https://github.com/halower/vue2-tree">vue-tree</a>-Vue.js 2.X 的树组件。</li><li><a href="https://github.com/amsik/liquor-tree">liquor-tree</a>-惊人的 Vue 树组件</li><li><a href="https://github.com/wyr1227/vue-trees">vue-trees-ui</a>-基于 Vue 的 Tree Ui。</li><li><a href="https://github.com/elbywan/bosket">Bosket</a>-前端框架(Vue，React，Angular 和 Riot)的树视图组件的集合。</li><li><a href="https://github.com/plantain-00/tree-component">plantain-00 &#x2F; tree-component</a>-一个 reactjs，angular 和 vuejs 树组件。</li><li><a href="https://github.com/holiber/sl-vue-tree">sl-vue-tree</a>-适用于 Vue.js 的简单可定制的可拖动树组件</li><li><a href="https://github.com/phphe/vue-draggable-nested-tree">vue-draggable-nested-tree</a>-适用于 Vuejs2 [@phphe](<a href="https://github.com的功能强大的可自定义可拖动树视图组件./">https://github.com的功能强大的可自定义可拖动树视图组件。</a> com &#x2F; phphe)</li><li><a href="https://github.com/scalia/vuejs-tree">vuejs-tree</a>-高度可定制的 VueJs 树查看器</li><li><a href="https://github.com/zdy1988/vue-jstree">vue-jstree</a>-适用于 Vue2 的树形插件，带有漂亮的图标和拖放功能</li><li><a href="https://github.com/XAHTEP26/vue-vtree">vue-vtree</a>-Vue.js 的通用且灵活的树组件</li><li><a href="https://github.com/tylerkrupicka/vue-json-component">vue-json-component</a>-JSON 树视图，没有依赖项，TypeScript 支持且易于定制。</li><li><a href="https://github.com/ParadeTo/vue-tree-list">vue-tree-list</a>-用于树形结构的 vue 组件</li></ul><h2 id="社交分享"><a href="#社交分享" class="headerlink" title="社交分享"></a>社交分享</h2><ul><li><a href="https://github.com/nicolasbeauvais/vue-social-sharing">vue-social-sharing</a>-一个 Vue.js 组件，用于共享指向社交网络的链接，可与 Vue.js 1.X 或 2.X 一起使用。</li><li><a href="https://github.com/koddr/vue-goodshare">vue-goodshare</a>-用于社交共享的 Vue.js 组件，具有精美的按钮设计。简单的安装，丰富的文档，开发人员支持，SEO 友好，干净的代码，无需脚本即可快速跟踪页面上的用户活动。使用 Vue.js2.x。</li><li><a href="https://github.com/mbj36/vue-socialmedia-share">vue-socialmedia-share</a>-一个 Vue.js 组件，用于使用 Vue 2.X 共享与社交网络的链接</li><li><a href="https://github.com/Onatcer/vue-picture-sharesheet">vue-picture-sharesheet</a>-一个 Vue 图片共享表组件，受到苹果新闻编辑室中图片共享表的启发</li><li><a href="https://github.com/chiaweilee/vue-twitter">vue-twitter</a>-用于嵌入 Twitter 小部件(例如时间线，按钮)的 Vue.js 组件</li><li><a href="https://github.com/Alexandrshy/vue-share-buttons">vue-share-buttons</a>-Vue.js 组件，用于在您的项目中放置按钮，您可以共享任何东西</li></ul><p>＃＃ 二维码</p><ul><li><a href="https://github.com/theomessin/vue-qriously">vue-qriously</a>-一个 Vue.js 2 组件，用于使用 qrious 在 HTML Canvas 上绘制 QR 代码。</li><li><a href="https://github.com/superman66/vue-qart">vue-qart</a>-vue 2.x 用于 qart.js 的指令。</li><li><a href="https://github.com/gruhn/vue-qrcode-reader">vue-qrcode-reader</a>-一个 Vue.js 2 组件，可从相机流中检测和解码 QR 码。</li></ul><h2 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h2><ul><li><a href="https://github.com/shayneo/vue-fuse">vue-fuse</a>-模糊搜索库 Fuse.js 的轻量级插件</li><li><a href="https://community.algolia.com/vue-instantsearch/">vue-instantsearch</a>-使用<a href="https://www.algolia.com/">Algolia</a>创建即时搜索体验的终极工具箱。</li><li><a href="https://github.com/InnerSearch/vue-innersearch">vue-innersearch</a>-用于 Elasticsearch 的 Vue.js 包装器</li><li><a href="https://github.com/appbaseio/reactivesearch">reactivesearch-vue</a>-用于使用 Elasticsearch 构建数据驱动的应用程序的 UI 组件</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li><a href="https://github.com/eliep/vue-avatar">vue-avatar</a>-vue.js 的头像组件。</li><li><a href="https://github.com/surmon-china/vue-touch-ripple">vue-touch-ripple</a>-Vue.js 的触摸波纹组件(1.x〜2.x)。</li><li><a href="https://github.com/cngu/vue-typer">vue-typer</a>-Vue 组件，用于模拟用户键入，选择和擦除文本。</li><li><a href="https://github.com/MartyWallace/vue-keyboard">vue-keyboard</a>-Vue 2 虚拟键盘组件。</li><li><a href="https://github.com/mhayes/vue-twentytwenty">vue-twentytwenty</a>-图像比较组件，可与 Vue.js 2.x 一起使用</li><li><a href="https://github.com/apertureless/vue-cookie-law">vue-cookie-law</a>-Vue.js 2.x 的 Cookie 信息插件</li><li><a href="https://github.com/JiriChara/vue-gravatar">vue-gravatar</a>-适用于 Vue.js 2.x 的简陋的 gravatar 组件</li><li><a href="https://github.com/Inndy/vue-clipboard2">vue-clipboard2</a>-一种易于使用的 Vue.js 2.x 剪贴板剪贴板绑定</li><li><a href="https://github.com/cuduy197/vue-flashcard">vue-flashcard</a>-带有 Vue.js 2.x 动画的 FLashcard 组件：bulb：</li><li><a href="https://github.com/kavalcante/vue-truncate-collapsed">vue-truncate-collapsed</a>-一个简单的组件，它会截断文本并为 Vue.js 2 添加可点击的“阅读更多&#x2F;显示较少”。 X</li><li><a href="https://github.com/BrockReece/vue-kanban">vue-kanban</a>-灵活的拖放式看板板组件</li><li><a href="https://github.com/aidewoode/vue-letter-avatar">vue-letter-avatar</a>-vue.js 的简单优雅的字母头像组件</li><li><a href="https://github.com/metachris/vue-highlightjs">vue-highlightjs</a>-使用 highlight.js 突出显示语法</li><li><a href="https://github.com/euvl/v-clipboard">v-clipboard</a>-简单，小巧且易于使用的指令将您的模型保存到剪贴板(最小 2kb，无依赖项)</li><li><a href="https://github.com/MicroDroid/vue-invisible-recaptcha">vue-invisible-recaptcha</a>-超级简单的 Google 隐形 reCAPTCHA 集成</li><li><a href="https://github.com/Gomah/vue-embed">vue-embed</a>-Embed 组件基于 Vue 2.x 的 embed.js，该组件可嵌入表情符号，媒体，地图，tweet，要点，代码，服务和减价。</li><li><a href="https://github.com/creotip/vue-particles">vue-particles</a>-粒子背景的 Vue.js 组件</li><li><a href="https://github.com/termosa/vue-uniq-ids">vue-uniq-ids</a>-Vue.js 2.x 插件，可帮助使用与 ID 相关的属性，且无副作用</li><li><a href="https://github.com/drewjbartlett/vue-multivue">vue-multivue</a>-在同一页面上使用同一类的多个 vue 应用。</li><li><a href="https://github.com/eddiemf/vue-affix">vue-affix</a>-一个 Vue.js 2.x 插件，可在滚动时在窗口中添加元素，类似于 Bootstrap Affix，但更简单，更智能</li><li><a href="https://github.com/OXOYO/X-Browser-Update-Vue">X-Browser-Update-Vue</a>-一个 Vue.js 浏览器更新插件。</li><li><a href="https://github.com/dabernathy89/vue-query-builder">vue-query-builder</a>-用于使用嵌套条件构建复杂查询的 UI 组件。</li><li><a href="https://github.com/karakanb/vue-info-card">vue-info-card</a>-一个简单漂亮的卡片组件，带有优美的火花线和 CSS3 翻转动画。</li><li><a href="https://github.com/vinayakkulkarni/v-offline">v-offline</a>-简单，小巧且易于使用的 Vue 应用程序检测离线和在线事件(最小 390b)</li><li><a href="https://github.com/SeregPie/VueWordCloud">vue-word-cloud</a>-词云生成器。</li><li><a href="https://github.com/grzhan/vue-flat-surface-shader">vue-flat-surface-shader</a>- <a href="https://github.com/wagerfield/%E5%B9%B3%E9%9D%A2%E7%9D%80%E8%89%B2%E5%99%A8">Vue-flat-surface-shader</a></li><li><a href="https://github.com/ddgll/vue-easteregg">vue-easteregg</a>-Easey 在您的 Vue 应用中添加了 Easteregg(默认使用 konami 代码)</li><li><a href="https://github.com/noomerzx/vue-barcode-scanner">vue-barcode-scanner</a></li><li><a href="https://github.com/BrockReece/vue-heatmapjs">vue-heatmapjs</a>-用于跟踪和可视化鼠标活动的 Vue 指令</li><li><a href="https://github.com/meganetaaan/vue-maze">vue-maze</a>-由 Vue.js 组件制作的小巧迷宫游戏</li><li><a href="https://github.com/AshleyLv/vue-drag-verify">vue-drag-verify</a>-这是一个 vue 组件，可以滑动以解锁以进行登录或注册。</li><li><a href="https://github.com/kevinwarne/vue-balloon">vue-balloon</a>-Vue 组件，用于在页面一角创建固定的，可缩放的容器。与 gmail 中使用的邮件撰写包装类似。</li><li><a href="https://github.com/KamilOcean/vue-sticker">vue-sticker</a>-任意方向的贴纸效果</li><li><a href="https://github.com/vinayakkulkarni/v-rating">v-rating</a>-⭐️ 使用 VueJS 制作的语义 UI 中的评级组件(&lt;500B 压缩，速度非常快)</li><li><a href="https://github.com/michalsnik/vue-content-placeholders">vue-content-placeholders</a>-用于在 vue 中渲染诸如 Facebook 之类的伪造(渐进)内容的可组合组件</li><li><a href="https://github.com/fireyy/vue-page-designer">vue-page-designer</a>-Vue 组件，用于拖放来设计和构建移动网站。</li><li><a href="https://github.com/julon/vue-creativecommons">vue-creativecommons</a>-CreativeCommons.org Vue.js 组件库。</li><li><a href="https://github.com/coderdiaz/vue-status-indicator">vue-status-indicator</a>-一个 Vue.js 组件，用于将状态指示器显示为彩色圆点。</li><li><a href="https://github.com/mazipan/vue-google-adsense">vue-google-adsense</a>-具有 InFeed 和 InArticle Ads 支持的 Vue.js Google Adsense 组件</li><li><a href="https://github.com/shershen08/emoji-vue">emoji-vue</a>-Vue.js 项目的 Emoji😎👌🏻 下拉菜单</li><li><a href="https://github.com/vitogit/vue-chessboard">vue-chessboard</a>-棋盘 vue 组件可加载位置，创建位置并查看威胁。</li><li><a href="https://github.com/anteriovieira/vue-mindmap">vue-mindmap</a>-用于 mindnode 映射的 Vue 组件。</li><li><a href="https://github.com/ignoreintuition/v-currency">v-currency</a>-用于格式化货币的 Vue 组件。</li><li><a href="https://github.com/DCzajkowski/vue-emoji-picker">vue-emoji-picker</a>-高度可定制的 Unicode 表情符号选择器 🔥🚀</li><li><a href="https://github.com/meganetaaan/vue-8-puzzle">vue-8-puzzle</a>-一个由 Vue.js 组件制作的小巧幻灯片益智游戏</li><li><a href="https://github.com/evildvl/vue-e164">vue-e164</a>-具有 E.164 标准支持的可自定义电话格式化程序</li><li><a href="https://github.com/deemaagog/vue-pgn">vue-pgn</a>-Vue.js 组件，用于以 pgn 格式查看棋牌游戏</li><li><a href="https://github.com/fpluquet/vue-avatar-editor">vue-avatar-editor</a>-使用清晰的用户界面调整大小，旋转并裁剪上传的头像。</li><li><a href="https://github.com/Botre/vue-connection-listener">vue-connection-listener</a>-Vue 事件总线插件监听在线&#x2F;离线更改。</li><li><a href="https://github.com/Botre/vue-sauce">vue-sauce</a>-Vue 的“查看源代码”指令。</li><li><a href="https://github.com/Botre/vue-prom">vue-prom</a>-Vue 承诺包装器组件。</li><li><a href="https://github.com/viclm/numeric-keyboard">数字键盘</a>-用于移动浏览器的数字键盘。</li><li><a href="https://github.com/Intera/vue-zoom-on-hover">vue-zoom-on-hover</a>-鼠标悬停时图像缩放</li><li><a href="https://github.com/HCESrl/vue-sensitive-image">vue-sensitive-image</a>-Vue 组件，可让您快速创建具有最佳数量的所有设备图像源的响应式图像标签。</li><li><a href="https://github.com/TonPC64/vue-highlight-text">vue-highlight-text</a>-Vue 组件，用于突出显示单词的多个实例</li><li><a href="https://github.com/anteriovieira/vue-cast-props">vue-cast-props</a>-提供了一种将 props 转换为常见数据类型的便捷方法。</li><li><a href="https://github.com/JustSteveKing/vue2-heropatterns">vue2-heropatterns</a>-一个 Vue2 实现，允许您将流行的 Hero Patterns 添加到任何 Div 上</li><li><a href="https://github.com/Developmint/vue-link">vue-link</a>-一个将所有链接都链接在一起的组件(处理外部和内部链接相同)</li><li><a href="https://github.com/vinayakkulkarni/vue-identify-network">vue-identify-network</a>-⚡️ 识别您的用户正在使用哪种互联网！</li><li><a href="https://github.com/ridaamirini/vue-cloneya">vue-cloneya</a>-用于克隆 DOM 元素的 vue 组件</li><li><a href="https://github.com/FissionHQ/vue-survey-builder">vue-survey-builder</a>-vue.js 应用程序的调查生成器</li><li><a href="https://github.com/Developmint/vue-if-bot">vue-if-bot</a>-一个轻量级的组件，用于基于用户代理向客户端隐藏&#x2F;显示内容</li><li><a href="https://github.com/clampy-js/vue-clampy">vue-clampy</a>-Vue.js(2+)指令，通过在其中包含内容的元素加上省略号来限制元素的内容太长。</li><li><a href="https://github.com/promosis/vue-cookie-accept-decline">vue-cookie-accept-decline</a>-在页面上显示带有文字，拒绝按钮和接受按钮的横幅。记住使用 cookie 进行选择。使用创建时的当前选择来发出事件。符合 GDPR 要求。</li><li><a href="https://github.com/lossendae/vue-avatar">@ lossendae &#x2F; vue-avatar</a>-VueJS 2.0 的头像组件。</li><li><a href="https://github.com/AlbertLucianto/vue-text-highlight">vue-text-highlight</a>-Vue.js 的文本荧光笔库 💄</li><li><a href="https://github.com/bsdfzzzy/vue2-hammer">vue2-hammer</a>Vue 2.x 的 Hammer.js 包装器支持移动触摸。</li><li><a href="https://github.com/johndatserakis/vue-countable">vue-countable</a>-countable.js 的 Vue 绑定。提供实时的段落，句子，单词和字符计数。</li><li><a href="https://github.com/phegman/v-show-slide">v-show-slide</a>-一个 Vue.js 指令，用于将元素上下移动动画：自动滑动。</li><li><a href="https://github.com/eCollect/vue-swipe-actions">vue-swipe-actions</a>-适用于 Vue.js 的 iOS 样式滑动操作</li><li><a href="https://github.com/nzlt/vue-friendly-iframe">vue-friendly-iframe</a>-用于创建超快速加载，无阻塞 iframe 的 Vue js 组件。</li><li><a href="https://github.com/mattmezza/vue-beautiful-chat">vue-beautiful-chat</a>-一个简单而美丽的 Vue 聊天组件后端不可知，完全可自定义和可扩展。</li><li><a href="https://github.com/zeknoss/vue-magnifier">vue-magnifier</a>-Vue.js 2.x 的简单图像缩放&#x2F;放大组件。</li><li><a href="https://github.com/Astray-git/vue-highlight-words">vue-highlight-words</a>-Vue 组件可在较大的文本正文中突出显示单词。从[react-highlight-words]移植(<a href="https://github.com/bvaughn/react-highlight-words">https://github.com/bvaughn/react-highlight-words</a>)</li><li><a href="https://github.com/yanthems/vue-tags-ball">vue-tags-ball</a>-使用此插件创建漂亮的球形标签</li><li><a href="https://github.com/spemer/vue-rippler">vue-rippler</a>-用于自定义波纹效果的简单 Vue.js 插件</li><li><a href="https://github.com/chiaweilee/vue-contacts">vue-contacts</a>-Vue 的移动通讯录组件</li><li><a href="https://github.com/jmaczan/basic-vue-chat">basic-vue-chat</a>-易于使用的 Vue.js 聊天</li><li><a href="https://github.com/JayeshLab/vue-resize-text">vue-resize-text</a>-一个 vue 指令，可根据元素宽度自动调整字体大小。</li><li><a href="https://github.com/GabrielBibiano/vue-github-profile">vue-github-profile</a>-一个 Vue 组件，用于查看确定的用户的配置文件和存储库</li><li><a href="https://github.com/P3trur0/vue-niege">vue-niege</a>-🎅 单文件 Vue 组件可通过画布添加暴风雪。</li><li><a href="https://github.com/JonathanDn/vue-stars-rating">vue-dynamic-star-rating</a>-高度动态的 Vue 明星评分组件，例如 Google Play 评分 ⭐️⭐️⭐️⭐️⭐️⭐️</li><li><a href="https://github.com/lucpotage/vue-katex">vue-katex</a>-在 Vue.js 中使用 KaTeX 进行数学排版的简单插件</li><li><a href="https://github.com/loo41/vuc">vue-canvas-identify</a>- [vuc-identify]的 Vue 画布组件(<a href="http://vuc.tianchenyong.top/">http://vuc.tianchenyong.top</a>)</li><li><a href="https://github.com/loo41/vuc">vue-canvas-material</a>- [vuc-material]的 Vue 画布组件(<a href="http://vuc.tianchenyong.top/#/materia">http://vuc.tianchenyong.top/#/materia</a>)</li><li><a href="https://github.com/superhos/vue-baberrage">vue-baberrage</a>-一个基于 Vue.js 的简单弹幕插件 😎</li><li><a href="https://github.com/shershen08/vue-terminal-ui">vue-terminal-ui</a>-🖥TerminalUI 模拟器 Vue：自定义和基本命令</li><li><a href="https://github.com/ndabAP/vue-command">vue-command</a>-完全正常工作的 Vue.js 终端模拟器</li><li><a href="https://github.com/P3trur0/vue-ribbon">vue-ribbon</a>-GitHub 功能区的 Vue 组件</li><li><a href="https://github.com/trunda/avatio-avatar">avatio-avatar</a>-插图化身的 Vue 组件- <a href="https://avatio.cool/">Avatio</a>使用</li><li><a href="https://github.com/man15h/vue-jazzicon">vue-jazzicon</a>-用于 Vue 的简陋的 Jazzicon 组件。</li><li><a href="https://github.com/craigh411/vue-star-rating">vue-star-rating</a>-一个简单的，高度可定制的星级评分组件 ⭐️⭐️⭐️</li><li><a href="https://github.com/potato4d/vue-fixed-header">vue-fixed-header</a>-简单且跨浏览器友好的由 TypeScript 编写的 Vue.js 固定标头组件。</li><li><a href="https://github.com/dreambo8563/vue-particle-effect-buttons">vue-particle-effect-buttons</a>一个爆发粒子效果按钮组件。</li><li><a href="https://github.com/gorbypark/vue-insomnia">vue-insomnia</a>-防止显示屏进入休眠状态(唤醒锁定)。</li><li><a href="https://github.com/yimocanxue/vue-car-plate-keyboard">vue-car-plate-keyboard</a>-用于 VueJS 2.x 的汽车牌照号码键盘。能源车牌 🚗🚗🚗)</li><li><a href="https://github.com/krthr/vue-dataflow-editor">vue-dataflow-editor</a>-Vue2 数据流图编辑器</li><li><a href="https://github.com/kevinfaguiar/cool-emoji-picker">cool-emoji-picker</a>-Vue 的快速即插即用[Tw] emoji Picker(用于 Twemoji 渲染的+ textarea)组件。</li></ul><h2 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h2><ul><li><a href="https://github.com/cristijora/vue-tabs">vue-tabs</a>-简单的标签和药丸。</li><li><a href="https://github.com/zhangxiang958/vue-tab">vue-swipe-tabs</a>-vue.js(vue2)的触摸滑动选项卡组件。</li><li><a href="https://github.com/spatie/vue-tabs-component">vue-tabs-component</a>-一种使用 Vue 显示标签的简便方法。</li><li><a href="https://github.com/kevindesousa/vue-k-tabs">vue-k-tabs</a>-具有 Gitlab 设计的简单标签组件。</li><li><a href="https://github.com/karambafe/vue-tabs-with-active-line">vue-tabs-with-active-line</a>-简单的 Vue 2 组件，可让您制作带有移动底线的标签</li><li><a href="https://github.com/viewweiwu/vue-tabs-chrome">vue-tabs-chrome</a>-一个类似于 Chrome 的标签的 Vue 组件。</li></ul><h2 id="电话号码输入格式器"><a href="#电话号码输入格式器" class="headerlink" title="电话号码输入格式器"></a>电话号码输入格式器</h2><ul><li><a href="https://github.com/LouisMazel/vue-phone-number-input">vue-phone-number-input</a>-一个漂亮的输入，用于格式化与国家&#x2F;地区代码有效的电话号码：fire：</li></ul><h2 id="选择器"><a href="#选择器" class="headerlink" title="选择器"></a>选择器</h2><ul><li><a href="https://github.com/hiyali/vue-smooth-picker">vue-smooth-picker</a>-Vue 2.x 的平滑选择器组件，例如 iOS 本机日期时间选择器。</li></ul><h2 id="发电机"><a href="#发电机" class="headerlink" title="发电机"></a>发电机</h2><ul><li><a href="https://github.com/formschema/native">FormSchema Native</a>-使用 JSON Schema 和 Vue.js 生成表单</li><li><a href="https://github.com/fightingm/vue-awesome-form">vue-awesome-form</a>-一个 vue.js 组件，就像 json-editor</li><li><a href="https://github.com/michaellyu/vue-generator">vue-generator</a>-Vue 项目的初始路由器和组件。</li><li><a href="https://github.com/14nrv/vue-form-json">vue-form-json</a>-从 json 生成具有验证和 bulma 样式的 vue 表单</li><li><a href="https://github.com/xaboy/form-create">form-create</a>-具有动态呈现，数据收集，验证和提交功能的表单生成器，支持 json 数据</li><li><a href="https://github.com/codetrial/element-form-builder">element-form-builder</a>-使用 JSON 模式构建 element-ui 表单。</li><li><a href="https://github.com/ncform/ncform">ncform</a>-一种非常好的配置生成表单的方式</li><li><a href="https://github.com/laraform/laraform">Laraform</a>-具有 Laravel 支持的 Vue.js 的高级表单生成器</li><li><a href="https://github.com/dream2023/vue-ele-form">vue-ele-form</a>-Vue DataForm，基于 element-ui</li></ul><h2 id="日期选择器"><a href="#日期选择器" class="headerlink" title="日期选择器"></a>日期选择器</h2><ul><li><a href="https://github.com/hilongjw/vue-datepicker">vue-datepicker</a>- [未维护]具有用于 Vue.js 的材质设计的日历和 datepicker 组件。</li><li><a href="https://github.com/phoenixwong/vue2-timepicker">vue2-timepicker</a>- [未维护] Vue 2.x 的下拉时间选择器(小时|分钟|秒)，具有灵活的时间格式支持。</li><li><a href="https://github.com/charliekassel/vuejs-datepicker">vuejs-datepicker</a>-一个简单的 Vue.js datepicker 组件。支持禁用日期，内联模式，翻译。</li><li><a href="https://github.com/nkoehring/vuedt">vuedt</a>- [未维护]疯狂的轻量级(5.5kb！)Vuejs 日期和时间选择器组件，动画效果很好，而且没有太多的模糊感。</li><li><a href="https://github.com/ankurk91/vue-flatpickr-component">vue-flatpickr-component</a>用于<a href="https://github.com/chmln/flatpickr">flatpickr</a>日期时间选择器的 Vue.js 组件</li><li><a href="https://github.com/ankurk91/vue-bootstrap-datetimepicker">vue-bootstrap-datetimepicker</a>Vue.js 组件，用于[eonasdan-bootstrap-datetimepicker](<a href="https://github.com/Eonasdan/bootstrap-">https://github.com/Eonasdan/bootstrap-</a> datetimepicker &#x2F;)</li><li><a href="https://github.com/pepour/vue-jalaali-datepicker">vue-jalaali-datepicker</a>-vue.js 的 Jalaali 日历和日期选择器 2。</li><li><a href="https://github.com/ridewn/vue-date-picker">vue-date-picker</a>-一个受材料设计启发的 vue 日期选择器组件</li><li><a href="https://github.com/ittus/vue-monthly-picker">vue-monthly-picker</a>-仅适用于月份和年份选择器的 Vue.js 组件</li><li><a href="https://github.com/krystalcampioni/vue-hotel-datepicker">vue-hotel-datepicker</a>-响应式日期范围选择器，显示选定的住宿天数，允许自定义入住&#x2F;退房规则，屏蔽日期，本地化支持等。</li><li><a href="https://github.com/dyonir/vue2-persian-datepicker">vue2-persian-datepicker</a>-vue 的真棒波斯 datepicker 组件。کامپوننتانتخابتاریخبرایویو。</li><li><a href="https://github.com/mariomka/vue-datetime">vue-datetime</a>-Vue 的移动友好日期时间选择器。支持日期，日期时间和时间模式，i18n 和禁用日期。</li><li><a href="https://github.com/bliblidotcom/vue-rangedate-picker">vue-rangedate-picker</a>-具有简单用法的范围日期选择器</li><li><a href="https://github.com/dwqs/v2-datepicker">v2-datepicker</a>-基于 Vue 2.x 的简单 datepicker 组件。</li><li><a href="https://github.com/weifeiyue/vue-datepicker-local">vue-datepicker-local</a>-Vue2 的一个漂亮的 Datepicker 组件。</li><li><a href="https://github.com/MikaelEdebro/vue-airbnb-style-datepicker">vue-airbnb-style-datepicker</a>-Vue datepicker，外观和功能与流行的 AirBnb datepicker 相似。轻巧，可配置且良好的浏览器支持！</li><li><a href="https://github.com/talkhabi/vue-persian-datetime-picker">vue-persian-datetime-picker</a>波斯材料 datepicker。支持日期时间，日期，时间，年，月。</li><li><a href="https://vcalendar.io/">VCalendar</a>非常可定制且功能强大的日历&#x2F;日期选择器组件，具有许多功能和完善的文档。</li><li><a href="https://github.com/Owumaro/vue-date-range-picker">@ owumaro &#x2F; vue-date-range-picker</a>-使用 Bootstrap 4 样式进行日期范围选择的 Vue 组件</li><li><a href="https://github.com/ikarosu/vue-datepicker-mobile">vue-datepicker-mobile</a>-适用于 vue2 的移动友好日期选择器。：cn：选择日期或日期范围，然后自定义所需的日期。</li><li><a href="https://github.com/liloow/vue-draggableCal">vue-draggable-cal</a>-不是普通的日期选择器。一个 Vuejs 可拖动的日期选择器，具有全新的响应式设计，可移动且具有 0 个依赖项，已压缩 17kb。</li><li><a href="https://github.com/Shchepotin/vue-vanilla-datetime-picker">vue-vanilla-datetime-picker</a>-Vue 的日期时间选择器。</li><li><a href="https://github.com/Innologica/vue2-daterange-picker/blob/master/README.md">vue2-daterange-picker</a>-基于 bootstrap-daterangepicker 的 Vue2 日期范围选择器(无 jQuery 依赖性)</li><li><a href="https://github.com/alexiscolin/vue-timeselector">vue-timeselector</a>-完全简单可定制的 Vue.js 功能强大的时间选择器组件。</li><li><a href="https://github.com/8788/vue-date-picker">vue-date-picker</a>-Vue 2.x 的轻量级 datepicker 组件。</li><li><a href="https://github.com/chronotruck/vue-ctk-date-time-picker">vue-ctk-date-time-picker</a>-一个漂亮的 VueJS 组件，用于选择日期和时间(使用范围模式)：新：</li><li><a href="https://github.com/jamespjarvis/simple-vue2-datetimepicker">simple-vue2-datetimepicker</a>-一个简单易用的 vue.js 组件，用于日期和时间选择。：新：</li><li><a href="https://github.com/sbarry50/vue-business-hours">vue-business-hours</a>-Vue 组件，用于在管理面板或仪表板中选择营业时间。</li><li><a href="https://github.com/ly525/material-vue-daterange-picker">material-vue-daterange-picker</a>-Vuejs 2.x 的 Material Design 样式的日期范围选择器，与 vuetify 和友好版本兼容手机。</li><li><a href="https://github.com/mathieustan/vue-datepicker">vue-datepicker</a>-具有 Vuejs 2.x 的 Material Design 样式的干净响应式日期选择器。(日期&#x2F;月&#x2F;季度&amp;&amp;日期范围选择器)：新：</li></ul><h2 id="选择"><a href="#选择" class="headerlink" title="选择"></a>选择</h2><ul><li><a href="https://github.com/sagalbot/vue-select">vue-select</a>-一个本地 Vue.js 组件，提供与 Select2 类似的功能，而无需 jQuery 的开销。</li><li><a href="https://github.com/monterail/vue-multiselect">vue-multiselect</a>-Vue.js 的通用选择&#x2F;多重选择&#x2F;标记组件。</li><li><a href="https://github.com/stfalcon-studio/stf-vue-select">stf-vue-select</a>-最灵活和自定义的选择 Vue2</li><li><a href="https://github.com/mazipan/vue-select-image">vue-select-image</a>-Vue 2 组件，用于从列表中选择图像</li><li><a href="https://github.com/riophae/vue-treeselect">@ riophae &#x2F; vue-treeselect</a>-具有对 Vue.js 的嵌套选项支持的多选组件。</li><li><a href="https://github.com/k186/pd-select">@ k186 &#x2F; pd-select</a>-一个移动 UI 组件，例如 Vue 2.x 的 IOS 选择器，可以随便定义。</li><li><a href="https://github.com/mikerodham/vue-dropdowns">vue-dropdowns</a>-如果对 vue2.x 使用对象，则是一种显示选择框的简约且可适应的方法</li><li><a href="https://github.com/zanseven007/v-cascade">v-cascade</a>-带有 Vue 2.x 的层叠选择器的一个可爱组件(支持 PC 和 Mobile)</li><li><a href="https://github.com/IneoO/vue-multi-select">vue-multi-select</a>-用于对 Vue2 进行选择&#x2F;多重选择的自定义组件。</li><li><a href="https://github.com/TerryZ/v-region">v-region</a>-一个简单的区域选择器，提供中文行政区划数据。</li><li><a href="https://github.com/TerryZ/v-selectpage">v-selectpage</a>-Vue2，分页列表或表格视图的强大选择器，使用标签进行多项选择，i18n 和服务器端资源支持。</li><li><a href="https://github.com/iliyaZelenko/vue-cool-select">vue-cool-select</a>-引导程序&#x2F;材质设计主题，支持广告位，自动填充，事件，验证等。</li><li><a href="https://github.com/myENA/advanced-select">@ myena &#x2F; advanced-select</a>-具有搜索功能，用于(取消)全选和 Bootstrap 3 主题的单&#x2F;多选择组件</li><li><a href="https://github.com/Sandalf/vue-bootstrap-select">@ alfsnd &#x2F; vue-bootstrap-select</a>-Vue 版本的<a href="https://github.com/snapappointments/bootstrap-%E9%80%89%E6%8B%A9/">bootstrap-select</a>。</li></ul><h2 id="滑块"><a href="#滑块" class="headerlink" title="滑块"></a>滑块</h2><ul><li><a href="https://github.com/NightCatSama/vue-slider-component">vue-slider-component</a>-vue1.x 和 vue2.x 的滑块。</li><li><a href="https://github.com/devstark-com/vue-circle-slider">vue-circle-slider</a>-vue2.x 的圆形滑块组件。</li><li><a href="https://github.com/fanyeh/vue-slider">vue-netflix-slider</a>-像 Netflix 的滑块。</li><li><a href="https://github.com/biigpongsatorn/vue-slide-bar">vue-slide-bar</a>-非常简单的 vue 滑条组件。</li><li><a href="https://github.com/hosein2398/Textra">textra</a>-Vue js 插件可滑动文本。</li><li><a href="https://github.com/kramer99/vue-knob-control">vue-knob-control</a>-Vue.js 的旋钮控件</li></ul><h2 id="拖放"><a href="#拖放" class="headerlink" title="拖放"></a>拖放</h2><ul><li><a href="https://github.com/SortableJS/Vue.Draggable">vuedraggable</a>-Vue 组件允许与 View-Model 同步进行拖放排序。基于 Sortable.js。</li><li><a href="https://github.com/Astray-git/vue-dragula">vue-dragula</a>-拖放是如此简单，很痛苦。</li><li><a href="https://github.com/kristianmandrup/vue2-dragula">vue2-dragula</a>-Vue2 的<code>vue-dragula</code>分支，有很多改进。</li><li><a href="https://github.com/hilongjw/vue-dragging">awe-dnd</a>-具有 Vue 的可排序列表指令。</li><li><a href="https://github.com/mauricius/vue-draggable-resizable">vue-draggable-resizable</a>-用于可拖动和可调整大小元素的 Vue2 组件。</li><li><a href="https://github.com/hejianxian/vddl">vddl</a>-用于使用 HTML5 拖放 API 修改列表的 Vue 组件，支持 VueJs 版本 1 和 2。</li><li><a href="https://github.com/cameronhimself/vue-drag-drop">vue-drag-drop</a>-HTML5 拖放 API 的最小且轻巧的包装器。</li><li><a href="https://github.com/goweiwen/vue-swing">vue-swing</a>-可滑动的卡片界面，如在 Jelly 和 Tinder 等应用中所见。</li><li><a href="https://github.com/Jexordexan/vue-slicksort">vue-slicksort</a>-一套无需依赖的混合包，用于动画，触摸友好，可排序的列表</li><li><a href="https://github.com/IsraelZablianov/draggable-vue-directive">draggable-vue-directive</a>-处理任何 Vue 组件拖放的简单指令。</li><li><a href="https://github.com/kutlugsahin/vue-smooth-dnd">vue-smooth-dnd</a>-smooth-dnd 库的 Vue 包装器。拖放，可分类的库，适用于许多情况。</li><li><a href="https://github.com/kirillmurashov/vue-drag-resize">vue-drag-resize</a>-一个无依赖的 Vue 组件，用于可拖动和可调整大小的元素，具有高宽比，反应性道具等</li><li><a href="https://github.com/Esvalirion/vue-drag-it-dude">vue-drag-it-dude</a>-Vue2 组件，可让您将对象拖动到任意位置。</li><li><a href="https://github.com/Vivify-Ideas/vue-draggable">vue-draggable</a>-Vue 拖放库没有任何依赖性。简单易用。</li><li><a href="https://github.com/rhwilr/vue-nestable">vue-nestable</a>-作为 vue 组件制作的简单拖放层次列表。</li><li><a href="https://github.com/phphe/vue-draggable-nested-tree">vue-draggable-nested-tree</a>-适用于 Vuejs2 [@phphe](<a href="https://github.com的功能强大的可自定义可拖动树视图组件./">https://github.com的功能强大的可自定义可拖动树视图组件。</a> com &#x2F; phphe)</li></ul><h2 id="自动完成"><a href="#自动完成" class="headerlink" title="自动完成"></a>自动完成</h2><ul><li><a href="https://github.com/santiblanko/vue-instant">vue-instant</a>-Vue 即时可让您轻松为 vue 2 应用程序创建带有自动建议的自定义搜索控件。</li><li><a href="https://github.com/paliari/v-autocomplete">v-autocomplete</a>-Vue.js 的自动填充组件</li><li><a href="https://github.com/sandi-racy/vue-awesomplete">vue-awesomplete</a>-Awesomplete 的 Vue 包装器</li><li><a href="https://github.com/charliekassel/vuejs-autocomplete">vue-auto-complete</a>-Vue2 的自动完成。适用于对象或 api 调用。</li><li><a href="https://github.com/Educents/vue-autosuggest">vue-autosuggest</a>-WAI-ARIA 完整的 Autosuggest 组件，对渲染和样式进行了完全自定义。</li><li><a href="https://github.com/soraino/v-autosuggest">v-autosuggest</a>-一个简单的模块化 Vuejs 组件，可以自动建议来自动态或静态数据查询的输入。</li><li><a href="https://github.com/ieski/AutoComplete">自动完成</a>-适用于 Vue.js 2. *的简单自动完成组件</li><li><a href="https://github.com/Attrash-Islam/vue-infinite-autocomplete">vue-infinite-autocomplete</a>-Vue 的 Vue 无限-自动完成包装 2。</li><li><a href="https://github.com/KazanExpress/vue-simple-suggest">vue-simple-suggest</a>-Vue.js 的简单但功能丰富的自动完成组件</li><li><a href="https://github.com/TerryZ/v-suggest">v-suggest</a>-一个 Vue2 插件，用于输入内容建议，支持键盘快速选择。</li><li><a href="https://github.com/alexurquhart/vue-bootstrap-typeahead">vue-bootstrap-typeahead</a>-使用 Bootstrap 4 CSS 的 Vue2 的 typeahead &#x2F; autocomplete 组件。</li></ul><h2 id="类型选择"><a href="#类型选择" class="headerlink" title="类型选择"></a>类型选择</h2><ul><li><a href="https://github.com/matiastucci/vue-input-tag">vue-input-tag</a>-Vue.js 2.0 输入标签组件。</li><li><a href="https://github.com/jcc/v-distpicker">v-distpicker</a>一个灵活，高度可用的区域选择器，用于为 Vue.js 2.x 挑选中国的省，市和地区。</li><li><a href="https://github.com/waynecz/vue-img-inputer">vue-img-inputer</a>Vue 2 的优美，高度可定制的 img 类型输入</li><li><a href="https://github.com/dameety/vue-image-preview">vue-img-preview</a>vue 2 中的图像输入预览组件</li><li><a href="https://github.com/vinayakkulkarni/v-image">v-image</a>：相机：用于输入 type &#x3D; file 的小组件(&lt;1kb，已压缩)</li><li><a href="https://github.com/AlexMordred/vue-tagsinput">@ voerro &#x2F; vue-tagsinput</a>一个简单的标签输入了带有 typeahead &#x2F; autocomplete 的 Vue.js 2 组件</li><li><a href="https://github.com/tomquinonero/vue-tag-selector">vue-tag-selector</a>-类似于标签的输入。轻巧，可自定义并处理 REGEX 验证！</li></ul><h2 id="颜色选择器"><a href="#颜色选择器" class="headerlink" title="颜色选择器"></a>颜色选择器</h2><ul><li><a href="https://github.com/xiaokaike/vue-color">vue-color</a>-适用于 Sketch，Photoshop，Chrome 等的 Vue 拾色器。</li><li><a href="https://github.com/saintplay/vue-swatches">vue-swatches</a>-帮助用户选择漂亮的颜色！</li><li><a href="https://github.com/radial-color-picker/vue-color-picker">radial-color-picker</a>-简约的拾色器，着重于尺寸，可访问性和性能。</li><li><a href="https://github.com/shlomnissan/vue-color-picker-board">vue-color-picker-board</a>-为人类设计的 Vue 拾色器组件！</li><li><a href="https://github.com/baianat/verte">verte</a>-一个完整的 Vue.js 颜色选择器组件。</li></ul><h2 id="开关"><a href="#开关" class="headerlink" title="开关"></a>开关</h2><ul><li><a href="https://github.com/drewjbartlett/vue-switches">vue-switches</a>-具有主题支持的 Vue.js 的开&#x2F;关开关组件。</li><li><a href="https://github.com/euvl/vue-js-toggle-button">vue-js-toggle-button</a>-Vue.js 2.0+切换&#x2F;切换按钮-简单，漂亮，可自定义。</li><li><a href="https://github.com/mariomka/vue-checkbox-radio">vue-checkbox-radio</a>-一个 Vue 组件，可轻松设置复选框和广播输入的样式。</li><li><a href="https://github.com/Keiwen/vue-enhancedCheck">vue-enhanced-check</a>-用于重新设计&#x2F;标记复选框&#x2F;无线电的 Vue 组件，包括切换&#x2F;切换按钮。</li><li><a href="https://github.com/hamed-ehtesham/pretty-checkbox-vue">pretty-checkbox-vue</a>- [pretty-checkbox 3]的实现(<a href="https://lokesh-coder.github.io/pretty-">https://lokesh-coder.github.io/pretty-</a> checkbox &#x2F;)(用于美化复选框和单选按钮的纯 CSS 库)组件，适用于 Vue.js 2.2+。</li><li><a href="https://github.com/roszpun/vue-collapse/">vue2-collapse</a>-Vue Collapse 是一个灵活的内容切换插件，用于手风琴列表或任何其他有条件的内容呈现。</li><li><a href="https://github.com/vanderb/vue-badger-accordion">vue-badger-accordion</a>-用于 Vue.js 2.0+的 Badger 手风琴的包装组件</li><li><a href="https://github.com/Carrene/vue-loading-checkbox">vue-loading-checkbox</a>-具有加载状态的高度可定制的 Vue.js 复选框 UI 组件</li><li><a href="https://github.com/DannyFeliz/vue-rocker-switch">vue-rocker-switch</a>-Vue.js 的可自定义翘板开关组件。</li><li><a href="https://github.com/JonathanDn/vue-toggle-btn">vue-toggle-btn</a>-高度可定制，易于使用的优雅切换&#x2F;切换按钮组件</li></ul><h2 id="屏蔽输入"><a href="#屏蔽输入" class="headerlink" title="屏蔽输入"></a>屏蔽输入</h2><ul><li><a href="https://github.com/niksmr/vue-masked-input">vue-masked-input</a>-Vue.js 的蒙版输入组件。</li><li><a href="https://github.com/text-mask/text-mask">vue-text-mask</a>-用于 React，Angular，Ember，Vue 和普通 JavaScript 的输入掩码。</li><li><a href="https://github.com/lakb248/vue-ip-input">vue-ip-input</a>-由 vuejs 实现的 ip 输入。</li><li><a href="https://github.com/kevinongko/vue-numeric">vue-numeric</a>-输入字段组件，用于显示基于 Vue 的货币值。</li><li><a href="https://github.com/moip/awesome-mask">awesome-mask</a>-基于纯 VanillaJS 实现的 Mask 指令</li><li><a href="https://github.com/vuejs-tips/v-money">v-money</a>-货币的微小(&lt;2k 压缩)输入&#x2F;指令掩码</li><li><a href="https://github.com/autoNumeric/vue-autoNumeric">vue-autonumeric</a>-一个 Vue.js 组件，包装了很棒的<a href="http://autonumeric.org/">AutoNumeric</a>输入格式化程序库</li><li><a href="https://github.com/scleriot/vue-inputmask">vue-inputmask</a>-Vue.js 指令可将 Robin Herbots 的 inputmask 库添加到您的输入中(香草 javascript)。</li><li><a href="https://github.com/joseluisq/vue-input-number">vue-input-number</a>-Vue.js 2 的自定义输入数字组件。</li><li><a href="https://github.com/ndelvalle/v-unicode">v-unicode</a>-Vue 指令通过 unicode 值限制输入。</li><li><a href="https://github.com/ankurk91/vue-cleave-component">vue-cleave-component</a>- [cleave.js]的 Vue.js 组件(<a href="http://nosir.github.io/cleave.js">http://nosir.github.io/cleave.js</a> &#x2F;)</li><li><a href="https://github.com/peteringram0/vue-ip">vue-ip</a>-具有端口和材料设计支持的 ip 地址输入</li><li><a href="https://github.com/raidan00/vue-r-mask">vue-r-mask</a>-具有类似于 javascript 正则表达式的模板的指令。</li><li><a href="https://github.com/zhouyuexie/vue-input-code">vue-input-code</a>-基于 Vue.js 2.0+验证码输入组件。</li><li><a href="https://github.com/myokyawhtun/label-edit">label-edit</a>-受 Trello 的启发。单击以显示可编辑的输入并返回值更改。这是 Vue 组件。</li><li><a href="https://github.com/ankurk91/vue-jquery-mask">vue-jquery-mask</a>- [jQuery Mask 插件]的 Vue.js v2.x 组件(<a href="https://github.com/igorescobar/">https://github.com/igorescobar/</a> jQuery-掩码-插件)</li><li><a href="https://github.com/vuejs-tips/vue-the-mask">vue-the-mask</a>-Tiny(&lt;2k gzipipped)和 Vue.js 的无依赖掩码输入</li><li><a href="https://github.com/loo41/vuc">vue-canvas-input</a>- [vuc-input]的 Vue 画布组件(<a href="http://vuc.tianchenyong.top/#/identify">http://vuc.tianchenyong.top/#/identify</a>)</li><li><a href="https://github.com/dm4t2/vue-currency-input">vue-currency-input</a>-轻松输入 Vue.js 的货币格式数字。</li><li><a href="https://github.com/Scrum/vue-restricted-input">vue-restricted-input</a>-基于[restricted-input]的 vue.js 输入掩码库(<a href="https://github.com/braintree">https://github.com/braintree</a> &#x2F;受限输入)</li></ul><h2 id="RTF-编辑"><a href="#RTF-编辑" class="headerlink" title="RTF 编辑"></a>RTF 编辑</h2><ul><li><a href="https://github.com/surmon-china/vue-quill-editor">vue-quill-editor</a>-Vue2 的鹅毛笔编辑器组件。</li><li><a href="https://github.com/alidcastano/vue-mobiledoc-editor">vue-mobiledoc-editor</a>-适用于 Vuejs 的 mobiledoc 编辑器组件工具包。</li><li><a href="https://github.com/FranzSkuffka/vue-medium-editor">vue2-medium-editor</a>-Vue 2 的 MediumEditor 组件。</li><li><a href="https://github.com/helpbase/vue-froala">vue-froala</a>-用于 Froala 编辑器的 VueJS 包装器。</li><li><a href="https://github.com/froala/vue-froala-wysiwyg">vue-froala-wysiwyg</a>-Froala WYSIWIG HTML 编辑器的官方 VueJS 插件。</li><li><a href="https://github.com/fritx/vue-at">vue-at</a>-Vue 的 At.js。</li><li><a href="https://github.com/chmln/vue-wysiwyg">vue-wysiwyg</a>轻巧，快速且可扩展的所见即所得编辑器</li><li><a href="https://github.com/ankurk91/vue-trumbowyg">vue-trumbowyg</a>[Trumbowyg]的 Vue.js 组件(<a href="http://alex-d.github.io/Trumbowyg/)%E6%89%80%E8%A7%81%E5%8D%B3%E6%89%80%E5%BE%97%E7%BC%96%E8%BE%91%E5%99%A8">http://alex-d.github.io/Trumbowyg/)所见即所得编辑器</a></li><li><a href="https://github.com/CinKon/vue-pell-editor">vue-pell-editor</a>用于<a href="https://jaredreich.com/pell">Pell</a>的 Vue.js 组件所见即所得编辑器</li><li><a href="https://github.com/dyonir/vue-tinymce-editor">vue-tinymce-editor</a>Vue2 的 Tinymce 编辑器组件。</li><li><a href="https://github.com/Eazymov/vue-mce">vue-mce</a>-VueJS 的 tinymce 编辑器组件。</li><li><a href="https://github.com/davidroyer/vue2-editor">Vue2-Editor</a>-使用 Vue.js 和 Quilljs 的 HTML 编辑器</li><li><a href="https://github.com/surmon-china/vue-codemirror">vue-codemirror</a>-Vue2 的 Codemirror 组件。</li><li><a href="https://github.com/m3esma/vue-easy-tinymce">vue-easy-tinymce</a>-一个简单而强大的软件包，可在 Vue.js 项目中轻松使用 tinymce。</li><li><a href="https://github.com/SyedWasiHaider/vue-highlightable-input">vue-highlightable-input</a>-输入文字时突出显示和设置样式</li><li><a href="https://github.com/hanhdt/vue-trix">vue-trix</a>-用于 Vue.js 的简单轻巧的 Trix 富文本编辑器</li><li><a href="https://github.com/heyscrumpy/tiptap">tiptap</a>-Vue.js 的不可渲染且可扩展的 RTF 编辑器</li><li><a href="https://github.com/nhnent/toast-ui.vue-editor">toast-ui.vue-editor</a>- [TOAST UI 编辑器]的 Vue 包装器(<a href="http://ui.toast.com/tui">http://ui.toast.com/tui</a> -编辑)。</li><li><a href="https://github.com/ckeditor/ckeditor5-vue">ckeditor5-vue</a>-Vue.js 的官方 CKEditor 5 Rich Text 编辑器组件。</li><li><a href="https://github.com/yimogit/yimo-vue-editor">yimo-vue-editor</a>-Vue2 的 wangEditor2 组件。</li><li><a href="https://github.com/arnog/vue-mathlive">vue-mathlive</a>适用于 Vue.hjs 的 MathLive 数学编辑器(mathfield)</li></ul><h2 id="图像处理"><a href="#图像处理" class="headerlink" title="图像处理"></a>图像处理</h2><ul><li><a href="https://github.com/Vanthink-UED/vue-core-image-upload">vue-core-image-upload</a>-一个用于裁剪和上传图像的 vue 插件。</li><li><a href="https://github.com/zhanziyang/vue-croppa">vue-croppa</a>-适用于 Vue 2.0 的简单易用的可自定义轻量级移动友好图像裁剪器。</li><li><a href="https://github.com/xyxiao001/vue-cropper">vue-cropper</a>-vue2.0 的图片剪辑插件</li><li><a href="https://github.com/nhnent/toast-ui.vue-image-editor">toast-ui.vue-image-editor</a>- [TOAST UI 图像编辑器]的 Vue 包装器(http：&#x2F;&#x2F; ui。 toast.com&#x2F;tui-image-editor)。</li><li><a href="https://github.com/duyanpeng/vue-quick-cropper">vue-quick-cropper</a>-Vue 移动头像上传裁剪插件可以选择裁剪区域和缩放。</li><li><a href="https://github.com/loo41/vuc">vue-canvas-image</a>-Vue 画布组件，用于<a href="http://vuc.tianchenyong.top/#/image">vuc-image</a></li><li><a href="https://github.com/jofftiquez/vue-croppie">vue-croppie</a>-另一个图像裁剪器</li><li><a href="https://github.com/wannaxiao/vue-slim-cropper">vue-slim-cropper</a>-💇Vue 2.x 的简单优雅的移动图像裁剪上传组件。</li><li><a href="https://github.com/Norserium/vue-advanced-cropper">vue-advanced-cropper</a>-先进的裁剪器，使您有机会创建几乎任何想要的裁剪器</li><li><a href="https://github.com/diegopamio/vue-cloudinary">vue-cloudinary</a>-vue(2.0)插件提供了可重用的指令，可通过动态操作从 Cloudinary(<a href="https://cloudinary.com)获取图像(调整大小/%E8%A3%81%E5%89%AA/%E6%95%88%E6%9E%9C/%E6%B0%B4%E5%8D%B0/%E7%BC%A9%E6%94%BE/%E6%A0%BC%E5%BC%8F%E5%8C%96)%E5%92%8C%E4%BC%98%E5%8C%96">https://cloudinary.com)获取图像(调整大小/裁剪/效果/水印/缩放/格式化)和优化</a>(webp &#x2F; png &#x2F;自动质量&#x2F;自动视网膜)。</li><li><a href="https://github.com/ssshooter/img-vuer">img-Vuer</a>-Vue2 的 Mobile-First 图像查看器&#x2F;图库</li><li><a href="https://github.com/kevindesousa/vue-image-loader">vue-image-loader</a>-Vue 加载器&#x2F;渐进式图像插件，例如 Medium。</li><li><a href="https://github.com/john015/vue-load-image">vue-load-image</a>-在图像加载期间显示加载器，并在图像加载失败时显示替代内容。</li><li><a href="https://github.com/wannaxiao/vue-image-painter">vue-image-painter</a>-V Vue 2.x 的图像魔术动画绘制效果组件。</li></ul><h2 id="视频操作"><a href="#视频操作" class="headerlink" title="视频操作"></a>视频操作</h2><ul><li><a href="https://github.com/MishaPetrov/vue-playlist">vue-playlist</a>-轻量级的 vue(2.0)组件，没有依赖关系，可提供真正无缝的 html5 视频播放。使用 Vanilla JS 进行无缝视频播放的唯一且唯一可行的解 决方案。它需要一系列视频并将它们拼接在一起成为一个视频。</li></ul><p>＃＃ 上传文件</p><ul><li><a href="https://github.com/thetutlage/vue-clip">vue-clip</a>-用于 VueJ 的简单且可入侵的文件上传器。支持 Vue&gt; &#x3D; 2.1。</li><li><a href="https://github.com/saivarunk/vue-simple-upload">vue-simple-upload</a>-Vue.js 的简单文件上传组件。</li><li><a href="https://github.com/updivision/vue2-multi-uploader">vue2-multi-uploader</a>-使用 Vue.js v2 和 Axios 的拖放式多文件上传器组件。上载器显示文件名，大小和添加文件的总大小。它还允许设置所需的最小文件上传数量。</li><li><a href="https://github.com/rowanwins/vue-dropzone">vue-dropzone</a>-Dropzone.js 的 Vue.js(vue2)组件-具有图像预览功能的拖放文件上传实用程序。</li><li><a href="https://github.com/alexsasharegan/vue-transmit">vue-transmit</a>-一个纯粹的基于 Vue 2.0 的 Dropzone.js 的 Vue.js 拖放上传器组件</li><li><a href="https://github.com/lian-yue/vue-upload-component">vue-upload-component</a>-Vue 上载组件，多文件上载，上载目录，拖动上载，拖动目录。支持 Vue&gt; &#x3D; 2.0</li><li><a href="https://github.com/simple-uploader/vue-uploader">vue-uploader</a>-一个由 simple-uploader.js 驱动的 Vue.js 上传组件</li><li><a href="https://github.com/InCuca/ic-firebase-uploader">ic-firebase-uploader</a>-用于 Firebase 存储的干净的多文件上传组件。</li><li><a href="https://github.com/charliekassel/vuejs-uploader">vuejs-uploader</a>-用于大型文件上传的可恢复的分段文件上传器。</li><li><a href="https://github.com/pqina/vue-filepond">vue-filepond</a>-FilePond 的 Vue.js 组件-文件上传库，可以上传您扔给它的任何内容。</li><li><a href="https://github.com/TerryZ/v-uploader">v-uploader</a>-一个 Vue2 插件，可以使上传文件变得更加轻松简单，您可以拖动文件或在对话框中选择文件进行上传</li></ul><h2 id="上下文菜单"><a href="#上下文菜单" class="headerlink" title="上下文菜单"></a>上下文菜单</h2><ul><li><a href="https://github.com/vmaimone/vue-context-menu">vue-context-menu</a>-vue js 的上下文菜单组件。</li><li><a href="https://github.com/timwis/vue-lil-context-menu">vue-lil-context-menu</a>-Vue 的灵活的 lil 上下文菜单组件。</li><li><a href="https://github.com/zgj233/vue-mouse-menu">vue-mouse-menu</a>-适用于 vue 2+的鼠标菜单组件。</li><li><a href="https://github.com/michitaro/vue-menu">@ hscmap &#x2F; vue-menu</a>-vue2 的菜单&#x2F;上下文菜单组件。</li><li><a href="https://github.com/rawilk/vue-context">vue-context</a>-用于 vue js 的简单但灵活的上下文菜单。</li><li><a href="https://github.com/johndatserakis/vue-simple-context-menu">vue-simple-context-menu</a>-为 Vue 构建的简单上下文菜单组件。左键单击和右键单击都可以很好地工作。</li><li><a href="https://github.com/Johnathan/vue-context-menu-popup">vue-context-menu-popup</a>-Vue 2 的上下文菜单弹出窗口。右键单击即可工作，也可以通过编程方式触发。</li><li><a href="https://github.com/Kiyoaki-w/Ki-vue-context">@ kiyoaki_w &#x2F; vue-context</a>-为 Vue2 构建的可自定义上下文菜单组件，支持惊人的图标。</li></ul><h2 id="其他-1"><a href="#其他-1" class="headerlink" title="其他"></a>其他</h2><ul><li><a href="https://github.com/ridermansb/vue-gmaps">vue-gmaps</a>-使用 Google Maps API 搜索地点和地址。</li><li><a href="https://github.com/QingWei-Li/vuep">vuep</a>-使用实时编辑器和预览渲染 Vue 组件的组件。</li><li><a href="https://github.com/Gomah/vue-places">vue-places</a>-Places 组件基于 Vue 2.x 的 places.js。将任何输入转换为地址自动完成。</li><li><a href="https://github.com/apertureless/vue-password-strength-meter">vue-password-strength-meter</a>-vue.js 中基于 zxcvbn 的密码强度计。</li><li><a href="https://github.com/bkzl/vue-float-label">vue-float-label</a>-Vue.js 的浮动标签模式。</li><li><a href="https://github.com/javisperez/vuelongpress">vue-longpress</a>-一个 VueJS(2.x)按钮组件，需要您持续按下以确认给定的动作。</li><li><a href="https://github.com/olefirenko/vue-google-autocomplete">vue-google-autocomplete</a>-适用于 Google Maps Places API 的 Vue.js(2.x)自动建议组件。</li><li><a href="https://github.com/lakb248/vue-ip-input">vue-ip-input</a>-Vue.js 2.x 的 ip 输入组件</li><li><a href="https://github.com/termosa/vue-default-value">vue-default-value</a>-Vue.js 2.x 指令为可编辑元素设置默认值，而不会影响模型状态</li><li><a href="https://github.com/outluch/vue-model-autoset">vue-model-autoset</a>-一个 Vue.js 插件，可解决通过 v-model 指令观察动态添加的属性时 Vue 的限制</li><li><a href="https://github.com/NxtChg/pieces/tree/master/js/vue/vue-submit">vue-submit</a>-Ladda 的简单实现([1](<a href="http://lab.hakim.se/">http://lab.hakim.se</a> &#x2F;ladda&#x2F;)，<a href="https://msurguy.github.io/ladda-bootstrap/">2</a>)不到 90 行代码，没有任何依赖关系。</li><li><a href="https://github.com/SinanMtl/vue-rate">vue-rate</a>-Vue 的费率组件</li><li><a href="https://github.com/MadimetjaShika/vuetify-google-autocomplete">vuetify-google-autocomplete</a>-适用于 Google Maps Places API 的 Vuetify 就绪 Vue.js(2.x)自动建议组件。</li><li><a href="https://github.com/PygmySlowLoris/vue-ripple-directive">vue-ripple-directive</a>-材质纹波效果作为 Vue 指令。</li><li><a href="https://github.com/PygmySlowLoris/vue-fab">vue-fab</a>-Vue 浮动操作按钮。</li><li><a href="https://github.com/mazipan/vue-complexify">vue-complexify</a>-来自 jquery.complexify.js 的 Vuejs 移植库。</li><li><a href="https://github.com/FiguredLimited/vue-mc">vue-mc</a>-Vue.js 的模型和集合</li><li><a href="https://www.tallent.us/vue-stars/">vue-stars</a>-高度可定制的等级控制(使用星号或其他字符)</li><li><a href="https://github.com/imRohan/vue-confirmation-button">vue-confirmation-button</a>-可自定义的确认按钮，要求用户在执行操作之前先阅读消息</li><li><a href="https://github.com/ppietris/vue-poll">vue-poll</a>-用于投票的 Vue.js 组件</li><li><a href="https://github.com/gwenaelp/vue-diagrams">vue-diagrams</a>-vue.js 的图表组件，受 react-diagrams 启发</li><li><a href="https://github.com/updivision/vue-easy-polls">vue-easy-polls</a>-一个 Vue.js 组件，用于创建民意调查，投票和显示结果。它易于实现且易于定制。</li><li><a href="https://github.com/mengdu/m-button">vue-m-button</a>-vue 的漂亮按钮组件。</li><li><a href="https://github.com/ittus/vue-long-click">vue-long-click</a>-用于 vue 的长按(长按)指令库，支持移动设备和台式机。</li><li><a href="https://github.com/FGRibreau/ui-predicate/tree/master/packages/ui-predicate-vue">vue-ui-predicate</a>-规则编辑器，通用过滤 UI，Vue JS 的谓词组件。</li><li><a href="https://github.com/ajerez/vue-mobile-detection">vue-mobile-detection</a>-Vue.js 原型函数<code>this。$ isMobile()</code>会根据布尔值是否返回布尔值用户正在使用手机浏览。</li><li><a href="https://github.com/Cobertos/vue-input-contenteditable">vue-input-contenteditable</a>-用于&#96;contenteditable’的 Vue 组件包装，具有您通常期望的所有功能。进行漂亮的输入，不受“ input [type &#x3D;’text’]”的限制。</li></ul><h2 id="向导"><a href="#向导" class="headerlink" title="向导"></a>向导</h2><ul><li><a href="https://github.com/cristijora/vue-form-wizard">vue-form-wizard</a>-基于选项卡的组件，可以代替经典的 bootstrap 和 jQuery 表单向导</li><li><a href="https://github.com/PygmySlowLoris/vue-stepper">vue-stepper</a>-一个简单的步进器，具有诸如 next，back 和 end 之类的简单动作，可以执行简单的表单。</li><li><a href="https://github.com/adi518/vue-stepper-component">vue-stepper-component</a>-具有 Vuex 支持和零依赖性的完全可定制的 Stepper 组件。</li></ul><h2 id="CSV"><a href="#CSV" class="headerlink" title="CSV"></a>CSV</h2><ul><li><a href="https://github.com/ynishi/vuecsv">vuecsv</a>-来自 json 的简单 CSV 下载程序，带有选项模式面板组件。</li></ul><h2 id="评论系统"><a href="#评论系统" class="headerlink" title="评论系统"></a>评论系统</h2><ul><li><a href="https://github.com/TugayYaldiz/vue-comment-grid">vue-comment-grid</a>-💬 使用 CSS Grid 和 Firebase REST API + Authentication 构建的自适应 Vue.js 注释系统插件。</li></ul><h2 id="帆布"><a href="#帆布" class="headerlink" title="帆布"></a>帆布</h2><ul><li><a href="http://github.com/dankuck/vue-easeljs">vue-easeljs</a>-对 HTML5 canvas 元素的数据驱动控制。</li><li><a href="https://github.com/chenxuan0000/vue-canvas-effect">vue-canvas-effect</a>-Vue.js 的简单画布效果集合。</li><li><a href="https://github.com/rafaesc/vue-konva">vue-konva</a>-Vue＆Canvas-JavaScript 库，用于使用 Vue 绘制复杂的画布图形。</li><li><a href="https://github.com/mycure-inc/vue-html2canvas">vue-html2canvas</a>-Vue mixin 捕获 html 并使用 Html2Canvas 将其转换为图像。</li><li><a href="https://github.com/ZYSzys/vue-canvas-nest">vue-canvas-nest</a>-适用于 canvas-nest 的 Vue.js 组件。</li><li><a href="https://github.com/neighborhood999/vue-signature-pad">vue-signature-pad</a>-V Vue 签名板组件</li></ul><h2 id="链接预览"><a href="#链接预览" class="headerlink" title="链接预览"></a>链接预览</h2><ul><li><a href="https://github.com/nivaldomartinez/link-prevue">link-prevue</a>-用于生成链接预览的灵活组件。</li></ul><h2 id="游览"><a href="#游览" class="headerlink" title="游览"></a>游览</h2><ul><li><a href="https://github.com/pulsardev/vue-tour">vue-tour</a>-轻巧且可自定义的游览插件</li><li><a href="https://github.com/sschandi/vue-page-guide">vue-page-guide</a>-具有指令的页面游览&#x2F;指南插件</li></ul><h2 id="UI-布局"><a href="#UI-布局" class="headerlink" title="UI 布局"></a>UI 布局</h2><ul><li><a href="https://github.com/MopTym/vue-waterfall">vue-waterfall</a>-Vue.js 的瀑布布局组件。</li><li><a href="https://github.com/David-Desmaisons/Vue.Isotope">vueisotope</a>-用于同位素过滤器和分类魔术布局的 Vue 组件。</li><li><a href="https://github.com/jbaysolutions/vue-grid-layout">vue-grid-layout</a>-Vue.js 的可拖动和可调整大小的网格布局。</li><li><a href="https://github.com/surmon-china/vue-drag-zone">vue-drag-zone</a>-Vue.js(2.x)的拖动区域组件。</li><li><a href="https://github.com/shershen08/vue-masonry">vue-masonry</a>-用于砌体块布局的 Vue.js 指令。</li><li><a href="https://github.com/bkzl/vue-fraction-grid">vue-fraction-grid</a>-基于 Flexbox 的 Vue.js 响应式分数网格系统。</li><li><a href="https://github.com/tangbc/vue-virtual-scroll-list">vue-virtual-scroll-list</a>-Vue(2.x)组件通过使用虚拟滚动列表支持大数据。</li><li><a href="https://github.com/Akryum/vue-virtual-scroller">vue-virtual-scroller</a>-用于有效滚动大量元素的组件(Vue 2.x)。</li><li><a href="https://github.com/ddgll/vue-virtualscroll">vue-virtualscroll</a>- [Vue 2.x]组件用于虚拟滚动内容。</li><li><a href="https://github.com/rachmanzz/vue-inview">vue-inview</a>- [Vue 2.x]视口，在输入或离开 DOM 元素时获取通知。</li><li><a href="https://github.com/dattn/dnd-grid">dnd-grid</a>-具有可拖动和可调整大小的框的 vuejs 网格</li><li><a href="https://github.com/ktquez/vue-extend-layout">vue-extend-layout</a>-扩展默认布局或为 Vue.js SPA 的页面创建自定义布局</li><li><a href="https://github.com/paulcollett/vue-masonry-css">vue-masonry-css</a>-由 CSS 驱动的 Vue.js Masonry 布局组件，无依赖</li><li><a href="https://github.com/alvarotrigo/vue-fullpage.js">vue-fullpage.js</a>-Vue.js 的官方 fullPage.js 组件。</li><li><a href="https://github.com/starkwang/vue-virtual-collection">vue-virtual-collection</a>-用于有效渲染大型集合数据的 Vue 组件。</li><li><a href="https://github.com/xudafeng/autosensitive-vue">自动响应-vue</a>-Vue 的自动响应网格布局库。</li><li><a href="https://github.com/SeregPie/VueFlex">VueFlex</a>-一个 flexbox 网格系统。</li><li><a href="https://gitlab.com/shellyBits/v-chacheli">v-chacheli</a>-一个 Vue.js 组件，用于创建和显示类似于仪表板的自定义网格布局。</li><li><a href="https://github.com/mattrothenberg/vue-grid-styled">vue-grid-styled</a>-一组轻量级的功能网格组件，从 React 的<a href="https://github.com移植/">grid-styled</a> &#x2F; jxnblk &#x2F;网格样式&#x2F;)</li><li><a href="https://github.com/anthinkingcoder/simple-grid">简单网格</a>-用于网格布局的 Vue 组件，支持 flex。</li><li><a href="https://github.com/kavalcante/vue-container-component">vue-container-component</a>-受 Bootstrap 容器启发的简单容器组件</li><li><a href="https://github.com/alexiscolin/vue-colcade">vue-colcade</a>-用于将 Colcade 网格布局集成到 Vuejs 的小包装。</li><li><a href="https://github.com/arnedesmedt/vue-ads-layout">vue-ads-layout</a>-一个小的 Vue 组件库，可快速生成带有工具栏，左&#x2F;右抽屉和页脚的响应式 Web 应用程序布局。所有组件都可以固定或相对放置。</li><li><a href="https://github.com/imlinus/Vue-Magic-Grid">vue-magic-grid</a>-Vue.js 2 的 Magic Grid 小端口。</li><li><a href="https://github.com/venkatperi/vue-splitter-pane">vue-splitter-pane</a>-一个 Vuejs 组件，它以可调节的拆分方式(垂直或水平)呈现两个插槽。</li><li><a href="https://github.com/antoniandre/splitpanes">splitpanes</a>-一个 Vue JS 可靠，简单且可触摸的窗格拆分器&#x2F;缩放器。</li><li><a href="https://github.com/promosis/vue-mock-layout">vue-mock-layout</a>-轻松模拟 Vue 应用程序的布局。</li><li><a href="https://github.com/dreambo8563/vue-simple-drawer">vue-simple-drawer</a>-带有反弹动画，支持嵌套和自定义主题的小抽屉面板。方向：左&#x2F;右&#x2F;上&#x2F;下</li><li><a href="https://github.com/1000ch/vue-grd">vue-grd</a>-用于网格布局的简单，轻巧和灵活的 Vue.js 组件。</li></ul><h2 id="自适应"><a href="#自适应" class="headerlink" title="自适应"></a>自适应</h2><ul><li><a href="https://github.com/quasarframework/quasar">quasar-framework</a>-类星体框架。使用 VueJs 2 使用相同的代码构建响应式网站，混合移动应用程序(在 Android 和 iOS 上看起来本机)和 Electron 应用程序。</li><li><a href="https://github.com/vuematerial/vue-material">vue-material</a>-Vue.js 的材料设计。</li><li><a href="https://github.com/vuetifyjs/vuetify">vuetify</a>-Vue.js 的材料组件框架 2。</li><li><a href="https://github.com/museui/muse-ui">muse-ui</a>-Vue.js 的材料组件库 2。</li><li><a href="https://github.com/rafaelpimpa/buefy">buefy</a>-基于布尔玛框架的组件。</li><li><a href="https://github.com/ElemeFE/element">element-ui</a>-用于 Web 的 Vue.js 2.0 UI 工具包。</li><li><a href="https://github.com/vouill/vue-bulma-components">vue-bulma-components</a>-对 vue 组件轻松使用 bulma 类语法。</li><li><a href="https://www.iviewui.com/">iview-ui</a>-适用于 Web 的 Vue.js 2.0 UI 框架。</li><li><a href="https://at.aotu.io/">AT-UI</a>-Vue.js 2.0 使用 ♥ 制作的专门用于桌面应用程序的全新扁平 UI-Kit</li><li><a href="https://www.npmjs.com/package/v-semantic">v-semantic</a>-Vue 的<a href="https://semantic-ui.com/">semantic-ui</a>的实现</li><li><a href="https://bootstrap-vue.github.io/">bootstrap-vue</a>-Vue.js 2 的<a href="https://getbootstrap.com/">bootstrap-4</a>网格和组件的实现。</li><li><a href="https://myliang.github.io/fish-ui">fish-ui</a>-用于 Web 的 Vue.js 2.0 UI 工具包</li><li><a href="https://github.com/zircleUI/zircleUI">zircle-ui</a>-开发可缩放用户界面的前端库。</li><li><a href="https://github.com/stasson/vue-mdc-adapter">vue-mdc-adapter</a>-根据 MDC 团队[指南]的 Vue.js 的材料组件集成(<a href="https://github.com/material">https://github.com/material</a> -components &#x2F; material-components-web &#x2F; blob &#x2F; master &#x2F; docs &#x2F; integrating-into-frameworks.md)。</li><li><a href="https://github.com/matsp/material-components-vue">Material Components Vue</a>- [material-components-web]的包装器(<a href="https://github.com/material-components/material-components-%E7%BD%91%E7%BB%9C)%E7%9A%84">https://github.com/material-components/material-components-网络)的</a> Vue.js</li><li><a href="https://github.com/sudheerj/vueface">VueFace</a>-用于 Web 的 Vue.js 2.0 UI 组件库</li><li><a href="https://github.com/lusaxweb/vuesax">vuesax</a>-Vue.js 的前端 vue 组件。</li><li><a href="https://bitbucket.org/acidmartin/vuecidity">vuecidity</a>-Vue.js 2.0 的 UI 组件框架</li><li><a href="https://github.com/vueComponent/ant-design-vue">ant-design-vue</a>-基于 Ant Design 和 Vue 2.5.0 的企业级 UI 组件</li><li><a href="https://github.com/heyui/heyui">heyui</a>-(<a href="https://www.heyui.top/zh)-%E9%80%82%E7%94%A8%E4%BA%8E">https://www.heyui.top/zh)-适用于</a> Web 的 Vue.js 2.0 UI 工具包。</li><li><a href="https://carvuejs.github.io/">Carvue.js</a>-IBM 的 Vue.js 碳设计系统</li><li><a href="https://material.balmjs.com/">BalmUI</a>-Vue.js 的下一代 Material UI</li><li><a href="https://osiris-ui.github.io/osiris">Osiris UI</a>-：art：一个 Vue.js 2.0 通用响应式 UI 组件库</li><li><a href="https://github.com/N3-components/N3-components">N3-components</a>-使用 Vue 2 构建的漂亮 Web 组件</li><li><a href="https://github.com/designrevision/shards-vue">碎片 Vue</a>-✨ 基于 Bootstrap 4 框架的时尚＆UI 组件库。</li><li><a href="https://github.com/SAP/fundamental-vue">基础 Vue</a>-基于 SAP Fiori 基础的组件。</li><li><a href="https://github.com/framevuerk/framevuerk">Framevuerk</a>-🚀 快速，响应迅速，无依赖性，基于 Vue.js 的方向支持和可配置 UI 框架。</li><li><a href="https://github.com/carbon-design-system/carbon-components-vue">@ Carbon &#x2F; vue</a>-@carbon 团队的 Carbon Design System 组件。</li><li><a href="https://github.com/jdf2e/nutui/">NutUI</a>-适用于移动网络的 Vue.js 2.0 UI 工具包</li><li><a href="https://github.com/inkline/inkline/">Inkline</a>-Inkline 是用于 Vue.js 的现代 UI &#x2F; UX 框架，旨在创建完美的响应式 Web 应用程序。</li><li><a href="https://github.com/Wscats/vue-awesome-mui">vue-awesome-mui</a>-用于 Web 的 Vue.js 2.0 MUI 组件</li><li><a href="https://github.com/mdbootstrap/Vue-Bootstrap-with-Material-Design">MDBootstrap</a>-基于最新的 Bootstrap 4 和 Vue 2.6.10 的强大 UI 工具包，提供了一组平滑的，响应式页面模板，布局，组件和小部件，以快速构建响应迅速，移动优先的网站和应用。</li></ul><h2 id="手机"><a href="#手机" class="headerlink" title="手机"></a>手机</h2><ul><li><a href="https://github.com/framework7io/framework7">Framework7-Vue</a>-使用 Framework7＆Vue 构建功能齐全的 iOS 和 Android 应用。</li><li><a href="https://github.com/airyland/vux">vux</a>- [中文]基于 WeUI 的 Vue UI 组件。</li><li><a href="https://github.com/OnsenUI/OnsenUI">vue-onsenui</a>-使用 HTML5 和 JavaScript 的移动应用开发框架和 SDK。创建美观，高性能的跨平台移动应用程序。基于 Web 组件，并提供 Angular 1、2，React 和 Vue.js 的绑定。</li><li><a href="https://weex.incubator.apache.org/">Weex</a>-Weex 提供了发布跨平台的功能，因此 Web，Android 和 IOS 应用程序可以使用相同的 API 开发功能。</li><li><a href="https://github.com/bmfe/eros-template">weex-eros</a>- [中文] Eros 是基于 Weex 和 Vue 的应用程序解决方案，使您能够使用 Vue 的 API，简单快速地开发 Vue 中小型应用程序。</li><li><a href="https://github.com/ElemeFE/mint-ui">mint-ui</a>-Vue.js 的移动 UI 元素。</li><li><a href="https://github.com/youzan/vant">vant</a>-来自 YouZan 的 Vue.js 2.0 移动用户界面。</li><li><a href="https://didi.github.io/cube-ui">cube-ui</a>-Vue.js 编写的出色的移动 ui lib 实现 2。</li><li><a href="https://didi.github.io/mand-mobile">mand-mobile</a>-基于 Vue.js 2 的移动 UI 工具包，专为金融场景而设计。</li></ul><h2 id="组件集合"><a href="#组件集合" class="headerlink" title="组件集合"></a>组件集合</h2><ul><li><a href="https://github.com/posva/vue-mdc">vue-mdc</a>-Vue.js 的 Material Components Web。</li><li><a href="https://github.com/JosephusPaye/Keen-UI">keen-ui</a>-用 Vue 编写并受 Material Design 启发的基本 UI 组件的轻量级集合。</li><li><a href="https://github.com/vue-bulma/vue-admin">vue-admin</a>-Vue 管理面板框架，由 Vue 2.0 和 Bulma 0.3 提供支持。</li><li><a href="https://github.com/vuikit/vuikit">vuikit</a>-具有 Vue 所有功能的 UIkit。</li><li><a href="https://github.com/wxsms/uiv">uiv</a>由 Vue2 实现的 Bootstrap3 组件。</li><li><a href="https://github.com/wffranco/vue-strap">wffranco &#x2F; vue-strap</a>-使用 Vue.js 2 构建的 Bootstrap 3 组件</li><li><a href="https://github.com/chaogao/jsmod-pc-vue">jsmod-vue-pc</a>-适用于 vue 2.0 的高度可扩展的 Web 组件</li><li><a href="https://github.com/guilhermewaess/SemVue">guilhermewaess &#x2F; SemVue</a>-使用 Vue 2 实现的语义 UI 模块</li><li><a href="https://github.com/aidewoode/office-ui-fabric-vue">office-ui-fabric-vue</a>-Vue.js 的 Office UI Fabric 实现</li><li><a href="https://github.com/epicmaxco/vuestic-admin">vuestic-admin</a>-带有自定义组件集合的 Vue Admin 仪表板。内置 Vue 2 和 Bootstrap 4</li><li><a href="https://github.com/Semantic-UI-Vue/Semantic-UI-Vue">语义 UI Vue</a>-Vue 的语义 UI 集成</li><li><a href="https://github.com/lusaxweb/vuesax">vuesax</a>-Vue.js 的前端 vue 组件。</li><li><a href="https://www.syncfusion.com/products/vue">Vue 的基本 JS 2</a>-功能齐全的 45+ Vue.js 组件，其中包括数据网格，图表，计划程序和图表组件等。</li><li><a href="https://github.com/banshee-ui/banshee">Banshee</a>-一个几乎没有渲染的 Vue UI 组件和实用程序框架，没有 CSS。</li><li><a href="https://github.com/nvms/vue-atlas">vue-atlas</a>-漂亮的 Vue 组件库。</li><li><a href="https://github.com/DevExpress/devextreme-vue">DevExtreme Vue 组件</a>-65+响应迅速且功能完善的 Vue UI 组件，具有可自定义的 Material Design 和 Bootstrap 兼容主题。</li><li><a href="https://www.jqwidgets.com/vue/">jqwidgets</a>-70 多个具有 Material Design 主题的 Vue.js 2.0 UI 组件。</li><li><a href="https://github.com/juijs/vue-uix">vue-uix</a>-Vue.js 中用于网页实现的 UI 集合</li><li><a href="https://github.com/LeCoupa/vuedarkmode">vuedarkmode</a>-Vue.js 的极简暗设计系统 🎨</li><li><a href="https://www.telerik.com/kendo-vue-ui/components/">Kendo Vue 用户界面</a>–为业务应用程序构建的 70 多个 UI 组件，包括网格。对多种设计语言(包括材料设计和 Bootstrap)的支持完全响应。</li><li><a href="https://github.com/arturmiz/vuent">Vuent</a>-实现 Microsoft Fluent Design 的 Vue.js 组件</li><li><a href="https://github.com/dreambo8563/bpit-vue">bpit &#x2F; vue</a>-专注于效果的 Vue 组件库</li><li><a href="https://github.com/alfonsobries/vue-tailwind">vue-tailwind</a>-具有可自定义类的 Vue 组件可用于 TailwindCSS，但与任何框架兼容。</li></ul><h2 id="管理模板"><a href="#管理模板" class="headerlink" title="管理模板"></a>管理模板</h2><ul><li><a href="https://github.com/TonyLuo/iview-vue-admin">iView Vue 管理员</a>-iView Vue 管理员&#x2F;基于 iView 2.x 的管理门户模板</li><li><a href="https://github.com/TonyLuo/element-vue-admin">element Vue Admin</a>-element Vue Admin &#x2F;基于 Element UI 2.x 的管理门户模板</li><li><a href="https://github.com/PanJiaChen/vue-element-admin">vue-element-admin</a>-基于 Element UI 2.x 的神奇 vue 管理员</li><li><a href="https://github.com/d2-projects/d2-admin">D2 管理员</a>-vue 制作的优雅后台模板<a href="https://d2admin.fairyever.com/">在线演示</a></li><li><a href="https://github.com/wxs77577/rest-admin">rest-admin</a>-基于 Vue 和 Bootstrap 4 的 Restful 管理面板<a href="http://rest-admin.genyii.com/">在线演示</a></li><li><a href="https://github.com/DesignRevision/shards-dashboard-vue">Shards Dashboard Lite Vue</a>-✨ 现代管理模板，具有数十个自定义组件和模板。</li><li><a href="https://github.com/tookit/vue-material-admin">Vue 材质管理员</a>-Vue 材质设计管理员模板</li><li><a href="https://github.com/codetrial/element-admin">element-admin</a>-使用 Vue CLI 3 和 element-ui 的简单而强大的 vue 管理员。</li></ul><h2 id="服务器端渲染"><a href="#服务器端渲染" class="headerlink" title="服务器端渲染"></a>服务器端渲染</h2><ul><li><a href="https://github.com/nuxt/nuxt.js">Nuxt.js</a>-通用的 Vue.js 框架。</li><li><a href="https://github.com/ream/ream">Ream</a>-用于构建服务器呈现的静态网站的简约框架。</li><li><a href="https://github.com/universal-vue/uvue">Universal vue</a>-Vue CLI 插件，可轻松创建通用 Vue 应用程序</li></ul><h2 id="静态网站生成器"><a href="#静态网站生成器" class="headerlink" title="静态网站生成器"></a>静态网站生成器</h2><ul><li><a href="https://github.com/vuejs/vuepress">VuePress</a>-简约的 Vue 驱动的静态网站生成器。</li><li><a href="https://github.com/egojump/peco">Peco</a>-人类的静态网站生成器。未维护</li><li><a href="https://github.com/egoist/saber">Sabre</a>-一个静态网站生成器，用于使用 Vue.js 构建快速的网站。</li><li><a href="https://github.com/gridsome/gridsome">Gridsome</a>-使用 Vue.js 构建超快速，现代化的网站</li></ul><h2 id="其他-2"><a href="#其他-2" class="headerlink" title="其他"></a>其他</h2><ul><li><a href="https://github.com/scriptPilot/app-framework">app-framework</a>-具有 HTML 和 JavaScript 的 IOS 和 Android 应用程序-开发，构建和部署-免费和开源。</li><li><a href="https://github.com/myfirebase/myfirebase">Myfirebase</a>-一种已解耦的单页应用程序框架，该框架与 google firebase 高度兼容。</li><li><a href="https://github.com/tower1229/Vue-Access-Control">Vue-Access-Control</a>基于 Vue.js 的前端访问控制框架 2。</li><li><a href="https://github.com/basys/basys">Basys</a>工具箱，用于构建完整的 Vue.js 应用程序</li><li><a href="https://github.com/zhennann/cabloy">CabloyJS</a>基于 KoaJS＆EggJS＆VueJS＆Framework7 的终极 NodeJS 全栈业务开发平台</li></ul><h2 id="事件处理"><a href="#事件处理" class="headerlink" title="事件处理"></a>事件处理</h2><ul><li><a href="https://github.com/iFgR/vue-shortkey">vue-shortkey</a>-Vue-ShortKey-Vue.js 的插件。</li><li><a href="https://github.com/scaccogatto/vue-throttle-event">vue-throttle-event</a>-基于 requestAnimationFrame 的油门事件。</li><li><a href="https://github.com/scaccogatto/vue-waypoint">vue-waypoint</a>-Vue 的 Waypoint 组件，这是滚动时触发功能的最简单方法。</li><li><a href="https://github.com/simplesmiler/vue-clickaway">vue-clickaway</a>-可重用的 Vue.js 组件的可重用 clickaway 指令。</li><li><a href="https://github.com/vue-comps/vue-scrollfire">vue-scrollfire</a>-在特定的滚动位置触发事件。</li><li><a href="https://github.com/David-Desmaisons/Vue.resize">vue-resize-directive</a>-Vue 指令可检测具有去污和节流能力的调整大小事件。</li><li><a href="https://github.com/ndelvalle/v-click-outside">v-click-outside</a>-Vue 指令对元素外部的点击做出反应，而不会停止事件传播。</li><li><a href="https://github.com/nchutchind/vue-outside-events">vue-outside-events</a>-Vue 2.x 指令可帮助指定元素侦听发生在自身外部的特定事件。</li><li><a href="https://github.com/JSmith01/vue-selectable">vue-selectable</a>-Vue 1.x &#x2F; 2.x 指令可通过鼠标选择项目。</li><li><a href="https://github.com/huangshuwei/vue-click-helper">vue-click-helper</a>-Vue2.x 指令可处理同一元素上的 click 事件和 dblclick 事件。</li><li><a href="https://github.com/Dafrok/v-hotkey">v-hotkey</a>-Vue 2.x 指令，用于将热键绑定到组件。</li><li><a href="https://github.com/Akryum/vue-resize">vue-resize</a>-Vue 2.x 组件可检测 DOM 元素的大小调整(基于事件&#x2F;无 window.onresize)</li><li><a href="https://github.com/Akryum/vue-observe-visibility">vue-observe-visibility</a>-使用 Intersection Observer API 的 Vue 2.x 指令可检测元素是否可见(在视口中是否被隐藏) CSS)。</li><li><a href="https://github.com/zhanziyang/v-dragged">v-dragged</a>-用于拖动事件检测的 Vue 2.x 指令插件。</li><li><a href="https://github.com/ianaya89/vue-esc">vue-esc</a>-Vue.js 指令，可在转义键盘上添加文档事件监听器。</li><li><a href="https://github.com/shentao/vue-global-events/">vue-global-events</a>–使用 Vue 的事件修饰符处理全局事件(如快捷方式)的组件</li><li><a href="https://github.com/gu-fan/vue-edge-check/">vue-edge-check</a>–检查浏览器边缘，以防止用&#96;vue-router’滑动边缘时奇怪地触发过渡效果</li><li><a href="https://github.com/PNKBizz/vue-mutation-observer">vue-mutation-observer</a>–使用 MutationObserver API 观察 DOM 中变化的简单而微小的指令</li><li><a href="https://github.com/AlekseyPleshkov/vue-scroll-show">vue-scroll-show</a>–如果用户在滚动后到达该元素，则显示该元素</li><li><a href="https://github.com/Almoullim/vue-tabevents">vue-tabevents</a>–其他打开的标签页之间易于通信</li><li><a href="https://github.com/shwilliam/vue-visibility-trigger">vue-visibility-trigger</a>-👀 滚动到视图时以声明方式触发方法</li></ul><h2 id="响应式设计"><a href="#响应式设计" class="headerlink" title="响应式设计"></a>响应式设计</h2><ul><li><a href="https://github.com/scaccogatto/vue-viewports">vue-viewports</a>-定义您的自定义视口，并在组件中使用它们。</li><li><a href="https://github.com/reinerBa/Vue-Responsive">vue 响应</a>：Vue.js(2.x)指令用于隐藏&#x2F;显示具有 Bootstrap 4、3 或自定义断点的 HTML 元素。</li><li><a href="https://github.com/drenglish/vue-match-media">vue-match-media</a>-Vue 2.x 兼容插件，提供一致，语义化的方法来使组件具有媒体查询意识。</li><li><a href="https://github.com/jofftiquez/vue-media-query-mixin">vue-media-query-mixin</a>-Vue 2 媒体查询 mixin 可以在组件 js 和组件模板中使用。与引导程序和可视化视口兼容。如果屏幕宽度为 xs，则返回 wxS；如果屏幕宽度为 sm，则返回 wSM。</li><li><a href="https://github.com/apertureless/vue-breakpoints">vue-breakpoints</a>-Vue 2 最小组件，用于显示和隐藏基于断点的元素。受到 Airbnb 的启发。</li><li><a href="https://github.com/AlexandreBonaventure/vue-mq">vue-mq</a>-提供一些有用的工具，以语义和移动优先的 API(Vue 2.x)快速设置响应式设计</li><li><a href="https://github.com/SeregPie/VueResizeSensor">VueResizeSensor</a>-支持调整大小事件的容器。</li><li><a href="https://github.com/adi518/vue-breakpoint-component">vue-breakpoint-component</a>-用于 组成 CSS 断点状态。</li><li><a href="https://github.com/nash403/fine-mq">fine-mq</a>-一个很好的 API，可以轻松地管理 JS 中的媒体查询，并且可以与 VueJS 作为插件进行一流的集成。</li><li><a href="https://github.com/Kelin2025/vue-sensitive-components">vue-response-components</a>-使用<code>ResizeObserver</code>创建响应组件。</li><li><a href="https://github.com/promosis/vue-screen-size">vue-screen-size</a>-可以轻松，被动地访问屏幕的宽度和高度。</li></ul><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><ul><li><a href="https://github.com/formly-js/vue-formly">vue-formly</a>-JavaScript 支持的 Vue.js 表单。</li><li><a href="https://github.com/simplesmiler/vue-focus">vue-focus</a>-用于可重用 Vue.js 组件的可重用 focus 指令。</li><li><a href="https://github.com/icebob/vue-form-generator">vue-form-generator</a>-Vue.js 的基于架构的表单生成器组件。</li><li><a href="https://gitlab.com/formschema/native">FormSchema Native</a>-使用 JSON Schema 和 Vue.js 生成表单</li><li><a href="https://github.com/InCuca/ic-formly">ic-formly</a>-由 vue-formly 提供支持的简单表单组件。</li><li><a href="https://github.com/laravel-enso/formbuilder">表单生成器</a>-基于 Json 模板的表单生成器，基于 Vue 和 Laravel。</li><li><a href="https://github.com/Botre/vue-autofocus-directive">vue-autofocus-directive</a>-Vue 自动聚焦指令。</li><li><a href="https://github.com/fightingm/vue-awesome-form">vue-awesome-form</a>-一个 vue.js 组件，就像 json-editor</li><li><a href="https://github.com/antonreshetov/vue-form-components">vue-form-components</a>-带有验证的干净＆最小化 vue 表单元素</li><li><a href="https://github.com/ncform/ncform">ncform</a>-一种非常好的配置生成表单的方式</li><li><a href="https://github.com/logaretm/vee-validate">vee-validate</a>-简单的 Vue.js 输入验证插件。</li><li><a href="https://github.com/xpepermint/vue-rawmodel">vue-rawmodel</a>-Vue.js v2 的 RawModel.js 插件。表单验证从未如此简单。</li><li><a href="https://github.com/monterail/vuelidate">vuelidate</a>-针对 Vue.js 的简单，轻量级基于模型的验证。</li><li><a href="https://github.com/semisleep/simple-vue-validator">simple-vue-validator</a>-一个简单而灵活的 vue.js 验证器库。</li><li><a href="https://github.com/joseluisq/vue-vform">vue-vform</a>-Vue.js 2 表单组件，集成了 jQuery 验证和 Axios。</li><li><a href="https://github.com/fergaldoyle/vue-form">vue-form</a>-Vue.js 的全面表单验证。</li><li><a href="https://github.com/cj/vuelidation">vuelidation</a>-简单，功能强大的 vuejs 验证。</li><li><a href="https://github.com/val-bubbleflat/laravel-vue-validator">laravel-vue-validator</a>-显示来自 laravel 验证规则的错误</li><li><a href="https://github.com/deulos/vue-daval">vue-daval</a>-超级 vue 数据验证器。简便，简单，准确。</li><li><a href="https://github.com/gustavoSoriano/willvalidate">willvalidate</a>-Vue.js 的验证表单。</li><li><a href="https://github.com/silksofthesoul/vue-m-validator">vue-m-validator</a>-用于 VueJ 的模型数据验证库。</li><li><a href="https://github.com/Pitu/vue-isyourpasswordsafe">vue-isyourpasswordsafe</a>-用 Vue 编写的小型实用程序，用于检查给定的密码是否已针对“我已被拥有” API 泄漏。</li><li><a href="https://github.com/AlekseyPleshkov/vue-form-send">vue-form-send</a>-用于从表单和原始验证发送数据的 Vue.js 指令</li><li><a href="https://github.com/janiskelemen/formvuelar">FormVuelar</a>-考虑服务器端验证的 Vue 表单组件</li><li><a href="https://phphe.github.io/vue-final-validate/">vue-final-validate</a>-根据我的开发经验，Vue 验证解决方案支持嵌套，异步。</li><li><a href="https://github.com/cretueusebiu/vform">vform</a>-一种在 Vue 中处理 Laravel 后端验证的简单方法。</li></ul><h2 id="调整大小"><a href="#调整大小" class="headerlink" title="调整大小"></a>调整大小</h2><ul><li><a href="https://github.com/PxyUp/vue-not-visible">vue-not-visible</a>-Vue 指令，用于从屏幕上小于断点的 dom(如 v-if)元素中删除。</li><li><a href="https://github.com/mya-ake/vue-window-size">vue-window-size</a>-提供反应性窗口大小属性。</li><li><a href="https://github.com/shwilliam/vue-sensitive-text">vue-sensitive-text</a>-↔ 相对于其父节点的宽度缩放其子节点的组件</li></ul><h2 id="滚动"><a href="#滚动" class="headerlink" title="滚动"></a>滚动</h2><ul><li><a href="https://github.com/theomessin/vue-chat-scroll">vue-chat-scroll</a>-Vue.js 2.0 的自动滚动至底部指令。</li><li><a href="https://github.com/rigor789/vue-scrollTo">vue-scrollto</a>-添加了一个指令，该指令侦听单击事件并滚动到元素。</li><li><a href="https://github.com/Developmint/vue-next-level-scroll">vue-next-level-scroll</a>-一种基于组件且支持 SSR 的方法，可使用现代 Scroll Behavior API 进行平滑滚动</li><li><a href="https://github.com/metawin-m/vue-scroll-sync">vue-scroll-sync</a>-同步容器滚动位置的组件</li><li><a href="https://github.com/phegman/v-scroll-lock">v-scroll-lock</a>-用于正文滚动锁定而不中断目标元素滚动的 Vue.js 指令</li><li><a href="https://github.com/mercs600/vue2-perfect-scrollbar">vue2-perfect-scrollbar</a>-PerfectScrollbar 简约包装器</li><li><a href="https://github.com/KevinHoughton/vue-scroll-to">vue-scroll-to</a>-添加了一个指令，该指令侦听单击事件并滚动到元素。</li><li><a href="https://github.com/guillaumebriday/vue-scroll-progressbar">vue-scroll-progressbar</a>-可自定义的组件，用于指示进度条中滚动的相对位置。</li><li><a href="https://github.com/caiofsouza/vue-backtotop">vue-backtotop</a>-Vue.js 的 Back-to-top 组件，单击该组件可将页面滚动到顶部。</li><li><a href="https://github.com/luiguild/v-bar">VBar</a>-适用于 Vue.js 2x 的虚拟响应式跨浏览器滚动条组件。</li><li><a href="http://serafin.io/vuebar/">Vuebar</a>-使用本地滚动行为的自定义滚动条的 Vue 2 指令。轻巧，高性能，可定制且无依赖性。</li><li><a href="https://github.com/ozangulle/vue-detached-scrollbar">vue-detached-scrollbar</a>-一个简单的滚动条，可以从正在滚动的容器中分离出来。</li><li><a href="https://github.com/YvesCoding/vuescroll">vuescroll</a>-基于 Vue.js 的滚动插件，用于统一 PC 和移动设备中的滚动。</li><li><a href="https://github.com/hfalucas/vue-simplebar">vue-simplebar</a>-Simplebar 插件的 Vue.js 包装器。</li><li><a href="https://github.com/scaccogatto/smooth-vuebar">smooth-vuebar</a>-平滑滚动条的 Vue 指令包装</li><li><a href="https://github.com/chrishurlburt/vue-scrollview">vue-scrollview</a>-一个组件，该组件利用作用域的插槽来检测 vue 组件何时进入和离开视口。</li><li><a href="https://github.com/eddiemf/vue-scrollactive">vue-scrollactive</a>-根据视口中的当前部分在菜单项中添加一个活动类，单击菜单项时也会滚动到该部分。</li><li><a href="https://github.com/heavyy/vue-intersect">vue-intersect</a>-一个 Vue 组件，用于向 Vue 组件或 HTML 元素添加交集观察者。</li><li><a href="https://github.com/AlexandreBonaventure/vue-scrollmonitor">vue-scrollmonitor</a>-一个 Vue 插件，可在支持多种浏览器的情况下观看视口内部元素的可见性状态(使用提供&#x2F;注入，因此兼容 <a href="mailto:vue@2.2">vue@2.2</a> 。X)</li><li><a href="https://github.com/xiaoluoboding/vue-stroll">vue-stroll</a>-适用于 Vue.js 2.x 的超棒 CSS3 列表滚动效果组件。</li><li><a href="https://github.com/nash403/navscroll-js">navscroll-js</a>-在滚动时突出显示菜单项，并且在单击菜单项时也会滚动到某个部分。用作 vue 组件，vue 指令或与 vanilla js 一起使用。</li><li><a href="https://github.com/Desdesdesgo/vue-scrollwatch">vue-scrollwatch</a>-一个轻便的插件，可检测滚动事件，在元素进入视口时自定义回调，将’scrollTo’api 暴露给特定元素。使用 vue 指令。</li><li><a href="https://github.com/vtimofeev/vue-check-view">vue-check-view</a>-一个检查元素是否在视口中的插件。快速，小型，无依赖性，实时演示。</li><li><a href="https://github.com/JALBAA/vue-stickto">vue-stickto</a>-支持多个 DOM 节点的 vue 指令会自动粘贴到顶部</li><li><a href="https://github.com/ibufu/vue2-scrollspy">vue2-scrollspy</a>-一个 scrollspy 插件和动画滚动到。</li><li><a href="https://github.com/jeneser/vue-scroll-behavior">vue-scroll-behavior</a>-自定义路线导航中的滚动行为。特别是哈希模式。</li><li><a href="https://github.com/voxtobox/vue-scroll-stop">vue-scroll-stop</a>-到达边缘时停止传播滚动。</li><li><a href="https://github.com/chenxuan0000/vue-seamless-scroll">vue-seamless-scroll</a>-Vue.js 的简单无缝 滚动。</li></ul><h2 id="路由"><a href="#路由" class="headerlink" title="路由"></a>路由</h2><ul><li><a href="https://github.com/vuejs/vue-router">vue-router</a>-Vue.js 的官方路由器。</li><li><a href="https://github.com/ElderJames/vue-router-storage">vue-router-storage</a>-Vue.js 2 和 vue-router 2 的路由器存储和解决方案</li><li><a href="https://github.com/edgarnadal/vue-tidyroutes">vue-tidyroutes</a>-分散的 vue-router 路由定义</li><li><a href="https://github.com/raniesantos/vue-routisan">vue-routisan</a>-基于 Laravel 路由系统的 Vue 路由器的优雅路由定义</li><li><a href="https://github.com/raniesantos/vue-error-page">vue-error-page</a>-提供路由器视图的包装器，使您可以显示错误页面而不更改 URL</li><li><a href="https://github.com/40818419/vue-router-sitemap">vue-router-sitemap</a>-通过 vue-router 配置生成 sitemap.xml</li><li><a href="https://github.com/f/vue-smart-route">vue-smart-route</a>-智能路由指令，可使用 Vue.js 制作具有智能外观的应用程序。</li><li><a href="https://github.com/ccqgithub/vue-router-lite">vue-router-lite</a>-Vue.js 2 的基于组件的声明性路由器。</li></ul><h2 id="延迟加载"><a href="#延迟加载" class="headerlink" title="延迟加载"></a>延迟加载</h2><ul><li><a href="https://github.com/hilongjw/vue-lazyload">vue-lazyload</a>-一个 Vue.js 插件，用于将图像或组件延迟加载到应用程序中。</li><li><a href="https://github.com/darrynten/vue-lazy-background-images">vue-lazy-background-images</a>-延迟加载 Vue 2 的背景图像。</li><li><a href="https://github.com/MatteoGabriele/vue-progressive-image">vue-progressive-image</a>-Vue 渐进式图像加载插件。</li><li><a href="https://github.com/lsycxyj/vue-l-lazyload">vue-l-lazyload</a>-Vue.js v2.x +的 lazyload 插件。</li><li><a href="https://github.com/JALBAA/vue-lazyload-img">vue-lazyload-img</a>-专门针对移动浏览器进行了优化。支持 V2 和 v1。</li><li><a href="https://github.com/yyh1102/vue-lazyload-images">vue-lazy-images</a>-Vue 2.x 的 lazyload 图像插件。</li><li><a href="https://github.com/nkoehring/v-lazy-img">v-lazy-img</a>-Tiny(&lt;0.6kb)指令，用于 Vue 2 的渐进式图像加载。</li><li><a href="https://github.com/matheusgrieger/vue-clazy-load">vue-clazy-load</a>-使用 IntersecionObserver for Vue 2 的轻量级可转换图像延迟加载组件。</li><li><a href="https://github.com/thangman22/vue-lazy-this">vue-lazy-this</a>-使用 Intersection Observer API 的延迟加载组件。</li><li><a href="https://github.com/dwqs/v2-lazy-list/">v2-lazy-list</a>-一个基于 Vue 2.x 的简单的延迟加载列表组件</li><li><a href="https://github.com/ooade/pimg">pimg</a>-一个用于延迟加载图像的简单渐进图像组件。</li><li><a href="https://github.com/mazipan/vue-tiny-lazyload-img">vue-tiny-lazyload-img</a>-用于延迟加载图像的小尺寸 Vue.js v.2 +指令</li><li><a href="https://github.com/3vilArthas/vue-lazy-youtube-video">vue-lazy-youtube-video</a>-一个用于延迟加载 YouTube 视频的简单 Vue.js 组件。</li><li><a href="https://github.com/Kazap/lazyload-vue">lazyload-vue</a>-适用于 vanilla-lazyload 的 Vue 插件。</li></ul><h2 id="分页"><a href="#分页" class="headerlink" title="分页"></a>分页</h2><ul><li><a href="https://github.com/TahaSh/vue-paginate">vue-paginate</a>-一个简单的 vue.js 插件，可对数据进行分页。</li><li><a href="https://github.com/matfish2/vue-pagination-2">vue-pagination-2</a>-Vue.js 2 分页组件。</li><li><a href="https://github.com/sant123/vuejs-uib-pagination">vuejs-uib-pagination</a>-适用于 Vue.js 的最佳，完整的分页插件。受角引导分页启发。</li><li><a href="https://github.com/lokyoung/vuejs-paginate">vuejs-paginate</a>-用于创建分页的 Vue.js(v2.x +)组件。</li><li><a href="https://github.com/brunoseco/vue-pagination-bootstrap">vue-pagination-bootstrap</a>-一个 Vue.js(1.x＆2.x)服务器端分页组件，带有基于 Bootstrap 的模板</li><li><a href="https://github.com/vinayakkulkarni/laravel-vue-semantic-ui-pagination">laravel-vue-semantic-ui-pagination</a>-与 Laravel 和 Semantic-UI 一起使用的 Vue.js 2.x 分页。</li><li><a href="https://github.com/alziqziq/vue-paginate-al">vue-paginate-al</a>-Vue 分页并返回您的数据。</li><li><a href="https://github.com/coderdiaz/vue-tiny-pagination">vue-tiny-pagination</a>-用于创建微小分页的 Vue 组件。</li><li><a href="https://github.com/gilbitron/laravel-vue-pagination">laravel-vue-pagination</a>-适用于 Laravel 分页器的 Vue.js 分页组件，可与 Bootstrap 一起使用。</li><li><a href="https://github.com/Botre/vue-lpage">vue-lpage</a>-低级 Vue 分页组件。</li><li><a href="https://github.com/TerryZ/v-page">v 页</a>-一个简单的分页栏，包括基于 Vue2.x 的长度菜单，i18n 支持。</li><li><a href="https://github.com/grinmax/vue-smart-pagination">vue-smart-pagination</a>-具有许多不错设置的任何数据的智能分页。</li><li><a href="https://github.com/sbaidon/vue-paginatron">vue-paginatron</a>-分页组件使用范围插槽道具构建，具有最大的灵活性。</li><li><a href="https://github.com/arnedesmedt/vue-ads-pagination">vue-ads-pagination</a>-使用 css 框架[tailwindcss](<a href="https://tailwindcss.com/docs/what">https://tailwindcss.com/docs/what</a> -is-tailwind &#x2F;)</li></ul><h2 id="动画"><a href="#动画" class="headerlink" title="动画"></a>动画</h2><ul><li><a href="https://github.com/asika32764/vue2-animate">vue2-animate</a>-Animate.css 的 Vue.js 2.0 端口。与 Vue 的内置转换一起使用。</li><li><a href="https://github.com/radical-dreamers/animated-vue">animated-vue</a>-一个 Vue.js 2.x 插件，可轻松使用 Animate.css 动画作为过渡。就像&#96;&#96;一样简单！</li><li><a href="https://github.com/chenqingspring/vue-lottie">vue-lottie</a>-一个 Vue.js 2.x 插件，用于基于 bodymovin 渲染特效动画</li><li><a href="https://github.com/jaweii/vueg">Vueg</a>-使 vue-router 具有过渡效果&#x2F;为 webApp 提供转场特效的开源 Vue 插件</li><li><a href="https://jofftiquez.github.io/v-animate-css/">v-animate-css</a>-最容易实现 Animate.css 的 Vue 2 指令</li><li><a href="https://github.com/lukechinworth/vue-mixin-tween">vue-mixin-tween</a>-Mixin 工厂，它将补间值添加到动画的组件上下文中</li><li><a href="https://github.com/JefferyHus/v-odometer">v-odometer</a>-轻松平滑地转换数字。使用此库可为您的应用程序提供平滑的动画，仅适用于数字。</li><li><a href="https://github.com/cristijora/vue2-transitions">vue2-transitions</a>✨ 可重复使用的 Vue 2 过渡组件</li><li><a href="https://github.com/mattrothenberg/vue-overdrive">vue-overdrive</a>Vue 应用程序的超级简单的魔术移动过渡 🎩</li><li><a href="https://github.com/Leocardoso94/animated-number-vue">animated-number-vue</a>超级简单的数字动画方法。</li><li><a href="https://github.com/Orlandster1998/vue-typed-js">vue-typed-js</a>集成了 Typed.js，可轻松创建打字动画。</li><li><a href="https://github.com/inamori/vue-parent-change-transition">vue-parent-change-transition</a>启用子组件在更改父组件时进行动画处理。</li><li><a href="https://github.com/guanzo/vue-smooth-reflow">vue-smooth-reflow</a>响应数据变化而转换元素重排。</li><li><a href="https://github.com/SeregPie/VueTween">VueTween</a>允许组件补间其属性。</li><li><a href="https://github.com/danieldiekmeier/vue-slide-up-down">vue-slide-up-down</a>就像 jQuery 的<code>slideUp</code> &#x2F;<code>slideDown</code>一样，但是对于 Vue！</li><li><a href="https://github.com/BenAHammond/vue-anime">vue-animejs</a>Vue 的简单<code>anime.js</code>指令。</li><li><a href="https://github.com/zulko/eagle.js/">Eagle.js</a>Eagle.js 是 Vue.js 的基于 Web 的幻灯片框架。</li><li><a href="https://github.com/Popmotion/popmotion/tree/master/packages/vue-pose">vue-pose</a>Pose for Vue 是一个声明式运动系统，结合了 CSS 过渡的简单性和 CSS 的强大功能和灵活性 JavaScript。</li><li><a href="https://github.com/k-okina/vue-slide-up-down-component">vue-slide-up-down-component</a>这是一个简单的界面，但是实现了非常灵活而强大的幻灯片动画 Vue！</li><li><a href="https://github.com/pearofducks/femtoTween">femtoTween</a>具有一流 Vue 支持的简约(零深度，小于 1k)补间库</li><li><a href="https://github.com/deivthings/vue-sequential-entrance">vue-sequential-entrance</a>插件，用于创建带有页面元素列表的优雅的连续动画入口。零努力。简单轻巧</li><li><a href="https://github.com/mike-prince/vue-animate-scroll">vue-animate-scroll</a>一种超级轻量级 的方法，可在元素滚动到视图中时向其添加 CSS 动画。</li><li><a href="https://github.com/kai-oswald/vue-svg-transition">vue-svg-transition</a>创建 2 状态，SVG 驱动的过渡</li><li><a href="https://github.com/Orlandster/vue-page-transition">vue-page-transition</a>Vue.js 的简单路由&#x2F;页面转换</li></ul><h2 id="元标记"><a href="#元标记" class="headerlink" title="元标记"></a>元标记</h2><ul><li><a href="https://github.com/ktquez/vue-head">vue-head</a>-管理 head 标签的元信息，一种简单的方法。</li><li><a href="https://github.com/declandewet/vue-meta">vue-meta</a>-在 Vue 2.0 组件中管理页面元信息。支持 SSR +流媒体。</li><li><a href="https://github.com/troxler/vue-headful">vue-headful</a>-从视图中设置文档&#96;&#96;和 meta 标签。</li><li><a href="https://github.com/VeryWow/vue-simple-headful">vue-simple-headful</a>-使用 vue.js 轻松设置元标记-具有 TypeScript 支持的更简单的<code>vue-headful</code>替代方法。</li></ul><h2 id="传送门"><a href="#传送门" class="headerlink" title="传送门"></a>传送门</h2><ul><li><a href="https://github.com/calebroseland/vue-dom-portal">vue-dom-portal</a>-Vue.js 组件中 DOM 元素的转义口。</li><li><a href="https://linusborg.github.io/portal-vue">portal-vue</a>-一个 Vue 插件，用于在 DOM 中的任何位置渲染组件的模板(在 virtualDOM 级别上有效，不会在 DOM 中移动节点)</li></ul><h2 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h2><ul><li><a href="https://github.com/freearhey/vue2-filters">vue2-filters</a>-适用于 Vue 2. *的标准过滤器 Vue 1. *的集合。</li><li><a href="https://github.com/jofftiquez/vue-morphling">vue-morphling</a>-Vue 2 的标准和自定义过滤器的集合。</li><li><a href="https://github.com/mazipan/vue-currency-filter">vue-currency-filter</a>-轻巧且可自定义的 Vue 2 货币过滤器。</li><li><a href="https://github.com/Trekels/vue-trans">vue-trans</a>-一个简单的过滤器，提供了与 Symfony trans 相似的翻译方式。</li><li><a href="https://github.com/mazipan/vue-string-filter">vue-string-filter</a>-轻量级 Vue 2 字符串处理过滤器。</li><li><a href="https://github.com/ERPedersen/vue-units">vue-units</a>-在 Vue 2 中使用的方便的单位转换过滤器的集合。</li><li><a href="https://github.com/lloydjatkinson/vue-numeral-filter">vue-numeral-filter</a>-过滤器的集合，允许在组件的模板部分内联使用 Numeral.js。</li><li><a href="https://github.com/eduardnikolenko/vue-filter-date-format">vue-filter-date-format</a>-Vue 2 的简单日期时间过滤器。</li><li><a href="https://github.com/eduardnikolenko/vue-filter-pluralize">vue-filter-pluralize</a>-Vue 2 的简单复数过滤器。</li><li><a href="https://github.com/eduardnikolenko/vue-filter-date-parse">vue-filter-date-parse</a>-Vue 2 的简单解析日期时间过滤器。</li></ul><h2 id="SVG"><a href="#SVG" class="headerlink" title="SVG"></a>SVG</h2><ul><li><a href="https://github.com/MMF-FE/vue-svgicon">vue-svgicon</a>-创建 svg 图标组件的工具。(版本 2.x)。</li><li><a href="https://github.com/LucasLeandro1204/vue-content-loading">vue-content-loading</a>-Vue 组件可轻松构建(或使用预设)Facebook 之类的 SVG 加载卡。</li><li><a href="https://github.com/DrSensor/vue-annotator">vue-annotator</a>-使用任何 SVG 元素(“ rect”，“ polygon”以及其他更多元素，即使包装了 HTML 元素如“ canvas”，也可以为页面添加注释)在<code>foreignObject</code>中)</li><li><a href="https://github.com/thierrymichel/vue-svg-sprite">vue-svg-sprite</a>-简单使用 SVG sprite(vue 2.x)的指令。</li><li><a href="https://github.com/biigpongsatorn/vue-svg-filler">vue-svg-filler</a>-用于自定义 svg 文件 🖍(vue 2.x)的 Vue 组件。</li></ul><h2 id="其他-3"><a href="#其他-3" class="headerlink" title="其他"></a>其他</h2><ul><li><a href="https://github.com/staskjs/vue-resource-progressbar-interceptor">vue-resource-progressbar-interceptor</a>-将进度条与所有请求联系在一起的拦截器，很明显，正在加载某些东西。</li><li><a href="https://github.com/David-Desmaisons/Vue.ImagesLoaded">vue-images-loaded</a>-Vue.js 2.0 指令可检测图像加载。</li><li><a href="https://github.com/javisperez/vue-visible">vue-visible</a>-VueJS(2.x)的 v-visible 指令，类似于 v-show 但具有可见性。</li><li><a href="https://github.com/FranckFreiburger/vue-resize-sensor">vue-resize-sensor</a>-用于检测容器大小的组件(基于事件)</li><li><a href="https://github.com/ndelvalle/v-blur">v-blur</a>-Vue 指令动态模糊元素</li><li><a href="https://github.com/mokkabonna/vue-async-methods">vue-async-methods</a>-用于基于承诺的方法的帮助程序实用程序</li><li><a href="https://github.com/braceslab/vue-openseadragon">vue-openseadragon</a>-适用于 Vue.js 的 OpenSeaDragon 组件(缩放和平移)</li><li><a href="https://github.com/samturrell/vue-match-heights">vue-match-heights</a>-指令将元素的高度设置为相同。</li><li><a href="https://github.com/FL3NKEY/vue-conditional-attrs">vue-conditional-attrs</a>-用于条件渲染属性和指令的 Vue.js 组件</li><li><a href="https://github.com/arthurvasconcelos/vue-cbsc">vue-cbsc</a>-一个 Vue.js 2.x 组件，用于以编程方式混合，着色和转换颜色。</li><li><a href="https://github.com/twcapps/vue-spatialnavigation">vue-spatialnavigation</a>-用于空间导航(键盘导航)的 Vue 指令(Vue.js 2.x)</li><li><a href="https://github.com/FL3NKEY/vue-lifecycle">vue-lifecycle</a>-Vue.js 生命周期指令。</li><li><a href="https://github.com/3vilArthas/v-aspect-ratio">vue-aspect-ratio</a>-vue 的长宽比指令。</li><li><a href="https://github.com/kooljay82/vue-m-camera">@ kooljay82 &#x2F; vue-m-camera</a>-为避免自动更改通过用户设备的相机拍摄的照片方向。</li></ul><h2 id="WebGL"><a href="#WebGL" class="headerlink" title="WebGL"></a>WebGL</h2><ul><li><a href="https://github.com/hujiulong/vue-3d-model">vue-3d-model</a>-Vue 组件中的 3D 模型查看器。</li><li><a href="https://github.com/ChiChou/vue-pano">vue-pano</a>-Vue 组件中的全景查看器。</li><li><a href="https://github.com/fritx/vue-threejs">vue-threejs</a>-Three.js 的 Vue 绑定。</li><li><a href="https://github.com/vue-gl/vue-gl">VueGL</a>-Vue.js 组件通过 three.js 反应性地渲染 3D 图形</li><li><a href="https://github.com/imudin/vue-vr">vue-vr</a>-使用 Vue 构建 VR 应用程序的框架</li><li><a href="https://github.com/AlbanCrepel/vue-displacement-slideshow">vue-displacement-slideshow</a>-一个 Vue.js 组件，可简化 Webgl 图像位移转换。</li></ul><h2 id="全屏"><a href="#全屏" class="headerlink" title="全屏"></a>全屏</h2><ul><li><a href="https://github.com/mirari/vue-fullscreen">vue-fullscreen</a>-用于全屏的简单 Vue 组件。</li></ul><h2 id="页面可见性"><a href="#页面可见性" class="headerlink" title="页面可见性"></a>页面可见性</h2><ul><li><a href="https://github.com/stefanodotit/vue-page-visibility-awesome">vue-page-visibility-awesome</a>-易于配置的页面可见性 api 的 Vue 2.x 组件。</li><li><a href="https://github.com/vv13/vue-authplugin">vue-authplugin</a>-美观的 auth 控制插件，支持指令和原型方法。</li></ul><h2 id="打印"><a href="#打印" class="headerlink" title="打印"></a>打印</h2><ul><li><a href="https://mycure-inc.github.io/vue-html-to-paper/">vue-html-to-paper</a>-Vue mixin 用于将 html 元素打印到纸张上。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前端组件汇总&quot;&gt;&lt;a href=&quot;#前端组件汇总&quot; class=&quot;headerlink&quot; title=&quot;前端组件汇总&quot;&gt;&lt;/a&gt;前端组件汇总&lt;/h1&gt;&lt;h2 id=&quot;菜单&quot;&gt;&lt;a href=&quot;#菜单&quot; class=&quot;headerlink&quot; title=&quot;菜单&quot;&gt;&lt;</summary>
      
    
    
    
    <category term="前端" scheme="http://ai.mak.cn/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="js" scheme="http://ai.mak.cn/tags/js/"/>
    
  </entry>
  
  <entry>
    <title>大模型概念总结</title>
    <link href="http://ai.mak.cn/2024/04/21/ai/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%A6%82%E5%BF%B5%E6%80%BB%E7%BB%93/"/>
    <id>http://ai.mak.cn/2024/04/21/ai/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%A6%82%E5%BF%B5%E6%80%BB%E7%BB%93/</id>
    <published>2024-04-20T16:00:00.000Z</published>
    <updated>2024-12-18T02:30:38.543Z</updated>
    
    <content type="html"><![CDATA[<h1 id="大模型概念总结"><a href="#大模型概念总结" class="headerlink" title="大模型概念总结"></a>大模型概念总结</h1><blockquote><p>链接：<a href="https://juejin.cn/post/7282944006674776124">https://juejin.cn/post/7282944006674776124</a><br>来源：稀土掘金</p></blockquote><blockquote><p>主要介绍了大模型相关的众多知识，包括小白学大模型需掌握的基础知识，如机器学习、深度学习、数据预处理等；还阐述了概率统计中的概念，如期望值、方差、标准差等；介绍了多种分布、损失函数及其作用和降低方法，以及不同神经网络的区别，如 CNN 和 RNN；还讲解了模型蒸馏、压缩量化、模型加速、多模态大模型等内容。</p></blockquote><h2 id="学大模型应该要学什么？"><a href="#学大模型应该要学什么？" class="headerlink" title="学大模型应该要学什么？"></a>学大模型应该要学什么？</h2><ol><li>机器学习基础知识：学习大模型的前提是对机器学习的基本概念和原理有一定的了解。需要了解什么是监督学习、无监督学习、强化学习等基本概念，以及常见的机器学习算法，如线性回归、逻辑回归、决策树、支持向量机等。</li><li>深度学习基础知识：在学习大模型中，深度学习是一种常用的技术。小白需要了解深度学习的基本概念和原理，如神经网络的结构和训练方法，常用的深度学习框架，如TensorFlow、Keras、PyTorch等。</li><li>数据预处理：在使用大模型之前，通常需要对数据进行预处理。小白需要了解常见的数据预处理方法，如数据清洗、特征选择、特征转换等。还需要了解如何处理缺失值、异常值等常见的数据问题。</li><li>模型选择和评估：在学习大模型时，需要选择适合的模型来解决具体的问题。小白需要了解不同模型之间的优缺点，并能根据具体情况选择合适的模型。此外，还需要了解如何评估模型的性能，如准确率、召回率、F1值等指标。</li><li>模型调优：学习大模型时，模型的调优是非常重要的一步。小白需要了解常见的模型调优方法，如网格搜索、随机搜索、交叉验证等。还需要了解如何调整模型的超参数，如学习率、正则化参数等。</li><li>模型部署：在学习大模型之后，还需要将模型部署到实际的应用中。小白需要了解如何将训练好的模型保存，并能够加载模型进行预测。还需要了解如何优化模型的计算速度和内存占用等问题。</li></ol><h2 id="期望值-均值-、方差、标准差之间的区别是什么"><a href="#期望值-均值-、方差、标准差之间的区别是什么" class="headerlink" title="期望值(均值)、方差、标准差之间的区别是什么"></a>期望值(均值)、方差、标准差之间的区别是什么</h2><p>期望值: 是指随机变量的平均值或长期平均值。它通过考虑随机变量的所有可能结果，并根据它们各自的概率进行加权计算得到。</p><p>均值: 则是一组数字的算术平均值。它通过将集合中的所有数字相加，然后将总和除以数字的总数来计算得到。</p><blockquote><p>总结起来，期望值是概率论中用于描述随机变量平均值的概念，而均值是一个更一般的术语，用于描述一组数字的平均值。</p></blockquote><p>方差: 方差衡量随机变量或一组数据点的分散程度或离散程度。它量化了数据集中每个值与均值之间的差异程度。通过取每个数据点与均值之间差的平方的平均值来计算。</p><p>标准差: 标准差是随机变量或一组数据点的另一种衡量分散程度或离散程度的指标。它是方差的平方根，并提供了对分散程度的更直观理解。它表示数据点偏离均值的平均量。</p><h2 id="均匀分布、正态分布、多项分布的概念"><a href="#均匀分布、正态分布、多项分布的概念" class="headerlink" title="均匀分布、正态分布、多项分布的概念"></a>均匀分布、正态分布、多项分布的概念</h2><ol><li>均匀分布：均匀分布是指在一定范围内，所有的数值具有相同的概率密度。换句话说，每个数值发生的概率是相等的。在均匀分布中，每个数据点都有相同的可能性出现。</li></ol><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/95d0a0d372d140bdaee6461f83cbded6~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=500&h=357&s=13688&e=png&a=1&b=000000" alt="image.png"></p><ol><li>正态分布：正态分布，也称为高斯分布，是自然界中最常见的分布之一。在正态分布中，数据呈现出钟形曲线的形状，均值位于中心，对称分布。大部分数据集中在均值附近，而离均值越远，数据出现的概率越小。</li></ol><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fede817d0b4741c0b6d46312043283eb~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=500&h=319&s=39640&e=png&a=1&b=000000" alt="image.png"></p><ol><li>多项分布：多项分布是一种离散概率分布，用于描述在多个类别中的多次独立试验的结果。每个试验有多个可能的结果，并且每个结果发生的概率可能不同。多项分布可以用于模拟掷骰子、投票结果等多种情况。</li></ol><h2 id="损失函数在深度学习中的作用是什么？"><a href="#损失函数在深度学习中的作用是什么？" class="headerlink" title="损失函数在深度学习中的作用是什么？"></a>损失函数在深度学习中的作用是什么？</h2><p>损失函数在深度学习中起着至关重要的作用。损失函数用于衡量模型的预测输出与实际标签之间的差异，即模型的性能好坏。通过最小化损失函数，我们可以训练模型以更准确地预测目标变量。</p><p>深度学习中常用的损失函数有多种，根据任务类型和数据特点选择不同的损失函数。以下是几种常见的损失函数：</p><ol><li>均方误差（Mean Squared Error，MSE）：适用于回归任务，计算预测值与真实值之间的平均平方差，用于衡量预测值与真实值之间的距离。</li><li>交叉熵损失（Cross-Entropy Loss）：适用于分类任务，衡量模型输出的概率分布与真实标签之间的差异。常见的交叉熵损失函数包括二元交叉熵和多类交叉熵。</li><li>KL 散度（Kullback-Leibler Divergence）：用于衡量两个概率分布之间的差异，常用于生成模型中。</li></ol><p>损失函数的选择对模型的训练和性能影响巨大。通过优化损失函数，我们可以调整模型的参数以最小化预测误差，从而提高模型的准确性和泛化能力。</p><h2 id="如何降低损失函数？"><a href="#如何降低损失函数？" class="headerlink" title="如何降低损失函数？"></a>如何降低损失函数？</h2><p>降低损失函数是深度学习中优化模型性能的关键目标之一。</p><p>以下是一些常用的方法来降低损失函数：</p><ol><li>调整模型架构：通过改变模型的结构，增加或减少神经网络的层数、神经元的数量等，可以改善模型的表示能力，从而降低损失函数。</li><li>调整学习率：学习率控制了参数更新的步长。如果学习率设置得过大，可能导致训练不稳定；如果学习率设置得过小，可能导致训练收敛速度过慢。通过选择适当的学习率，可以更好地降低损失函数。</li><li>数据预处理：对输入数据进行预处理可以改善数据的质量，有助于降低损失函数。例如，对数据进行归一化、标准化、缺失值处理等。</li><li>增加训练数据量：增加更多的训练数据可以提供更多的样本信息，有助于提高模型的泛化能力，从而降低损失函数。</li><li>正则化技术：正则化方法可以通过限制模型的复杂度来减少过拟合，从而降低损失函数。常见的正则化技术包括L1正则化、L2正则化等。</li><li>批次归一化：批次归一化是一种常用的技术，可以加速模型的训练过程并提高模型的性能。它通过对每个小批次的数据进行归一化，有助于减少梯度消失和爆炸问题。</li><li>调整优化器：优化器选择对模型的性能有很大影响。常用的优化器包括随机梯度下降（SGD）、Adam、RMSProp等。通过选择合适的优化器和调整其超参数，可以帮助降低损失函数。</li></ol><p>请注意，降低损失函数是一个复杂的过程，需要根据具体的问题和数据来选择适当的方法。通常需要进行实验和调优，以找到最佳的方式来降低损失函数</p><h2 id="卷积神经网络（CNN）和递归神经网络（RNN）区别是什么？"><a href="#卷积神经网络（CNN）和递归神经网络（RNN）区别是什么？" class="headerlink" title="卷积神经网络（CNN）和递归神经网络（RNN）区别是什么？"></a>卷积神经网络（CNN）和递归神经网络（RNN）区别是什么？</h2><p>卷积神经网络（CNN）和递归神经网络（RNN）是两种常见的神经网络架构，用于处理不同类型的数据。</p><p>主要区别如下：</p><ol><li>数据处理方式：CNN主要用于处理网格状结构的数据，如图像。它通过卷积操作来提取局部特征，并通过池化操作来减少参数数量。而RNN则适用于序列数据，如文本和语音。它通过循环连接来处理序列中的时序信息。</li><li>网络结构：CNN通常由多个卷积层和池化层组成，最后通过全连接层进行分类或回归。每个卷积层都可以检测不同的特征，逐渐提取更高级别的特征。RNN由一个或多个循环单元组成，可以捕捉序列中的上下文信息。</li><li>参数共享：CNN具有参数共享的特性，即在整个图像中使用相同的过滤器来提取特征。这样可以减少参数数量，提高模型的效率。而RNN在每个时间步都使用相同的参数，以处理序列中的不同位置的输入。</li><li>上下文理解：由于RNN的循环连接结构，它能够捕捉到序列数据中的上下文信息和长期依赖关系。而CNN主要关注局部特征，对于长期依赖的序列数据处理可能相对困难。</li></ol><p>综上所述，CNN适用于处理网格状数据，如图像，而RNN适用于处理序列数据，如文本和语音。它们在数据处理方式、网络结构、参数共享和上下文理解等方面存在明显的区别。</p><h2 id="模型蒸馏是什么？"><a href="#模型蒸馏是什么？" class="headerlink" title="模型蒸馏是什么？"></a>模型蒸馏是什么？</h2><p>模型蒸馏（Model Distillation）是一种用于训练模型的方法，它通过将一个大型模型转换为一个较小的模型，从而实现更高效地部署和优化。模型蒸馏通常用于解决训练集不足的问题，特别是在数据量较少的场景下。</p><p>模型蒸馏的主要思想是将一个大型模型的输出映射到一个较小的模型，以便较小的模型能够更好地拟合较大的模型。具体步骤如下：</p><ol><li>选择一个大型模型：首先，从大量数据中训练一个大型模型。这个模型通常包含多个层，每层都有一个特定的权重。</li><li>选择一个较小的模型：为了实现模型蒸馏，需 要创建一个较小的模型，该模型具有与大型模型相同的层结构，但权重较小。这可以通过使用较少的参数和较小的神经网络结构来实现。</li><li>输出层：为了将大型模型的输出映射到较小的模型，需要将大型模型的输出层转换为较小的模型可以理解的格式。这通常是通过将大型模型的输出层转换为多个较小的输出层来实现。每个较小的输出层都可以被视为一个分类器，它将输入特征映射到相应的类别。</li><li>训练较小的模型：使用较小的数据集对较小的模型进行训练。训练的目标是使较小的模型的权重与大型模型的权重接近，从而实现模型蒸馏。</li><li>评估模型：使用测试集评估较小的模型的性能，并与大型模型的性能进行比较。通过比较性能，可以评估模型蒸馏的效果。</li></ol><p>模型蒸馏是一种有效的训练方法，特别是在数据量较少的场景下，可以帮助训练较小的模型，从而提高性能并提高模型在实际应用中的可移植性。</p><h2 id="压缩量化是什么？"><a href="#压缩量化是什么？" class="headerlink" title="压缩量化是什么？"></a>压缩量化是什么？</h2><p>压缩量化是一种优化技术，用于减少神经网络模型的参数量，同时保持模型的性能。它通过减少权重系数的大小来减少模型的大小，从而降低计算量，提高存储空间和传输速度。通常，压缩量化方法包括以下几个步骤：</p><ol><li>初始化：首先，随机初始化模型的权重系数。</li><li>训练：使用训练数据对模型进行训练，同时更新权重系数。</li><li>量化：将权重系数转换为整数表示，从而减少其大小。通常，使用固定点精度或浮点精度来量化权重系数。</li><li>微调：根据训练过程中的性能指标对权重系数进行微调，以优化模型的性能。</li><li>评估：使用测试数据对模型进行评估，以评估压缩量化后的性能。</li></ol><p>压缩量化方法在神经网络模型压缩和优化方面取得了很好的效果，特别是在资源有限的场景下。然而，在实际应用中，压缩量化可能会导致模型的性能损失，因此需要谨慎应用。</p><h2 id="模型加速是什么？"><a href="#模型加速是什么？" class="headerlink" title="模型加速是什么？"></a>模型加速是什么？</h2><p>模型加速（Model Acceleration）是一种用于加速神经网络模型训练的方法。它通过优化模型结构、优化算法和并行处理技术来提高模型的训练速度。通常，模型加速方法包括以下几个步骤：</p><ol><li>初始化：首先，随机初始化模型的权重系数。</li><li>训练：使用训练数据对模型进行训练，同时更新权重系数。在训练过程中，使用加速标志来记录模型权重系数的变化。</li><li>优化：根据训练过程中的性能指标对模型结构进行优化，以提高模型的训练速度。</li><li>并行处理：使用并行处理技术提高模型的训练速度。这可以通过使用多线程、多进程或分布式计算来并行处理多个样本，从而提高训练速度。</li><li>评估：使用测试数据对模型进行评估，以评估加速后的性能。在评估过程中，确保加速标志保持不变。</li></ol><p>模型加速方法在提高神经网络模型训练速度方面取得了很好的效果，特别是在资源有限的场景下。然而，在实际应用中，模型加速可能会导致模型的性能损失，因此需要谨慎应用。</p><h2 id="什么是多模态大模型？"><a href="#什么是多模态大模型？" class="headerlink" title="什么是多模态大模型？"></a>什么是多模态大模型？</h2><p>多模态大模型（Multimodal Large Model）是一种结合了多种任务（如文本、图像、音频等）的通用预训练模型。它通过学习多种任务的数据来提高在多种任务上的性能，从而提高模型的通用性。多模态大模型通常使用深度学习技术来实现，包括卷积神经网络（CNN）和递归神经网络（RNN）。</p><p>多模态大模型通常具有以下特点：</p><ol><li>large：模型参数规模较大，需要大量训练数据和计算资源。</li><li>multi-task：模型同时学习多种任务，提高模型的通用性。</li><li>multi-modality：模型处理不同类型的输入，如文本、图像、音频等，提高模型的适应性。</li><li>deep：模型内部结构复杂，包含多个层次的神经网络。</li></ol><p>当前的多模态大模型有：</p><ol><li>谷歌的 GLM（General Language Modeling）模型，一种基于 Transformer 的通用语言模型。</li><li>百度的 PaddleNLP 模型，一种基于 Transformer 的通用语言模型。</li><li>清华大学的 GLM-130B 模型，一种基于 Transformer 的通用语言模型。</li><li>清华大学的 Im2txt 模型，一种基于 CNN 的通用文本生成模型。</li><li>清华大学的 Audio2Text 模型，一种基于 CNN 的通用音频转文本模型。</li></ol><p>总之，多模态大模型是一种结合了多种任务（如文本、图像、音频等）的通用预训练模型，通过学习多种任务的数据来提高在多种任务上的性能，从而提高模型的通用性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;大模型概念总结&quot;&gt;&lt;a href=&quot;#大模型概念总结&quot; class=&quot;headerlink&quot; title=&quot;大模型概念总结&quot;&gt;&lt;/a&gt;大模型概念总结&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://juejin.cn/post/72</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="深度学习" scheme="http://ai.mak.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>解读 CNCF 推出的云原生 AI 白皮书</title>
    <link href="http://ai.mak.cn/2024/04/17/ai/%E8%A7%A3%E8%AF%BB%20CNCF%20%E6%8E%A8%E5%87%BA%E7%9A%84%E4%BA%91%E5%8E%9F%E7%94%9F%20AI%20%E7%99%BD%E7%9A%AE%E4%B9%A6/"/>
    <id>http://ai.mak.cn/2024/04/17/ai/%E8%A7%A3%E8%AF%BB%20CNCF%20%E6%8E%A8%E5%87%BA%E7%9A%84%E4%BA%91%E5%8E%9F%E7%94%9F%20AI%20%E7%99%BD%E7%9A%AE%E4%B9%A6/</id>
    <published>2024-04-16T16:00:00.000Z</published>
    <updated>2024-12-18T08:03:53.179Z</updated>
    
    <content type="html"><![CDATA[<h1 id="解读-CNCF-推出的云原生-AI-白皮书"><a href="#解读-CNCF-推出的云原生-AI-白皮书" class="headerlink" title="解读 CNCF 推出的云原生 AI 白皮书"></a>解读 CNCF 推出的云原生 AI 白皮书</h1><p>2024 年 3 月，在 KubeCon EU 期间，云原生计算基金会（CNCF）发布了首份关于云原生人工智能（CNAI）的详细白皮书 [1] 。这份报告详尽地探讨了将云原生技术与人工智能融合的当前状态、面临的挑战、以及未来的发展方向。本文将对这份白皮书的核心内容进行深入解读。</p><h2 id="什么是云原生-AI？"><a href="#什么是云原生-AI？" class="headerlink" title="什么是云原生 AI？"></a>什么是云原生 AI？</h2><p>云原生 AI 指的是利用云原生技术原则来构建和部署人工智能应用和工作负载的方法。这包括利用微服务、容器化、声明式 API 和持续集成 &#x2F; 持续部署（CI&#x2F;CD）等云原生技术来增强 AI 应用的可扩展性、可复用性和可操作性。</p><p>下图展示了云原生 AI 的架构，图片根据该白皮书重新绘制。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/msqHleoN7Q3ZpYibOGNPicf0ia0yY1fFRrV3zXLDbG7brpjgYRKvzIkYojW0OnK84XyY1b4MExxRiatqZQ8iceibvibFA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><h2 id="云原生-AI-与云原生技术之间的关系"><a href="#云原生-AI-与云原生技术之间的关系" class="headerlink" title="云原生 AI 与云原生技术之间的关系"></a>云原生 AI 与云原生技术之间的关系</h2><p>云原生技术提供了一个灵活、可扩展的平台，使得开发和运行 AI 应用变得更加高效。通过容器化和微服务架构，开发人员可以快速迭代和部署 AI 模型，同时保证系统的高可用性和可扩展性。Kubernetes 和其他云原生工具提供了必要的支持，例如资源调度、自动扩缩容和服务发现等。</p><p>白皮书中给出了两个例子说明云原生 AI 与云原生技术的关系，即在云原生基础架构上运行 AI：</p><ul><li>• Hugging Face Collaborates with Microsoft to launch Hugging Face Model Catalog on Azure[2]</li><li>• OpenAI Scaling Kubernetes to 7,500 nodes[3]</li></ul><h2 id="云原生-AI-的挑战"><a href="#云原生-AI-的挑战" class="headerlink" title="云原生 AI 的挑战"></a>云原生 AI 的挑战</h2><p>尽管云原生技术为 AI 应用提供了坚实的基础，但在将 AI 工作负载与云原生平台整合时，仍然存在一些挑战。这些挑战包括数据准备的复杂性、模型训练的资源需求、以及在多租户环境中保持模型的安全性和隔离性。此外，云原生环境中的资源管理和调度对于大规模 AI 应用尤其关键，需要进一步优化以支持高效的模型训练和推理。</p><h2 id="云原生-AI-的发展路径"><a href="#云原生-AI-的发展路径" class="headerlink" title="云原生 AI 的发展路径"></a>云原生 AI 的发展路径</h2><p>白皮书中提出了几条云原生 AI 的发展路径，包括改进资源调度算法以更好地支持 AI 负载、开发新的服务网格技术以提高 AI 应用的性能和安全性，以及通过开源项目和社区合作来推动云原生 AI 技术的创新和标准化。</p><h2 id="云原生-AI-技术景观图"><a href="#云原生-AI-技术景观图" class="headerlink" title="云原生 AI 技术景观图"></a>云原生 AI 技术景观图</h2><p>云原生 AI 涉及到多种技术，从容器和微服务到服务网格和无服务器计算。Kubernetes 是部署和管理 AI 应用的关键平台，而 Istio、Envoy 等服务网格技术则提供了强大的流量管理和安全功能。此外，Prometheus 和 Grafana 等监控工具对于维护 AI 应用的性能和可靠性至关重要。</p><p>下面是白皮书中给出的云原生 AI 景观图。</p><h3 id="General-Orchestration"><a href="#General-Orchestration" class="headerlink" title="General Orchestration"></a>General Orchestration</h3><ul><li>• Kubernetes</li><li>• Volcano</li><li>• Armada</li><li>• Kuberay</li><li>• Nvidia NeMo</li><li>• Yunikorn</li><li>• Kueue</li><li>• Flame</li></ul><h3 id="Distributed-Training"><a href="#Distributed-Training" class="headerlink" title="Distributed Training"></a>Distributed Training</h3><ul><li>• Kubeflow Training Operator</li><li>• Pytorch DDP</li><li>• TensorFlow Distributed</li><li>• Open MPI</li><li>• DeepSpeed</li><li>• Megatron</li><li>• Horovod</li><li>• Apla</li><li>• …</li></ul><h3 id="ML-Serving"><a href="#ML-Serving" class="headerlink" title="ML Serving"></a>ML Serving</h3><ul><li>• Kserve</li><li>• Seldon</li><li>• VLLM</li><li>• TGT</li><li>• Skypilot</li><li>• …</li></ul><h3 id="CI-x2F-CD-Delivery"><a href="#CI-x2F-CD-Delivery" class="headerlink" title="CI&#x2F;CD - Delivery"></a>CI&#x2F;CD - Delivery</h3><ul><li>• Kubeflow Pipelines</li><li>• Mlflow</li><li>• TFX</li><li>• BentoML</li><li>• MLRun</li><li>• …</li></ul><h3 id="Data-Science"><a href="#Data-Science" class="headerlink" title="Data Science"></a>Data Science</h3><ul><li>• Jupyter</li><li>• Kubeflow Notebooks</li><li>• PyTorch</li><li>• TensorFlow</li><li>• Apache Zeppelin</li><li>• …</li></ul><h3 id="Workload-Observability"><a href="#Workload-Observability" class="headerlink" title="Workload Observability"></a>Workload Observability</h3><ul><li>• Prometheus</li><li>• Influxdb</li><li>• Grafana</li><li>• Weights and Biases (wandb)</li><li>• OpenTelemetry</li><li>• …</li></ul><h3 id="AutoML"><a href="#AutoML" class="headerlink" title="AutoML"></a>AutoML</h3><ul><li>• Hyperopt</li><li>• Optuna</li><li>• Kubeflow Katib</li><li>• NNI</li><li>• …</li></ul><h3 id="Governance-amp-Policy"><a href="#Governance-amp-Policy" class="headerlink" title="Governance &amp; Policy"></a>Governance &amp; Policy</h3><ul><li>• Kyverno</li><li>• Kyverno-JSON</li><li>• OPA&#x2F;Gatekeeper</li><li>• StackRox Minder</li><li>• …</li></ul><h3 id="Data-Architecture"><a href="#Data-Architecture" class="headerlink" title="Data Architecture"></a>Data Architecture</h3><ul><li>• ClickHouse</li><li>• Apache Pinot</li><li>• Apache Druid</li><li>• Cassandra</li><li>• ScyllaDB</li><li>• Hadoop HDFS</li><li>• Apache HBase</li><li>• Presto</li><li>• Trino</li><li>• Apache Spark</li><li>• Apache Flink</li><li>• Kafka</li><li>• Pulsar</li><li>• Fluid</li><li>• Memcached</li><li>• Redis</li><li>• Alluxio</li><li>• Apache Superset</li><li>• …</li></ul><h3 id="Vector-Databases"><a href="#Vector-Databases" class="headerlink" title="Vector Databases"></a>Vector Databases</h3><ul><li><p>• Milvus</p></li><li><p>• Chroma</p></li><li><p>• Weaviate</p></li><li><p>• Quadrant</p></li><li><p>• Pinecone</p></li><li><p>• Extensions</p></li><li><ul><li>• Redis</li><li>• Postgres SQL</li><li>• ElasticSearch</li></ul></li><li><p>• …</p></li></ul><h3 id="Model-x2F-LLM-Observability"><a href="#Model-x2F-LLM-Observability" class="headerlink" title="Model&#x2F;LLM Observability"></a>Model&#x2F;LLM Observability</h3><ul><li>• Trulens</li><li>• Langfuse</li><li>• Deepchecks</li><li>• OpenLLMetry</li><li>• …</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后，笔者梳理了以下关键观点：</p><ul><li>• <strong>开源社区的推动作用</strong>：白皮书明确指出开源社区对云原生 AI 进步的推动作用，其中包括通过开源项目和广泛的合作来加速创新和降低成本。</li><li>• <strong>云原生技术的重要性</strong>：云原生 AI 是按照云原生原则构建和部署的，突出了可重复性和可扩展性的重要性。云原生技术为 AI 应用提供了高效的开发和运行环境，特别是在资源调度和服务可伸缩性方面。</li><li>• <strong>存在的挑战</strong>：尽管云原生 AI 带来了诸多优势，但在数据准备、模型训练资源需求以及模型安全性和隔离性方面，仍面临不少挑战。</li><li>• <strong>未来发展方向</strong>：白皮书提出的发展路径包括优化资源调度算法以支持 AI 负载，开发新的服务网格技术以提升性能和安全性，以及利用开源项目和社区合作进一步促进技术创新和标准化。</li><li>• <strong>关键技术组件</strong>：云原生 AI 涉及的关键技术包括容器、微服务、服务网格和无服务器计算等，其中 Kubernetes 扮演着 AI 应用部署和管理的中心角色，Istio 和 Envoy 等服务网格技术提供了必要的流量管理和安全保障。</li></ul><p>有关详情，请下载 云原生 AI 白皮书 [4] 。</p><h4 id="引用链接"><a href="#引用链接" class="headerlink" title="引用链接"></a>引用链接</h4><p><code>[1]</code> 白皮书: <em><a href="https://www.cncf.io/reports/cloud-native-artificial-intelligence-whitepaper/">https://www.cncf.io/reports/cloud-native-artificial-intelligence-whitepaper/</a></em><br><code>[2]</code> Hugging Face Collaborates with Microsoft to launch Hugging Face Model Catalog on Azure: <em><a href="https://huggingface.co/blog/hugging-face-endpoints-on-azure">https://huggingface.co/blog/hugging-face-endpoints-on-azure</a></em><br><code>[3]</code> OpenAI Scaling Kubernetes to 7,500 nodes: <em><a href="https://openai.com/research/scaling-kubernetes-to-7500-nodes">https://openai.com/research/scaling-kubernetes-to-7500-nodes</a></em><br><code>[4]</code> 云原生 AI 白皮书: <em><a href="https://www.cncf.io/reports/cloud-native-artificial-intelligence-whitepaper/">https://www.cncf.io/reports/cloud-native-artificial-intelligence-whitepaper/</a></em></p><p>欢迎<a href="http://mp.weixin.qq.com/s?__biz=MzIwNDIzODExOA==&mid=2650168882&idx=2&sn=8e476e78afbdbb43db65caba51e555a3&chksm=8ec1c27bb9b64b6d5413c0c6dc48be79f83091aa5c84c05a0171cb362e4d975f12bf6ad4226f&scene=21#wechat_redirect">加入云原生社区</a>或向社区投稿，点击阅读原文了解更多。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;解读-CNCF-推出的云原生-AI-白皮书&quot;&gt;&lt;a href=&quot;#解读-CNCF-推出的云原生-AI-白皮书&quot; class=&quot;headerlink&quot; title=&quot;解读 CNCF 推出的云原生 AI 白皮书&quot;&gt;&lt;/a&gt;解读 CNCF 推出的云原生 AI 白皮书&lt;/</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="深度学习" scheme="http://ai.mak.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-调参总结</title>
    <link href="http://ai.mak.cn/2024/04/14/ai/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%B0%83%E5%8F%82%E6%80%BB%E7%BB%93/"/>
    <id>http://ai.mak.cn/2024/04/14/ai/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%B0%83%E5%8F%82%E6%80%BB%E7%BB%93/</id>
    <published>2024-04-13T16:00:00.000Z</published>
    <updated>2024-12-17T09:20:18.392Z</updated>
    
    <content type="html"><![CDATA[<h1 id="机器学习-调参总结"><a href="#机器学习-调参总结" class="headerlink" title="机器学习-调参总结"></a>机器学习-调参总结</h1><p><code>超参数调优</code>是机器学习例程中的基本步骤之一。该方法也称为<code>超参数优化</code>，需要搜索超参数的最佳配置以实现最佳性能。</p><p>机器学习算法需要用户定义的输入来实现准确性和通用性之间的平衡。这个过程称为超参数调整。有多种工具和方法可用于调整超参数。</p><blockquote><p>原文出处：<a href="https://analyticsindiamag.com/top-8-approaches-for-tuning-hyperparameters-of-machine-learning-models/">https://analyticsindiamag.com/top-8-approaches-for-tuning-hyperparameters-of-machine-learning-models/</a></p></blockquote><p>本文整理了一份用于调整机器学习模型超参数的前八种方法的列表。</p><h2 id="1-贝叶斯优化"><a href="#1-贝叶斯优化" class="headerlink" title="1 贝叶斯优化"></a>1 贝叶斯优化</h2><p>贝叶斯优化已成为机器学习算法超参数调整的有效工具，更具体地说，适用于深度神经网络等复杂模型。</p><p>它提供了一个有效的框架来优化昂贵的黑盒功能，而无需知道它的形式。它已应用于多个领域，包括学习最优机器人力学、序列实验设计和合成基因设计。</p><h2 id="2-遗传算法"><a href="#2-遗传算法" class="headerlink" title="2 遗传算法"></a>2 遗传算法</h2><p>遗传算法 (EA) 是一种优化算法，它通过根据称为算子的某些规则修改一组候选解决方案（种群）来工作。</p><p>EA 的主要优势之一是它们的通用性：这意味着 EA 可以在广泛的条件下使用，因为它们简单且独立于潜在问题。在超参数调整问题中，遗传算法已被证明比基于精度&#x2F;速度的网格搜索技术表现更好。</p><h2 id="3-基于梯度的优化"><a href="#3-基于梯度的优化" class="headerlink" title="3 基于梯度的优化"></a>3 基于梯度的优化</h2><p>基于梯度的优化是一种优化多个超参数的方法，基于机器学习模型选择标准相对于超参数的梯度计算。</p><p>当满足训练标准的一些可微性和连续性条件时，可以应用这种超参数调整方法。</p><h2 id="4-网格搜索"><a href="#4-网格搜索" class="headerlink" title="4 网格搜索"></a>4 网格搜索</h2><p>网格搜索是超参数调优的基本方法。它对用户指定的超参数集执行详尽的搜索。这种方法是最直接的导致最准确的预测。</p><p>使用这种调优方法，用户可以找到最佳组合。网格搜索适用于几个超参数，但是搜索空间有限。</p><h2 id="5-Keras-Tuner"><a href="#5-Keras-Tuner" class="headerlink" title="5 Keras Tuner"></a>5 Keras Tuner</h2><p>Keras Tuner是一个库，允许用户为机器学习或深度学习模型找到最佳超参数。</p><p>该库有助于查找内核大小、优化学习率和不同的超参数。Keras Tuner可用于为各种深度学习模型获取最佳参数，以实现最高精度。</p><h2 id="6-基于种群的优化"><a href="#6-基于种群的优化" class="headerlink" title="6 基于种群的优化"></a>6 基于种群的优化</h2><p>基于种群的方法本质上是一系列基于随机搜索（如遗传算法）的方法。</p><p>最广泛使用的基于种群的方法之一是 DeepMind 提出的基于种群的训练（PBT）。PBT在两个方面，是一种独特的方法：</p><ul><li>它允许在训练期间使用自适应超参数</li><li>它结合了并行搜索和顺序优化</li></ul><h2 id="7-ParamILS"><a href="#7-ParamILS" class="headerlink" title="7 ParamILS"></a>7 ParamILS</h2><p>ParamILS（参数配置空间中的迭代局部搜索）是一种用于自动算法配置的通用随机局部搜索方法。ParamILS 是一种自动算法配置方法，有助于开发高性能算法及其应用程序。</p><p>ParamILS 使用默认和随机设置进行初始化，并采用迭代第一改进作为辅助本地搜索过程。它还使用固定数量的随机移动来进行扰动，并且总是接受更好或同样好的参数配置，但会随机重新初始化搜索。</p><h2 id="8-随机搜索"><a href="#8-随机搜索" class="headerlink" title="8 随机搜索"></a>8 随机搜索</h2><p>随机搜索可以说是对网格搜索的基本改进。该方法是指对可能参数值的某些分布的超参数进行随机搜索。</p><p>搜索过程继续进行，直到达到所需的精度。随机搜索类似于网格搜索，但已证明比后者创建更好的结果。</p><p>该方法通常被用作 HPO 的基线来衡量新设计算法的效率。尽管随机搜索比网格搜索更有效，但它仍然是一种计算密集型方法。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;机器学习-调参总结&quot;&gt;&lt;a href=&quot;#机器学习-调参总结&quot; class=&quot;headerlink&quot; title=&quot;机器学习-调参总结&quot;&gt;&lt;/a&gt;机器学习-调参总结&lt;/h1&gt;&lt;p&gt;&lt;code&gt;超参数调优&lt;/code&gt;是机器学习例程中的基本步骤之一。该方法也称为&lt;c</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="深度学习" scheme="http://ai.mak.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Mac安装多个JDK版本</title>
    <link href="http://ai.mak.cn/2024/04/10/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/Mac%20%E5%90%8C%E6%97%B6%E5%AE%89%E8%A3%85JDK%E5%A4%9A%E7%89%88%E6%9C%AC/"/>
    <id>http://ai.mak.cn/2024/04/10/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/Mac%20%E5%90%8C%E6%97%B6%E5%AE%89%E8%A3%85JDK%E5%A4%9A%E7%89%88%E6%9C%AC/</id>
    <published>2024-04-09T16:00:00.000Z</published>
    <updated>2024-04-10T06:21:03.061Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>目前很多java应用使用到了jdk8，jdk11，jdk17等不同的版本，Mac上需要安装多个版本，并方便切换</p></blockquote><h3 id="下载JDK"><a href="#下载JDK" class="headerlink" title="下载JDK"></a>下载JDK</h3><p>官方网站：<a href="https://www.oracle.com/cn/java/technologies/downloads/#jdk17-mac">Java Downloads</a> | Oracle</p><p>根据mac芯片是intel还是apple进行不同版本下载：</p><ul><li>ARM64 DMG Installer 苹果M，芯片</li><li>x64 DMG Installer Intel 芯片</li></ul><h3 id="查看安装目录"><a href="#查看安装目录" class="headerlink" title="查看安装目录"></a>查看安装目录</h3><p>安装pkg文件后，打开终端窗口，查看我们安装的 JDK 版本</p><ul><li><p>访问 JDK 安装目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /Library/Java/JavaVirtualMachines</span><br></pre></td></tr></table></figure></li><li><p>查看安装的 JDK 版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -al</span><br></pre></td></tr></table></figure></li></ul><p>可以看到安装了两个版本 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ls -lrt</span><br><span class="line">drwxr-xr-x  3 root  wheel  96  8 22  2017 jdk1.8.0_144.jdk</span><br><span class="line">drwxr-xr-x  3 root  wheel  96  4 10 10:25 jdk-17.jdk</span><br></pre></td></tr></table></figure><h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><p>3.1 打开环境变量文件</p><ul><li><p>输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd ~</span><br></pre></td></tr></table></figure></li><li><p>打开环境变量配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi/subl等 .bash_profile</span><br></pre></td></tr></table></figure><p>3.2 配置 JDK 多版本环境变量</p></li><li><p>复制如下内容粘贴到.bash_profile中，</p></li><li><p>因为我是安装了三个，所以配置了三个版本</p></li><li><p>自己是安装了几个版本就配置几个</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_8_HOME=$(/usr/libexec/java_home -v1.8)</span><br><span class="line">export JAVA_11_HOME=$(/usr/libexec/java_home -v11)</span><br><span class="line">export JAVA_17_HOME=$(/usr/libexec/java_home -v17)</span><br><span class="line"></span><br><span class="line">alias java8=&#x27;export JAVA_HOME=$JAVA_8_HOME&#x27;</span><br><span class="line">alias java11=&#x27;export JAVA_HOME=$JAVA_11_HOME&#x27;</span><br><span class="line">alias java17=&#x27;export JAVA_HOME=$JAVA_17_HOME&#x27;</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=$JAVA_11_HOME</span><br></pre></td></tr></table></figure></li><li><p>保存</p></li><li><p>3.3 检查环境变量</p></li><li><p>配置文件立即生效</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source .bash_profile</span><br></pre></td></tr></table></figure></li><li><p>查看 JAVA_HOME 目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo $JAVA_HOME</span><br></pre></td></tr></table></figure></li><li><p>查看 JDK 版本信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure></li></ul><ol start="4"><li>JDK 版本切换<br>我们定义了个别名：java8，和java17，其中默认配置为 jdk11。</li></ol><p>相互切换，在终端中输入命令即可，如下</p><ul><li><p>切换到JDK8：<br>java8 </p></li><li><p>查看 JDK 版本信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure></li><li><p>切换到JDK11：<br>java11</p></li></ul><h1 id="查看-JDK-版本信息"><a href="#查看-JDK-版本信息" class="headerlink" title="查看 JDK 版本信息"></a>查看 JDK 版本信息</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure><ul><li>切换到JDK17：<br>java17</li></ul><h1 id="查看-JDK-版本信息-1"><a href="#查看-JDK-版本信息-1" class="headerlink" title="查看 JDK 版本信息"></a>查看 JDK 版本信息</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure><p>————————————————</p><p>原文链接：<a href="https://blog.csdn.net/Zhaoruifeng158/article/details/135832564">https://blog.csdn.net/Zhaoruifeng158/article/details/135832564</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;目前很多java应用使用到了jdk8，jdk11，jdk17等不同的版本，Mac上需要安装多个版本，并方便切换&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;下载JDK&quot;&gt;&lt;a href=&quot;#下载JDK&quot; class=&quot;headerlink&quot;</summary>
      
    
    
    
    <category term="工具" scheme="http://ai.mak.cn/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="mac" scheme="http://ai.mak.cn/tags/mac/"/>
    
  </entry>
  
  <entry>
    <title>基于神经网络的网络流量预测</title>
    <link href="http://ai.mak.cn/2024/03/26/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/%E5%9F%BA%E4%BA%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B/"/>
    <id>http://ai.mak.cn/2024/03/26/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/%E5%9F%BA%E4%BA%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B/</id>
    <published>2024-03-25T16:00:00.000Z</published>
    <updated>2024-03-29T07:32:30.409Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-背景介绍"><a href="#1-背景介绍" class="headerlink" title="1.背景介绍"></a>1.背景介绍</h1><p>随着互联网的不断发展，网络流量预测已经成为一项重要的技术，用于优化网络资源分配、提高网络性能和可靠性。传统的流量预测方法主要基于统计学和机器学习，但这些方法在处理复杂网络流量数据时存在一定局限性。深度学习技术在近年来迅速发展，已经成功应用于多个领域，包括图像识别、自然语言处理、语音识别等。因此，研究深度学习在网络流量预测中的应用具有重要意义。</p><p>本文将从以下几个方面进行阐述：</p><ol><li>背景介绍</li><li>核心概念与联系</li><li>核心算法原理和具体操作步骤以及数学模型公式详细讲解</li><li>具体代码实例和详细解释说明</li><li>未来发展趋势与挑战</li><li>附录常见问题与解答</li></ol><h1 id="2-核心概念与联系"><a href="#2-核心概念与联系" class="headerlink" title="2. 核心概念与联系"></a>2. 核心概念与联系</h1><p>网络流量预测是指根据历史网络流量数据，预测未来网络流量的大小和趋势。这项技术在网络规划、运营和管理中具有重要意义，可以帮助网络管理员更有效地分配网络资源、提高网络性能和可靠性。</p><p>深度学习是一种人工智能技术，通过模拟人类大脑的学习和思维过程，使计算机能够从数据中自动学习出模式和规律。深度学习技术在图像识别、自然语言处理、语音识别等领域取得了显著的成功，因此在网络流量预测领域也有广泛的应用前景。</p><h1 id="3-核心算法原理和具体操作步骤以及数学模型公式详细讲解"><a href="#3-核心算法原理和具体操作步骤以及数学模型公式详细讲解" class="headerlink" title="3. 核心算法原理和具体操作步骤以及数学模型公式详细讲解"></a>3. 核心算法原理和具体操作步骤以及数学模型公式详细讲解</h1><p>深度学习在网络流量预测中主要应用于以下几种算法：</p><ol><li>卷积神经网络（CNN）</li><li>循环神经网络（RNN）</li><li>长短期记忆网络（LSTM）</li><li>自编码器（Autoencoder）</li><li>卷积递归神经网络（CRNN）</li></ol><p>下面我们将逐一详细介绍这些算法的原理、步骤和数学模型。</p><h2 id="1-卷积神经网络（CNN）"><a href="#1-卷积神经网络（CNN）" class="headerlink" title="1. 卷积神经网络（CNN）"></a>1. 卷积神经网络（CNN）</h2><p>卷积神经网络（Convolutional Neural Networks，CNN）是一种深度学习算法，主要应用于图像和音频等二维和一维数据的处理。在网络流量预测中，CNN可以用于处理时间序列数据，以捕捉流量数据中的时间特征。</p><p>CNN的主要组件包括卷积层、池化层和全连接层。卷积层用于对输入数据进行卷积操作，以提取特征；池化层用于对卷积层的输出进行下采样，以减少参数数量和计算复杂度；全连接层用于对池化层的输出进行分类。</p><p>在网络流量预测中，CNN的具体操作步骤如下：</p><ol><li>数据预处理：将原始流量数据进行归一化处理，以减少计算复杂度和提高模型性能。</li><li>构建CNN模型：根据问题需求选择合适的CNN结构，包括卷积层、池化层和全连接层的数量和大小。</li><li>训练模型：使用历史流量数据训练CNN模型，以学习出流量特征。</li><li>预测流量：使用训练好的CNN模型对未来流量数据进行预测。</li></ol><h2 id="2-循环神经网络（RNN）"><a href="#2-循环神经网络（RNN）" class="headerlink" title="2. 循环神经网络（RNN）"></a>2. 循环神经网络（RNN）</h2><p>循环神经网络（Recurrent Neural Networks，RNN）是一种能够处理序列数据的深度学习算法。在网络流量预测中，RNN可以用于处理时间序列数据，以捕捉流量数据中的时间特征。</p><p>RNN的主要组件包括隐藏层和输出层。隐藏层用于存储和更新序列数据，输出层用于输出预测结果。RNN的主要优势在于可以捕捉序列数据中的长距离依赖关系，但其主要缺点是难以处理长序列数据，容易出现梯度消失问题。</p><p>在网络流量预测中，RNN的具体操作步骤如下：</p><ol><li>数据预处理：将原始流量数据进行归一化处理，以减少计算复杂度和提高模型性能。</li><li>构建RNN模型：根据问题需求选择合适的RNN结构，包括隐藏层和输出层的数量和大小。</li><li>训练模型：使用历史流量数据训练RNN模型，以学习出流量特征。</li><li>预测流量：使用训练好的RNN模型对未来流量数据进行预测。</li></ol><h2 id="3-长短期记忆网络（LSTM）"><a href="#3-长短期记忆网络（LSTM）" class="headerlink" title="3. 长短期记忆网络（LSTM）"></a>3. 长短期记忆网络（LSTM）</h2><p>长短期记忆网络（Long Short-Term Memory，LSTM）是一种特殊的RNN，具有内部状态和门机制，可以更好地处理长序列数据。在网络流量预测中，LSTM可以用于处理时间序列数据，以捕捉流量数据中的时间特征。</p><p>LSTM的主要组件包括输入门、遗忘门、输出门和内部状态。这些门机制可以控制信息的进入、保留和输出，从而解决RNN中的梯度消失问题。</p><p>在网络流量预测中，LSTM的具体操作步骤如下：</p><ol><li>数据预处理：将原始流量数据进行归一化处理，以减少计算复杂度和提高模型性能。</li><li>构建LSTM模型：根据问题需求选择合适的LSTM结构，包括隐藏层和输出层的数量和大小。</li><li>训练模型：使用历史流量数据训练LSTM模型，以学习出流量特征。</li><li>预测流量：使用训练好的LSTM模型对未来流量数据进行预测。</li></ol><h2 id="4-自编码器（Autoencoder）"><a href="#4-自编码器（Autoencoder）" class="headerlink" title="4. 自编码器（Autoencoder）"></a>4. 自编码器（Autoencoder）</h2><p>自编码器（Autoencoder）是一种深度学习算法，主要应用于降维和生成任务。在网络流量预测中，自编码器可以用于处理时间序列数据，以捕捉流量数据中的时间特征。</p><p>自编码器的主要组件包括编码层和解码层。编码层用于对输入数据进行编码，以提取特征；解码层用于对编码后的数据进行解码，以重构原始数据。自编码器的目标是使解码后的数据与原始数据最小化差异。</p><p>在网络流量预测中，自编码器的具体操作步骤如下：</p><ol><li>数据预处理：将原始流量数据进行归一化处理，以减少计算复杂度和提高模型性能。</li><li>构建自编码器模型：根据问题需求选择合适的自编码器结构，包括编码层和解码层的数量和大小。</li><li>训练模型：使用历史流量数据训练自编码器模型，以学习出流量特征。</li><li>预测流量：使用训练好的自编码器模型对未来流量数据进行预测。</li></ol><h2 id="5-卷积递归神经网络（CRNN）"><a href="#5-卷积递归神经网络（CRNN）" class="headerlink" title="5. 卷积递归神经网络（CRNN）"></a>5. 卷积递归神经网络（CRNN）</h2><p>卷积递归神经网络（Convolutional Recurrent Neural Networks，CRNN）是一种结合卷积神经网络和循环神经网络的深度学习算法。在网络流量预测中，CRNN可以用于处理时间序列数据，以捕捉流量数据中的时间特征。</p><p>CRNN的主要组件包括卷积层、池化层、隐藏层和输出层。卷积层用于对输入数据进行卷积操作，以提取特征；池化层用于对卷积层的输出进行下采样，以减少参数数量和计算复杂度；隐藏层用于存储和更新序列数据；输出层用于输出预测结果。</p><p>在网络流量预测中，CRNN的具体操作步骤如下：</p><ol><li>数据预处理：将原始流量数据进行归一化处理，以减少计算复杂度和提高模型性能。</li><li>构建CRNN模型：根据问题需求选择合适的CRNN结构，包括卷积层、池化层、隐藏层和输出层的数量和大小。</li><li>训练模型：使用历史流量数据训练CRNN模型，以学习出流量特征。</li><li>预测流量：使用训练好的CRNN模型对未来流量数据进行预测。</li></ol><h1 id="4-具体代码实例和详细解释说明"><a href="#4-具体代码实例和详细解释说明" class="headerlink" title="4. 具体代码实例和详细解释说明"></a>4. 具体代码实例和详细解释说明</h1><p>在本节中，我们将通过一个简单的例子来演示如何使用Python和Keras库实现网络流量预测。</p><p>首先，安装所需的库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bash</span><br><span class="line">复制代码pip install numpy pandas keras tensorflow</span><br></pre></td></tr></table></figure><p>然后，准备数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line">复制代码<span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;flow_data.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择时间序列数据</span></span><br><span class="line">time_series = data[<span class="string">&#x27;flow&#x27;</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># 归一化数据</span></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line">time_series = scaler.fit_transform(time_series.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割数据</span></span><br><span class="line">look_back = <span class="number">60</span></span><br><span class="line">X, y = [], []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(look_back, <span class="built_in">len</span>(time_series)):</span><br><span class="line">    X.append(time_series[i-look_back:i, <span class="number">0</span>])</span><br><span class="line">    y.append(time_series[i, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">X, y = np.array(X), np.array(y)</span><br><span class="line">X = np.reshape(X, (X.shape[<span class="number">0</span>], X.shape[<span class="number">1</span>], <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割训练集和测试集</span></span><br><span class="line">train_size = <span class="built_in">int</span>(<span class="built_in">len</span>(X) * <span class="number">0.8</span>)</span><br><span class="line">X_train, X_test = X[:train_size], X[train_size:]</span><br><span class="line">y_train, y_test = y[:train_size], y[train_size:]</span><br></pre></td></tr></table></figure><p>接下来，构建模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line">复制代码<span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, LSTM</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建LSTM模型</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(<span class="number">50</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(X_train.shape[<span class="number">1</span>], <span class="number">1</span>)))</span><br><span class="line">model.add(Dense(<span class="number">1</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;mse&#x27;</span>)</span><br></pre></td></tr></table></figure><p>然后，训练模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line">复制代码model.fit(X_train, y_train, epochs=<span class="number">100</span>, batch_size=<span class="number">32</span>)</span><br></pre></td></tr></table></figure><p>最后，预测流量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line">复制代码predicted_flow = model.predict(X_test)</span><br><span class="line">predicted_flow = scaler.inverse_transform(predicted_flow)</span><br></pre></td></tr></table></figure><h1 id="5-未来发展趋势与挑战"><a href="#5-未来发展趋势与挑战" class="headerlink" title="5. 未来发展趋势与挑战"></a>5. 未来发展趋势与挑战</h1><p>随着深度学习技术的不断发展，网络流量预测将会面临以下几个挑战：</p><ol><li>数据不足和质量问题：网络流量数据通常是大量的、高维的、不均匀的，这会增加预测模型的难度。未来，需要开发更高效的数据预处理和增强技术，以提高模型性能。</li><li>模型复杂性和计算成本：深度学习模型通常具有较高的参数数量和计算复杂度，这会增加训练和预测的时间和资源消耗。未来，需要开发更简洁的模型结构和更高效的计算方法，以提高模型性能和可扩展性。</li><li>多源数据集成：网络流量数据通常来自多个不同的源，如路由器、交换机、服务器等。未来，需要开发更智能的数据集成和融合技术，以提高预测准确性。</li><li>实时预测和自适应调整：网络流量是时间序列数据，其特征和模式可能会随着时间的推移发生变化。未来，需要开发更智能的实时预测和自适应调整技术，以提高预测准确性和可靠性。</li></ol><h1 id="6-附录常见问题与解答"><a href="#6-附录常见问题与解答" class="headerlink" title="6. 附录常见问题与解答"></a>6. 附录常见问题与解答</h1><p>Q: 深度学习在网络流量预测中的优势是什么？</p><p>A: 深度学习在网络流量预测中的优势主要体现在以下几个方面：</p><ol><li>能够捕捉时间序列数据中的复杂特征，以提高预测准确性。</li><li>能够自动学习出流量特征，无需人工特征工程。</li><li>能够处理大量、高维的数据，提高模型性能。</li><li>能够实现实时预测和自适应调整，提高预测可靠性。</li></ol><p>Q: 深度学习在网络流量预测中的局限性是什么？</p><p>A: 深度学习在网络流量预测中的局限性主要体现在以下几个方面：</p><ol><li>需要大量的训练数据，可能会导致过拟合和欠拟合问题。</li><li>模型参数数量和计算复杂度较高，可能会导致训练和预测的时间和资源消耗。</li><li>模型解释性较差，可能会导致预测结果的可解释性问题。</li></ol><p>Q: 如何选择合适的深度学习算法？</p><p>A: 选择合适的深度学习算法需要考虑以下几个因素：</p><ol><li>问题类型：根据问题类型选择合适的深度学习算法，如图像识别、自然语言处理、语音识别等。</li><li>数据特征：根据数据特征选择合适的深度学习算法，如时间序列数据、空间数据、文本数据等。</li><li>模型性能：根据模型性能选择合适的深度学习算法，如准确性、召回率、F1分数等。</li><li>计算资源：根据计算资源选择合适的深度学习算法，如GPU、TPU、CPU等。</li></ol><h1 id="7-参考文献"><a href="#7-参考文献" class="headerlink" title="7. 参考文献"></a>7. 参考文献</h1><p>[1] Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). Deep Learning. MIT Press.</p><p>[2] Chollet, F. (2017). Deep Learning with Python. Manning Publications Co.</p><p>[3] Zhou, H., &amp; Liu, B. (2018). A Comprehensive Survey on Deep Learning for Traffic Prediction. arXiv preprint arXiv:1809.03160.</p><p>[4] Wang, Y., Zhang, Y., &amp; Zhang, J. (2017). Deep Learning for Network Traffic Prediction. arXiv preprint arXiv:1703.06856.</p><p>[5] LSTM: Long Short-Term Memory. (n.d.). Retrieved from <a href="https://link.juejin.cn/?target=https://keras.io/layers/recurrent/%23lstm">keras.io&#x2F;layers&#x2F;recu…</a></p><p>[6] CRNN: Convolutional Recurrent Neural Networks. (n.d.). Retrieved from <a href="https://link.juejin.cn/?target=https://keras.io/examples/cnn/%23convolutional-recurrent-neural-networks-crnn">keras.io&#x2F;examples&#x2F;cn…</a></p><p>[7] Autoencoder. (n.d.). Retrieved from <a href="https://link.juejin.cn/?target=https://keras.io/examples/generative/autoencoder/">keras.io&#x2F;examples&#x2F;ge…</a></p><p>[8] MinMaxScaler. (n.d.). Retrieved from <a href="https://link.juejin.cn/?target=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html">scikit-learn.org&#x2F;stable&#x2F;modu…</a></p><p>[9] TensorFlow. (n.d.). Retrieved from <a href="https://link.juejin.cn/?target=https://www.tensorflow.org/">www.tensorflow.org/</a></p><p>[10] Keras. (n.d.). Retrieved from <a href="https://link.juejin.cn/?target=https://keras.io/">keras.io&#x2F;</a></p><p>[11] Pandas. (n.d.). Retrieved from <a href="https://link.juejin.cn/?target=https://pandas.pydata.org/pandas-docs/stable/index.html">pandas.pydata.org&#x2F;pandas-docs…</a></p><p>[12] NumPy. (n.d.). Retrieved from <a href="https://link.juejin.cn/?target=https://numpy.org/doc/stable/index.html">numpy.org&#x2F;doc&#x2F;stable&#x2F;…</a></p><p>[13] Scikit-learn. (n.d.). Retrieved from <a href="https://link.juejin.cn/?target=https://scikit-learn.org/stable/index.html">scikit-learn.org&#x2F;stable&#x2F;inde…</a></p><p>[14] TensorFlow: A Scalable Machine Learning Framework for Everyone. (2015). Retrieved from <a href="https://link.juejin.cn/?target=https://www.tensorflow.org/overview">www.tensorflow.org/overview</a></p><p>[15] Chollet, F. (2015). Deep Learning with TensorFlow. O’Reilly Media.</p><p>[16] Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). Deep Learning. MIT Press.</p><p>[17] LeCun, Y., Bengio, Y., &amp; Hinton, G. (2015). Deep Learning. Nature, 521(7553), 436-444.</p><p>[18] Bengio, Y. (2009). Learning Deep Architectures for AI. Foundations and Trends® in Machine Learning, 2(1-5), 1-142.</p><p>[19] Schmidhuber, J. (2015). Deep Learning in Neural Networks: An Introduction. arXiv preprint arXiv:1505.00091.</p><p>[20] Hochreiter, S., &amp; Schmidhuber, J. (1997). Long Short-Term Memory. Neural Computation, 9(8), 1735-1780.</p><p>[21] Xing, J., Cui, Y., &amp; Tong, H. (2015). Convolutional Recurrent Neural Networks. arXiv preprint arXiv:1503.00315.</p><p>[22] Bengio, Y., Courville, A., &amp; Vincent, P. (2012). Deep Learning. Foundations and Trends® in Machine Learning, 3(1-5), 1-316.</p><p>[23] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio, Y. (2014). Generative Adversarial Networks. arXiv preprint arXiv:1406.2661.</p><p>[24] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio, Y. (2014). Generative Adversarial Networks. arXiv preprint arXiv:1406.2661.</p><p>[25] Hinton, G., Srivastava, N., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2012). Deep Learning. Nature, 489(7416), 242-243.</p><p>[26] LeCun, Y., Bottou, L., Bengio, Y., &amp; Hinton, G. (2015). Deep Learning. Nature, 521(7553), 436-444.</p><p>[27] Bengio, Y. (2009). Learning Deep Architectures for AI. Foundations and Trends® in Machine Learning, 2(1-5), 1-142.</p><p>[28] Schmidhuber, J. (2015). Deep Learning in Neural Networks: An Introduction. arXiv preprint arXiv:1505.00091.</p><p>[29] Hochreiter, S., &amp; Schmidhuber, J. (1997). Long Short-Term Memory. Neural Computation, 9(8), 1735-1780.</p><p>[30] Xing, J., Cui, Y., &amp; Tong, H. (2015). Convolutional Recurrent Neural Networks. arXiv preprint arXiv:1503.00315.</p><p>[31] Bengio, Y., Courville, A., &amp; Vincent, P. (2012). Deep Learning. Foundations and Trends® in Machine Learning, 3(1-5), 1-316.</p><p>[32] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio, Y. (2014). Generative Adversarial Networks. arXiv preprint arXiv:1406.2661.</p><p>[33] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio, Y. (2014). Generative Adversarial Networks. arXiv preprint arXiv:1406.2661.</p><p>[34] Hinton, G., Srivastava, N., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2012). Deep Learning. Nature, 489(7416), 242-243.</p><p>[35] LeCun, Y., Bottou, L., Bengio, Y., &amp; Hinton, G. (2015). Deep Learning. Nature, 521(7553), 436-444.</p><p>[36] Bengio, Y. (2009). Learning Deep Architectures for AI. Foundations and Trends® in Machine Learning, 2(1-5), 1-142.</p><p>[37] Schmidhuber, J. (2015). Deep Learning in Neural Networks: An Introduction. arXiv preprint arXiv:1505.00091.</p><p>[38] Hochreiter, S., &amp; Schmidhuber, J. (1997). Long Short-Term Memory. Neural Computation, 9(8), 1735-1780.</p><p>[39] Xing, J., Cui, Y., &amp; Tong, H. (2015). Convolutional Recurrent Neural Networks. arXiv preprint arXiv:1503.00315.</p><p>[40] Bengio, Y., Courville, A., &amp; Vincent, P. (2012). Deep Learning. Foundations and Trends® in Machine Learning, 3(1-5), 1-316.</p><p>[41] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio, Y. (2014). Generative Adversarial Networks. arXiv preprint arXiv:1406.2661.</p><p>[42] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio, Y. (2014). Generative Adversarial Networks. arXiv preprint arXiv:1406.2661.</p><p>[43] Hinton, G., Srivastava, N., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2012). Deep Learning. Nature, 489(7416), 242-243.</p><p>[44] LeCun, Y., Bottou, L., Bengio, Y., &amp; Hinton, G. (2015). Deep Learning. Nature, 521(7553), 436-444.</p><p>[45] Bengio, Y. (2009). Learning Deep Architectures for AI. Foundations and Trends® in Machine Learning, 2(1-5), 1-142.</p><p>[46] Schmidhuber, J. (2015). Deep Learning in Neural Networks: An Introduction. arXiv preprint arXiv:1505.00091.</p><p>[47] Hochreiter, S., &amp; Schmidhuber, J. (1997). Long Short-Term Memory. Neural Computation, 9(8), 1735-1780.</p><p>[48] Xing, J., Cui, Y., &amp; Tong, H. (2015). Convolutional Recurrent Neural Networks. arXiv preprint arXiv:1503.00315.</p><p>[49] Bengio, Y., Courville, A., &amp; Vincent, P. (2012). Deep Learning. Foundations and Trends® in Machine Learning, 3(1-5), 1-316.</p><p>[50] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio, Y. (2014). Generative Adversarial Networks. arXiv preprint arXiv:1406.2661.</p><p>[51] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio, Y. (2014). Generative Adversarial Networks. arXiv preprint arXiv:1406.2661.</p><p>[52] Hinton, G., Srivastava, N., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2012). Deep Learning. Nature, 489(7416), 242-243.</p><p>[53] LeCun, Y., Bottou, L., Bengio, Y., &amp; Hinton, G. (2015). Deep Learning. Nature, 521(7553), 436-444.</p><p>[54] Bengio, Y. (2009). Learning Deep Architectures for AI. Foundations and Trends® in Machine Learning, 2(1-5), 1-142.</p><p>[55] Schmidhuber, J. (2015). Deep Learning in Neural Networks: An Introduction. arXiv preprint arXiv:1505.00091.</p><p>[56] Hochreiter, S., &amp; Schmidhuber, J. (1997). Long Short-Term Memory. Neural Computation, 9(8), 1735-1780.</p><p>[57] Xing, J., Cui, Y., &amp; Tong, H. (2015). Convolutional Recurrent Neural Networks. arXiv preprint arXiv:1503.00315.</p><p>[58] Bengio, Y., Courville, A., &amp; Vincent, P. (2012). Deep Learning. Foundations and Trends® in Machine Learning, 3(1-5), 1-316.</p><p>[59] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio, Y. (2014). Generative Adversarial Networks. arXiv preprint arXiv:1406.2661.</p><p>[60] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio, Y. (2014). Generative Adversarial Networks. arXiv preprint arXiv:1406.2661.</p><p>[61] Hinton, G., Srivastava, N., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2012). Deep Learning. Nature, 489(7416), 242-243.</p><p>[62] LeCun, Y., Bottou, L., Bengio, Y., &amp; Hinton, G. (2015). Deep Learning. Nature, 521(7553), 436-444.</p><p>[63] Bengio, Y. (2009). Learning Deep Architectures for AI. Foundations and Trends® in Machine Learning, 2(1-5), 1-142.</p><p>[64] Schmidhuber, J. (2015). Deep Learning in Neural Networks: An Introduction. arXiv preprint arXiv:1505.00091.</p><p>[65] Hochreiter, S., &amp; Schmidhuber, J. (1997). Long Short-Term Memory. Neural Computation, 9(8), 1735-1780.</p><p>[66] Xing, J., Cui, Y., &amp; Tong, H. (2015). Convolutional Recurrent Neural Networks. arXiv preprint arXiv:1503.0031</p><p>作者：OpenChat<br>链接：<a href="https://juejin.cn/post/7325129599447531570">https://juejin.cn/post/7325129599447531570</a><br>来源：稀土掘金</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-背景介绍&quot;&gt;&lt;a href=&quot;#1-背景介绍&quot; class=&quot;headerlink&quot; title=&quot;1.背景介绍&quot;&gt;&lt;/a&gt;1.背景介绍&lt;/h1&gt;&lt;p&gt;随着互联网的不断发展，网络流量预测已经成为一项重要的技术，用于优化网络资源分配、提高网络性能和可靠性。传统的</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="深度学习" scheme="http://ai.mak.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>如何理解 LSTM神经网络模型</title>
    <link href="http://ai.mak.cn/2024/02/27/ai/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%20LSTM%20%E7%BD%91%E7%BB%9C/"/>
    <id>http://ai.mak.cn/2024/02/27/ai/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%20LSTM%20%E7%BD%91%E7%BB%9C/</id>
    <published>2024-02-26T16:00:00.000Z</published>
    <updated>2024-05-28T07:08:56.412Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>转载 <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p></blockquote><h1 id="如何理解-LSTM神经网络模型"><a href="#如何理解-LSTM神经网络模型" class="headerlink" title="如何理解 LSTM神经网络模型"></a>如何理解 LSTM神经网络模型</h1><h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h2><p>人类不会每分每秒都从头开始思考。当你阅读这篇文章时，你会根据对前面单词的理解来理解每个单词。你不会抛弃一切，重新从头开始思考。你的思想具有持久性。</p><p>传统的神经网络无法做到这一点，这似乎是一个重大缺陷。例如，假设你想对电影中每个时刻发生的事件进行分类。目前还不清楚传统的神经网络如何利用其对电影中先前事件的推理来指导后续事件。</p><p>循环神经网络解决了这个问题。它们是具有循环的网络，可使信息持久存在。</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-rolled.png" alt="img"></p><p><strong>循环神经网络</strong></p><p>在上图中，神经网络的一个部分，A，查看一些输入<code>X_t</code>，并输出一个值<code>h_t</code>. 循环允许信息从网络的一个步骤传递到下一个步骤。</p><p>这些循环使得循环神经网络看起来有些神秘。但是，如果你再仔细想想，就会发现它们与普通神经网络并没有太大区别。循环神经网络可以看作是同一网络的多个副本，每个副本都会向后继者传递一条消息。考虑一下如果我们展开循环会发生什么：</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png" alt="展开的循环神经网络。"></p><p><strong>展开的循环神经网络。</strong></p><p>这种链式特性表明循环神经网络与序列和列表密切相关。它们是用于此类数据的神经网络的自然架构。</p><p>而且它们确实被使用！在过去的几年中，RNN 在各种问题上的应用取得了令人难以置信的成功：语音识别、语言建模、翻译、图像字幕……等等。在 Andrej Karpathy 的优秀博客文章《循环<a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">神经网络的不合理有效性》</a>中讨论使用 RNN 可以实现的惊人成就。但它们确实非常了不起。</p><p>这些成功的关键在于使用“LSTM”，这是一种非常特殊的循环神经网络，在许多任务中，它的效果比标准版本好得多。几乎所有基于循环神经网络的令人兴奋的结果都是通过它们实现的。本文将探讨的就是这些 LSTM。</p><h2 id="长期依赖的问题"><a href="#长期依赖的问题" class="headerlink" title="长期依赖的问题"></a>长期依赖的问题</h2><p>RNN 的吸引力之一是它们可能能够将先前的信息与当前任务联系起来，例如使用先前的视频帧可能有助于理解当前帧。如果 RNN 能够做到这一点，它们将非常有用。但它们能做到吗？这取决于情况。</p><p>有时，我们只需要查看最近的信息即可执行当前任务。例如，考虑一个语言模型，它试图根据前面的单词预测下一个单词。如果我们试图预测 <strong>“云在天空中”</strong> 中的最后一个单词，我们不需要任何其他上下文——很明显下一个单词将是天空。在这种情况下，相关信息与需要它的地方之间的差距很小，RNN 可以学习使用过去的信息。</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-shorttermdepdencies.png" alt="img"></p><p>但也有需要更多背景信息的情况。考虑尝试预测文本“我在法国长大……我能说一口流利的<em>法语</em>”中的最后一个单词。最近的信息表明下一个单词可能是一种语言的名称，但如果我们想缩小范围，确定是哪种语言，我们需要更早的法国背景信息。相关信息与需要信息点之间的差距完全有可能变得非常大。</p><p>不幸的是，随着差距的扩大，RNN 无法学会连接信息。</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-longtermdependencies.png" alt="神经网络难以应对长期依赖关系。"></p><p>理论上，RNN 绝对有能力处理这种“长期依赖关系”。人类可以仔细挑选参数来解决这种形式的小问题。遗憾的是，在实践中，RNN 似乎无法学习它们。Hochreiter [(1991) <a href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf">德语]</a>和<a href="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf">Bengio 等人 (1994)</a>深入探讨了这个问题，他们发现了一些非常根本的原因，说明这个问题可能很难解决。</p><p>值得庆幸的是，LSTM 没有这个问题！</p><h2 id="LSTM-网络"><a href="#LSTM-网络" class="headerlink" title="LSTM 网络"></a>LSTM 网络</h2><p>长短期记忆网络（通常简称为“LSTM”）是一种特殊的 RNN，能够学习长期依赖关系。它们由<a href="http://www.bioinf.jku.at/publications/older/2604.pdf">Hochreiter 和 Schmidhuber（1997 年）</a>提出，并在后续工作中被许多人改进和推广。1<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/#fn1">它们</a>在解决各种问题方面都表现出色，目前已被广泛使用。</p><p>LSTM 的设计明确地避免了长期依赖问题。长时间记忆信息实际上是它们的默认行为，而不是它们需要努力学习的事情！</p><p>所有循环神经网络都具有神经网络重复模块链的形式。在标准 RNN 中，此重复模块将具有非常简单的结构，例如单个 tanh 层。</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png" alt="img"></p><p><strong>标准 RNN 中的重复模块包含单层。</strong></p><p>LSTM 也具有这种链式结构，但重复模块的结构不同。它不是只有一个神经网络层，而是有四个，并以非常特殊的方式相互作用。</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png" alt="LSTM 神经网络。"></p><p><strong>LSTM 中的重复模块包含四个交互层。</strong></p><p>不必担心细节。稍后我们将逐步介绍 LSTM 图。现在，我们先熟悉一下我们将要使用的符号。</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM2-notation.png" alt="img"></p><p>在上图中，每条线都承载着一个完整的向量，从一个节点的输出到其他节点的输入。粉色圆圈表示逐点运算，如向量加法，而黄色框表示学习到的神经网络层。线合并表示连接，而线分叉表示其内容被复制，副本被发送到不同的位置。</p><h2 id="LSTM-背后的核心思想"><a href="#LSTM-背后的核心思想" class="headerlink" title="LSTM 背后的核心思想"></a>LSTM 背后的核心思想</h2><p>LSTM 的关键是细胞状态，即贯穿图表顶部的水平线。</p><p>细胞状态有点像传送带。它沿着整个链条笔直运行，只有一些微小的线性相互作用。信息很容易不加改变地沿着它流动。</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-C-line.png" alt="img"></p><p>LSTM 确实有能力从细胞状态中删除或添加信息，并由称为门的结构严格调节。</p><p>门是一种选择性地让信息通过的方式。它们由 S 型神经网络层和逐点乘法运算组成。</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-gate.png" alt="img"></p><p>S 型层输出介于 0 和 1 之间的数字，描述每个组件应通过的量。值为 0 表示“不让任何组件通过”，而值为 1 表示“让所有组件通过！”</p><p>LSTM 有三个这样的门，用于保护和控制单元状态。</p><h2 id="逐步了解-LSTM"><a href="#逐步了解-LSTM" class="headerlink" title="逐步了解 LSTM"></a>逐步了解 LSTM</h2><p>我们的 LSTM 的第一步是决定要从细胞状态中丢弃哪些信息。这个决定是由一个叫做“遗忘门”的 S 型层做出的。它查看<code>h_&#123;t-1&#125;</code>和<code>x_t</code>，并输出一个介于 0 和 1 对于细胞状态中的每个数字<code>C_&#123;t-1&#125;</code>。 A. 1 代表“完全保留这一点”，而0 代表“彻底摆脱这个。”</p><p>让我们回到语言模型的示例，该模型尝试根据所有先前的单词预测下一个单词。在这样的问题中，单元状态可能包括当前主语的性别，以便可以使用正确的代词。当我们看到一个新主语时，我们希望忘记旧主语的性别。</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-f.png" alt="img"></p><p>下一步是决定我们要在单元状态中存储哪些新信息。这分为两部分。首先，一个称为“输入门”的 S 型层决定我们要更新哪些值。接下来，一个 tanh 层创建一个新候选值的向量，<code>C̃_t</code>，可以将其添加到状态中。在下一步中，我们将把这两者结合起来，以创建对状态的更新。</p><p>在我们的语言模型示例中，我们希望将新主语的性别添加到单元状态中，以替换我们忘记的旧主语。</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-i.png" alt="img"></p><p>现在是时候更新旧的细胞状态了，<code>x_&#123;t-1&#125;</code>，进入新的细胞状态 <code>C_t</code> 前面的步骤已经决定了要做什么，我们只需要实际去做。</p><p>我们将旧状态乘以 <code>f~_t</code>，忘记我们之前决定忘记的事情。然后我们添加 <code>i_t</code>*<code>C̃_t</code>。这是新的候选值，根据我们决定更新每个状态值的程度进行缩放。</p><p>在语言模型的情况下，我们实际上会删除有关旧主题性别的信息并添加新信息，正如我们在前面的步骤中所决定的那样。</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-C.png" alt="img"></p><p>最后，我们需要决定要输出什么。此输出将基于我们的细胞状态，但将是一个经过过滤的版本。首先，我们运行一个 S 型层，它决定要输出细胞状态的哪些部分。然后，我们将细胞状态通过双曲函数双曲函数（将值推至− 1 和 1 ）并将其乘以 S 型门的输出，这样我们就只输出我们决定的部分。</p><p>对于语言模型示例，由于它刚刚看到一个主语，因此它可能需要输出与动词相关的信息，以防接下来是动词。例如，它可能会输出主语是单数还是复数，这样我们就知道如果接下来是动词，动词应该变位成什么形式。</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-o.png" alt="img"></p><h2 id="长期短期记忆的变体"><a href="#长期短期记忆的变体" class="headerlink" title="长期短期记忆的变体"></a>长期短期记忆的变体</h2><p>到目前为止，我所描述的是一个非常普通的 LSTM。但并非所有 LSTM 都与上面的相同。事实上，几乎每篇涉及 LSTM 的论文似乎都使用了略有不同的版本。这些差异很小，但值得一提的是其中的一些。</p><p><a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf">Gers 和 Schmidhuber (2000)</a>提出的一种流行的 LSTM 变体是添加“窥孔连接”。这意味着我们让门层查看单元状态。</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-peepholes.png" alt="img"></p><p>上图为所有门添加了窥视孔，但许多论文只会给出一些窥视孔，而不会给出其他窥视孔。</p><p>另一种变体是使用耦合的遗忘门和输入门。我们不是分别决定遗忘什么以及应该向什么添加新信息，而是一起做出这些决定。我们只会在要输入某些东西来代替它时才会忘记。我们只会在忘记旧东西时向状态输入新值。</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-tied.png" alt="img"></p><p><a href="http://arxiv.org/pdf/1406.1078v3.pdf">LSTM 的一个稍微更戏剧性的变体是Cho 等人（2014 年）</a>提出的门控循环单元（GRU ）。它将遗忘门和输入门合并为一个“更新门”。它还合并了单元状态和隐藏状态，并做了一些其他更改。由此产生的模型比标准 LSTM 模型更简单，而且越来越受欢迎。</p><p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-GRU.png" alt="门控循环单元神经网络。"></p><p>这些只是最值得注意的 LSTM 变体中的一小部分。还有很多其他的变体，例如<a href="http://arxiv.org/pdf/1508.03790v2.pdf">Yao 等人 (2015)</a>提出的深度门控 RNN 。还有一些完全不同的方法来解决长期依赖关系，例如<a href="http://arxiv.org/pdf/1402.3511v1.pdf">Koutnik 等人 (2014)</a>提出的 Clockwork RNN 。</p><p>这些变体中哪一个最好？差异重要吗？<a href="http://arxiv.org/pdf/1503.04069.pdf">Greff 等人（2015 年）</a>对流行的变体进行了很好的比较，发现它们都差不多。Jozefowicz<a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf">等人（2015 年）</a>测试了超过一万个 RNN 架构，发现有些架构在某些任务上比 LSTM 效果更好。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>之前，我提到了人们使用 RNN 取得的显著成果。基本上，所有这些都是使用 LSTM 实现的。它们在大多数任务上确实表现更好！</p><p>LSTM 写成一组方程式后，看起来相当吓人。希望本文一步步介绍它们能让你更容易理解。</p><p>LSTM 是我们利用 RNN 实现的一大进步。人们自然会想：还有另一大进步吗？研究人员的普遍看法是：“是的！还有下一步，那就是注意力！”这个想法是让 RNN 的每一步都从更大的信息集合中挑选信息来查看。例如，如果您使用 RNN 创建描述图像的标题，它可能会挑选图像的一部分来查看它输出的每个单词。事实上，<a href="http://arxiv.org/pdf/1502.03044v2.pdf">Xu<em>等人</em>(2015)</a>就是这么做的——如果您想探索注意力，这可能是一个有趣的起点！使用注意力已经取得了许多非常令人兴奋的成果，而且似乎还有更多的成果即将面世……</p><p>注意力并不是 RNN 研究中唯一令人兴奋的线索。例如，<a href="http://arxiv.org/pdf/1507.01526v1.pdf">Kalchbrenner<em>等人</em>(2015)</a>的网格 LSTM看起来非常有前景。在生成模型中使用 RNN 的工作 - 例如<a href="http://arxiv.org/pdf/1502.04623.pdf">Gregor<em>等人</em>(2015)</a>、<a href="http://arxiv.org/pdf/1506.02216v3.pdf">Chung<em>等人</em>(2015)</a>或<a href="http://arxiv.org/pdf/1411.7610v3.pdf">Bayer &amp; Osendorfer (2015)</a> - 也看起来非常有趣。过去几年对于循环神经网络来说是激动人心的几年，而未来的几年只会更加激动人心！</p><h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h2><p>我非常感谢许多人帮助我更好地理解 LSTM、对可视化效果发表评论并对这篇文章提供反馈。</p><p>我非常感谢 Google 的同事们提供的有益反馈，特别是<a href="http://research.google.com/pubs/OriolVinyals.html">Oriol Vinyals</a>、<a href="http://research.google.com/pubs/GregCorrado.html">Greg Corrado</a>、<a href="http://research.google.com/pubs/JonathonShlens.html">Jon Shlens</a>、<a href="http://people.cs.umass.edu/~luke/">Luke Vilnis</a>和<a href="http://www.cs.toronto.edu/~ilya/">Ilya Sutskever</a>。我还要感谢许多其他朋友和同事抽出时间帮助我，包括<a href="https://www.linkedin.com/pub/dario-amodei/4/493/393">Dario Amodei</a>和<a href="http://cs.stanford.edu/~jsteinhardt/">Jacob Steinhardt</a>。我特别感谢<a href="http://www.kyunghyuncho.me/">Kyunghyun Cho</a>对我的图表的极其周到的反馈。</p><p>在写这篇文章之前，我在两个关于神经网络的研讨会系列中练习解释 LSTM。感谢所有参加研讨会的人对我的耐心和反馈。</p><hr><h2 id=""><a href="#" class="headerlink" title=""></a></h2>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;转载 &lt;a href=&quot;https://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot;&gt;https://colah.github.io/posts/2015-08-Understanding-</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="深度学习" scheme="http://ai.mak.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
