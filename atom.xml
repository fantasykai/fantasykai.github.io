<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>枫哲&#39;s文栖小筑</title>
  
  <subtitle>君子终日乾乾，夕惕若厉，无咎</subtitle>
  <link href="http://ai.mak.cn/atom.xml" rel="self"/>
  
  <link href="http://ai.mak.cn/"/>
  <updated>2025-02-21T01:18:32.841Z</updated>
  <id>http://ai.mak.cn/</id>
  
  <author>
    <name>fantasykai</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>每日资讯</title>
    <link href="http://ai.mak.cn/posts/411b54c4/"/>
    <id>http://ai.mak.cn/posts/411b54c4/</id>
    <published>2025-02-20T16:00:00.000Z</published>
    <updated>2025-02-21T01:18:32.841Z</updated>
    
    <content type="html"><![CDATA[<hr><h1 id="2025年2月20日-AI与人工智能领域核心动态与深度解读"><a href="#2025年2月20日-AI与人工智能领域核心动态与深度解读" class="headerlink" title="2025年2月20日 AI与人工智能领域核心动态与深度解读"></a>2025年2月20日 AI与人工智能领域核心动态与深度解读</h1><hr><h2 id="一、国内AI领域核心进展"><a href="#一、国内AI领域核心进展" class="headerlink" title="一、国内AI领域核心进展"></a>一、国内AI领域核心进展</h2><h3 id="1-AI医疗赛道爆发：药物研发与政策利好共振"><a href="#1-AI医疗赛道爆发：药物研发与政策利好共振" class="headerlink" title="1. AI医疗赛道爆发：药物研发与政策利好共振"></a>1. <strong>AI医疗赛道爆发：药物研发与政策利好共振</strong></h3><p>港股医药股逆势大涨，歌礼制药-B因小分子口服GLP-1R激动剂ASC30临床试验取得突破，单日涨幅超36%。该药物在肥胖症治疗中展现出优于诺和诺德司美格鲁肽的给药便利性（每月一次皮下注射），结合国务院《2025年稳外资行动方案》对创新药加速上市的扶持政策，AI医疗商业化进程显著提速。<br><strong>深度解读</strong>：AI在药物研发中可将成本降低40%、周期缩短60%。目前已有超30家医疗企业接入DeepSeek技术，覆盖诊断、影像分析等领域。但需警惕临床试验后期风险及AI模型在医疗决策中的伦理争议，建议建立AI诊断结果双盲验证机制。</p><h3 id="2-阿里巴巴宣布AI战略升级：三年投入三大方向"><a href="#2-阿里巴巴宣布AI战略升级：三年投入三大方向" class="headerlink" title="2. 阿里巴巴宣布AI战略升级：三年投入三大方向"></a>2. <strong>阿里巴巴宣布AI战略升级：三年投入三大方向</strong></h3><p>阿里集团CEO吴泳铭明确未来三年将聚焦AI基础设施、基础模型平台及业务AI转型，重点突破边缘计算与多模态应用。此举呼应了高通白皮书中“终端侧推理”趋势，预计将加速AI在电商、云计算等场景的渗透。<br><strong>建议</strong>：关注阿里云与边缘芯片厂商（如地平线）协同效应，同时警惕大厂生态垄断对中小开发者的挤压。</p><h3 id="3-人形机器人产业化进程加速"><a href="#3-人形机器人产业化进程加速" class="headerlink" title="3. 人形机器人产业化进程加速"></a>3. <strong>人形机器人产业化进程加速</strong></h3><p>宇树科技G1机器人搭载“BeamDojo”强化学习框架，实现复杂地形稳定行走，股价单日上涨5.54%。公司预计2025年底人形机器人将突破消费级量产瓶颈，价格下探至三四千元区间，推动产业链上游精密零部件需求激增。<br><strong>投资方向</strong>：优先布局滚柱丝杠、力矩传感器等高壁垒环节，但需注意当前板块市盈率中位数达87倍的泡沫化风险。</p><hr><h2 id="二、国际AI前沿突破"><a href="#二、国际AI前沿突破" class="headerlink" title="二、国际AI前沿突破"></a>二、国际AI前沿突破</h2><h3 id="1-高通发布边缘推理白皮书：小模型时代来临"><a href="#1-高通发布边缘推理白皮书：小模型时代来临" class="headerlink" title="1. 高通发布边缘推理白皮书：小模型时代来临"></a>1. <strong>高通发布边缘推理白皮书：小模型时代来临</strong></h3><p>高通深度解读DeepSeek-R1模型，指出AI发展正从“规模竞赛”转向“能效优化”。该模型通过蒸馏技术实现百亿参数级别的终端部署，搭载骁龙平台的设备已可运行完整推理流程，标志着边缘计算进入实用阶段。<br><strong>趋势预判</strong>：2025年终端侧AI市场规模或突破2000亿美元，关注轻量化模型开发工具链（如TensorFlow Lite）及低功耗芯片设计。</p><h3 id="2-生成式AI重塑文娱产业工作流"><a href="#2-生成式AI重塑文娱产业工作流" class="headerlink" title="2. 生成式AI重塑文娱产业工作流"></a>2. <strong>生成式AI重塑文娱产业工作流</strong></h3><p>腾讯《2025年GenAI趋势报告》显示，影视、游戏行业已形成完整AI工作流：  </p><ul><li><strong>影视制作</strong>：从剧本生成（DeepSeek）到特效渲染（Sora），全流程效率提升50%  </li><li><strong>游戏开发</strong>：角色设计（Midjourney）、程序生成（Cursor）实现低成本高迭代<br><strong>风险提示</strong>：AI生成内容存在“幻想”问题（如逻辑矛盾、事实错误），需建立内容真实性审核体系。</li></ul><hr><h2 id="三、技术趋势与产业变革"><a href="#三、技术趋势与产业变革" class="headerlink" title="三、技术趋势与产业变革"></a>三、技术趋势与产业变革</h2><h3 id="1-终端智能化浪潮：从穿戴设备到空间计算"><a href="#1-终端智能化浪潮：从穿戴设备到空间计算" class="headerlink" title="1. 终端智能化浪潮：从穿戴设备到空间计算"></a>1. <strong>终端智能化浪潮：从穿戴设备到空间计算</strong></h3><ul><li><strong>AI眼镜</strong>：RayBan-Meta Wayfarer通过中国信通院7大模块测试，Micro LED技术推动轻量化落地，Rokid Glasses将于Q2开售  </li><li><strong>机器人感知</strong>：多模态大模型提升环境交互能力，宇树G1已实现动态负载平衡<br><strong>商业机遇</strong>：2025年AI穿戴设备出货量预计突破1.2亿台，关注光学模组与语音交互技术供应商。</li></ul><h3 id="2-AI伦理治理进入深水区"><a href="#2-AI伦理治理进入深水区" class="headerlink" title="2. AI伦理治理进入深水区"></a>2. <strong>AI伦理治理进入深水区</strong></h3><p>瑞士拟推数字平台法，要求社交媒体披露内容推荐算法逻辑，并建立AI生成内容标记体系。此举可能影响全球平台运营策略，推动“可解释AI”技术发展。<br><strong>企业应对</strong>：建议提前布局透明化AI系统，例如采用香港大学提出的“白盒大模型”架构。</p><hr><h2 id="四、投资策略与风险预警"><a href="#四、投资策略与风险预警" class="headerlink" title="四、投资策略与风险预警"></a>四、投资策略与风险预警</h2><h3 id="1-短期焦点（1-2年）"><a href="#1-短期焦点（1-2年）" class="headerlink" title="1. 短期焦点（1-2年）"></a>1. <strong>短期焦点（1-2年）</strong></h3><ul><li><strong>算力基建</strong>：液冷技术（海南海底数据中心节能40%）与国产GPU（寒武纪）  </li><li><strong>医疗AI</strong>：聚焦辅助诊断（医学影像分析）与药物研发（AI分子筛选）</li></ul><h3 id="2-长期布局（3-5年）"><a href="#2-长期布局（3-5年）" class="headerlink" title="2. 长期布局（3-5年）"></a>2. <strong>长期布局（3-5年）</strong></h3><ul><li><strong>人机交互</strong>：脑机接口与情感计算（参考Meta智能眼镜多模态交互）  </li><li><strong>量子AI融合</strong>：微软Majorana芯片推动算法革命，但需防范量子加密对传统安全体系的冲击</li></ul><h3 id="3-风险警示"><a href="#3-风险警示" class="headerlink" title="3. 风险警示"></a>3. <strong>风险警示</strong></h3><ul><li><strong>技术悬崖</strong>：过度依赖开源模型的企业面临中美技术脱钩风险  </li><li><strong>伦理争议</strong>：司法AI量刑建议可能引发公众对算法公正性质疑  </li><li><strong>资本泡沫</strong>：机器人概念股市盈率中位数达87倍，远超硬件制造合理区间</li></ul><hr><h3 id="扩展阅读"><a href="#扩展阅读" class="headerlink" title="扩展阅读"></a>扩展阅读</h3><ul><li><a href="https://example.com/">高通《AI变革与终端推理》白皮书全文</a>  </li><li>《人形机器人产业链核心技术图谱》电子版</li></ul><hr><p><strong>结语</strong><br>2025年的AI产业呈现“冰与火之歌”：一方面，终端智能化与垂直应用爆发推动效率革命；另一方面，伦理治理与资本过热构成潜在风险。从业者需以“技术锚定场景，创新匹配合规”为原则，在智能化的浪潮中把握确定性机遇。未来一个月，AI医疗审批加速与人形机器人量产进展或成市场核心催化剂。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;hr&gt;
&lt;h1 id=&quot;2025年2月20日-AI与人工智能领域核心动态与深度解读&quot;&gt;&lt;a href=&quot;#2025年2月20日-AI与人工智能领域核心动态与深度解读&quot; class=&quot;headerlink&quot; title=&quot;2025年2月20日 AI与人工智能领域核心动态与深度解读</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="人工智能, 技术趋势, 行业动态" scheme="http://ai.mak.cn/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-%E6%8A%80%E6%9C%AF%E8%B6%8B%E5%8A%BF-%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>每日资讯</title>
    <link href="http://ai.mak.cn/posts/42f55511/"/>
    <id>http://ai.mak.cn/posts/42f55511/</id>
    <published>2025-02-19T16:00:00.000Z</published>
    <updated>2025-02-20T01:39:58.147Z</updated>
    
    <content type="html"><![CDATA[<h1 id="2025年2月19日-AI与人工智能领域动态深度解读"><a href="#2025年2月19日-AI与人工智能领域动态深度解读" class="headerlink" title="2025年2月19日 AI与人工智能领域动态深度解读"></a>2025年2月19日 AI与人工智能领域动态深度解读</h1><hr><h2 id="一、国内AI核心进展"><a href="#一、国内AI核心进展" class="headerlink" title="一、国内AI核心进展"></a>一、国内AI核心进展</h2><h3 id="1-司法系统引入DeepSeek：AI助力法律决策效率革命"><a href="#1-司法系统引入DeepSeek：AI助力法律决策效率革命" class="headerlink" title="1. 司法系统引入DeepSeek：AI助力法律决策效率革命"></a>1. <strong>司法系统引入DeepSeek：AI助力法律决策效率革命</strong></h3><p>广东省湛江市司法局率先部署DeepSeek大模型，实现行政复议案件自动分类准确率92%，案件分流效率提升300%，并生成刑期与罚金区间参考。山东滨州、天津静海等地检察院亦接入该系统，用于法律文书生成、证据审查等场景。<br><strong>点评</strong>：AI在司法领域的渗透标志着从“辅助工具”向“决策参与者”转变。需警惕算法偏见对司法公正的影响，建议建立AI决策追溯机制和伦理审查框架。</p><h3 id="2-“AI员工”规模化落地，政务与企业效率双提升"><a href="#2-“AI员工”规模化落地，政务与企业效率双提升" class="headerlink" title="2. “AI员工”规模化落地，政务与企业效率双提升"></a>2. <strong>“AI员工”规模化落地，政务与企业效率双提升</strong></h3><p>深圳福田区上线70个AI数智员工，覆盖240个政务场景；中石化“数字员工”实现油价播报与旅游咨询一体化服务；小鹏汽车Iron机器人参与生产线实训，目标替代30%重复性岗位。<br><strong>建议</strong>：企业应优先在标准化流程（如客服、质检）部署AI员工，同时加强人机协作培训，避免技术性失业引发社会矛盾。</p><h3 id="3-医疗AI突破：全国首个罕见病大模型上线"><a href="#3-医疗AI突破：全国首个罕见病大模型上线" class="headerlink" title="3. 医疗AI突破：全国首个罕见病大模型上线"></a>3. <strong>医疗AI突破：全国首个罕见病大模型上线</strong></h3><p>北京协和医院联合中科院发布“协和·太初”模型，基于极小样本冷启动技术，可快速识别雷特综合征等罕见病，初诊咨询响应时间仅数秒。该模型未来将接入全国罕见病诊疗协作网，推动基层医疗能力升级。<br><strong>意义</strong>：解决了罕见病数据稀缺难题，但需防范模型过度依赖导致医生临床经验退化，建议建立AI诊断结果双盲验证机制。</p><h3 id="4-人形机器人量产进程加速，产业链上游受益"><a href="#4-人形机器人量产进程加速，产业链上游受益" class="headerlink" title="4. 人形机器人量产进程加速，产业链上游受益"></a>4. <strong>人形机器人量产进程加速，产业链上游受益</strong></h3><p>宇树科技发布新一代机器人舞蹈视频，动作抗干扰能力显著提升；券商预测2025年为人形机器人量产元年，滚柱丝杠、传感器等核心零部件需求激增，国内产能缺口达60%。<br><strong>投资方向</strong>：关注精密制造企业（如长盛轴承机器人关节部件业务）及国产替代标的（如双环传动谐波减速器），警惕概念股泡沫化风险。</p><hr><h2 id="二、国际AI前沿动态"><a href="#二、国际AI前沿动态" class="headerlink" title="二、国际AI前沿动态"></a>二、国际AI前沿动态</h2><h3 id="1-量子计算-AI：微软发布Majorana-1芯片"><a href="#1-量子计算-AI：微软发布Majorana-1芯片" class="headerlink" title="1. 量子计算+AI：微软发布Majorana 1芯片"></a>1. <strong>量子计算+AI：微软发布Majorana 1芯片</strong></h3><p>微软推出集成8量子比特的Majorana 1芯片，目标实现百万级量子比特，同步发布生成式AI工具Muse，可基于Xbox玩家数据自动生成游戏场景，加速娱乐产业内容生产。<br><strong>趋势解读</strong>：量子计算与AI的融合将突破传统算力瓶颈，但需关注量子加密技术对现有数据安全体系的冲击。</p><h3 id="2-韩国启动全球最大AI数据中心建设"><a href="#2-韩国启动全球最大AI数据中心建设" class="headerlink" title="2. 韩国启动全球最大AI数据中心建设"></a>2. <strong>韩国启动全球最大AI数据中心建设</strong></h3><p>韩国拟建3千兆瓦级AI数据中心，规模为当前最大数据中心的3倍，总投资350亿美元，由LG系资本主导。该项目将支撑东亚地区AI算力需求，加剧全球算力资源争夺。<br><strong>影响</strong>：可能重塑全球AI算力格局，中国需加速液冷技术（如海南海底智算中心节能方案）研发以应对能耗挑战。</p><h3 id="3-特斯拉人形机器人量产倒计时"><a href="#3-特斯拉人形机器人量产倒计时" class="headerlink" title="3. 特斯拉人形机器人量产倒计时"></a>3. <strong>特斯拉人形机器人量产倒计时</strong></h3><p>马斯克透露Optimus机器人将于2025年底前实现规模化量产，2026年进入服务业和工业场景。供应链消息称，特斯拉已锁定10万台伺服电机订单，国产供应商占比超40%。<br><strong>风险提示</strong>：家用场景安全性标准尚未统一，可能延缓消费级产品落地进度。</p><hr><h2 id="三、技术趋势与产业洞察"><a href="#三、技术趋势与产业洞察" class="headerlink" title="三、技术趋势与产业洞察"></a>三、技术趋势与产业洞察</h2><h3 id="1-算力“绿色化-边缘化”并行突破"><a href="#1-算力“绿色化-边缘化”并行突破" class="headerlink" title="1. 算力“绿色化+边缘化”并行突破"></a>1. <strong>算力“绿色化+边缘化”并行突破</strong></h3><ul><li><strong>绿色算力</strong>：中国智能算力规模2025年将达1037.3 EFLOPS，液冷服务器市场年复合增长率48.3%，海南海底数据中心能耗降低40%。  </li><li><strong>边缘计算</strong>：手机端百亿参数模型压缩技术成熟，阿里启动数百个端侧AI岗位招聘，聚焦多模态与Agent技术。<br><strong>建议</strong>：投资者可关注液冷技术供应商（如英维克）和端侧芯片企业（如地平线）。</li></ul><h3 id="2-AI伦理治理进入实操阶段"><a href="#2-AI伦理治理进入实操阶段" class="headerlink" title="2. AI伦理治理进入实操阶段"></a>2. <strong>AI伦理治理进入实操阶段</strong></h3><p>最高法发布企业名誉权保护案例，规范AI舆情管理；MIT研究建议建立职业转型基金应对39%岗位自动化风险。<br><strong>行动路径</strong>：企业需完善AI应用伦理审查流程，政府应探索UBI（全民基本收入）试点缓解就业冲击。</p><hr><h2 id="四、深度点评与策略建议"><a href="#四、深度点评与策略建议" class="headerlink" title="四、深度点评与策略建议"></a>四、深度点评与策略建议</h2><h3 id="1-产业机遇三维度"><a href="#1-产业机遇三维度" class="headerlink" title="1. 产业机遇三维度"></a>1. <strong>产业机遇三维度</strong></h3><ul><li><strong>硬件革新</strong>：人形机器人丝杠、传感器赛道将复制新能源车产业链爆发逻辑，关注技术壁垒高、国产替代空间大的环节。  </li><li><strong>垂直应用</strong>：医疗、司法、政务等强规则领域适合率先落地，需构建“行业知识库+轻量化模型”组合拳。  </li><li><strong>算力服务</strong>：智算中心租赁、合成数据平台等新兴商业模式潜力巨大，但需警惕过度投资导致的产能过剩。</li></ul><h3 id="2-风险预警与应对"><a href="#2-风险预警与应对" class="headerlink" title="2. 风险预警与应对"></a>2. <strong>风险预警与应对</strong></h3><ul><li><strong>技术悬崖</strong>：部分企业依赖开源模型却缺乏自主迭代能力，可能在中美技术脱钩背景下遭遇断供风险。  </li><li><strong>伦理黑洞</strong>：司法AI的刑期建议若未设置人工复核机制，可能引发量刑标准化与个案公正的冲突。  </li><li><strong>资本泡沫</strong>：机器人概念股市盈率中位数已达87倍，远超硬件制造业合理区间，需警惕估值回调。</li></ul><h3 id="3-投资策略矩阵"><a href="#3-投资策略矩阵" class="headerlink" title="3. 投资策略矩阵"></a>3. <strong>投资策略矩阵</strong></h3><table><thead><tr><th>周期</th><th>重点领域</th><th>代表标的</th><th>风险系数</th></tr></thead><tbody><tr><td>短期（1年）</td><td>算力基建&#x2F;精密零部件</td><td>中科曙光、双环传动</td><td>★★★☆☆</td></tr><tr><td>中期（3年）</td><td>垂类AI应用&#x2F;边缘计算</td><td>恒生电子、寒武纪</td><td>★★★★☆</td></tr><tr><td>长期（5年）</td><td>量子AI融合&#x2F;通用机器人</td><td>科大国盾、优必选</td><td>★★★★★</td></tr></tbody></table><hr><ul><li><strong>扩展阅读</strong>：  <ul><li><a href="https://deepseek.com/legal_ai">DeepSeek司法应用白皮书</a>  </li><li>《人形机器人产业链投资图谱2025》</li></ul></li></ul><hr><p><strong>结语</strong><br>2025年AI产业呈现“冰火两重天”态势：一方面，技术落地速度超预期，司法、医疗、制造等领域产生实质性效率革命；另一方面，伦理争议与资本泡沫化风险持续累积。建议从业者以“技术锚定场景，创新匹配伦理”为原则，在智能革命的浪潮中把握确定性机遇。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;2025年2月19日-AI与人工智能领域动态深度解读&quot;&gt;&lt;a href=&quot;#2025年2月19日-AI与人工智能领域动态深度解读&quot; class=&quot;headerlink&quot; title=&quot;2025年2月19日 AI与人工智能领域动态深度解读&quot;&gt;&lt;/a&gt;2025年2月1</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="人工智能, 技术趋势, 行业动态" scheme="http://ai.mak.cn/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-%E6%8A%80%E6%9C%AF%E8%B6%8B%E5%8A%BF-%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>每日资讯</title>
    <link href="http://ai.mak.cn/posts/63200/"/>
    <id>http://ai.mak.cn/posts/63200/</id>
    <published>2025-02-18T16:00:00.000Z</published>
    <updated>2025-02-19T01:11:30.152Z</updated>
    
    <content type="html"><![CDATA[<h1 id="2025年2月18日-AI领域动态与深度洞察"><a href="#2025年2月18日-AI领域动态与深度洞察" class="headerlink" title="2025年2月18日 AI领域动态与深度洞察"></a>2025年2月18日 AI领域动态与深度洞察</h1><h2 id="一、国际AI前沿速递"><a href="#一、国际AI前沿速递" class="headerlink" title="一、国际AI前沿速递"></a>一、国际AI前沿速递</h2><h3 id="1-马斯克发布Grok-3，训练成本创纪录"><a href="#1-马斯克发布Grok-3，训练成本创纪录" class="headerlink" title="1. 马斯克发布Grok 3，训练成本创纪录"></a>1. <strong>马斯克发布Grok 3，训练成本创纪录</strong></h3><p>马斯克旗下xAI公司正式推出新一代大模型Grok 3，宣称其“具备令人不安的创造力”。该模型训练消耗了20万块英伟达GPU，创下AI训练资源投入的新高。同期，OpenAI计划推出开源项目，探索手机端优化的轻量级模型，进一步降低AI应用门槛。<br><strong>点评</strong>：算力军备竞赛持续升级，但训练成本的陡增可能加剧行业垄断。开源策略或成破局关键，但需警惕技术伦理风险。</p><h3 id="2-欧洲AI差异化竞争"><a href="#2-欧洲AI差异化竞争" class="headerlink" title="2. 欧洲AI差异化竞争"></a>2. <strong>欧洲AI差异化竞争</strong></h3><p>法国公司Mistral发布专精阿拉伯语的AI大模型，避开与DeepSeek、谷歌的通用模型竞争，聚焦垂类市场。此举呼应了全球AI应用从“大而全”转向“小而精”的趋势。<br><strong>建议</strong>：垂类模型开发需结合本地化需求，如语言、文化适配，可参考Mistral路径。</p><h3 id="3-医疗AI突破"><a href="#3-医疗AI突破" class="headerlink" title="3. 医疗AI突破"></a>3. <strong>医疗AI突破</strong></h3><p>美国医疗科技公司Innovaccer推出AI健康智能体，帮助医生处理低价值重复工作，预计提升诊疗效率30%。<br><strong>意义</strong>：AI在医疗场景的渗透从辅助诊断向流程优化深化，但数据隐私和责任界定仍需政策配套。</p><hr><h2 id="二、国内AI核心进展"><a href="#二、国内AI核心进展" class="headerlink" title="二、国内AI核心进展"></a>二、国内AI核心进展</h2><h3 id="1-DeepSeek生态持续扩张"><a href="#1-DeepSeek生态持续扩张" class="headerlink" title="1. DeepSeek生态持续扩张"></a>1. <strong>DeepSeek生态持续扩张</strong></h3><ul><li><strong>资本层面</strong>：DeepSeek技术突破推动外资加速流入中国AI资产，对冲基金近一月增持速度创年内新高。  </li><li><strong>应用场景</strong>：网易云音乐接入DeepSeek-R1模型，优化音乐播客生成工具；香港创新科技局确认DeepSeek在港子公司成立，助力本地语言模型研发。<br><strong>趋势</strong>：国产大模型通过“开源+场景适配”构建生态护城河，但需警惕过度依赖单一厂商的生态风险。</li></ul><h3 id="2-算力基建新突破"><a href="#2-算力基建新突破" class="headerlink" title="2. 算力基建新突破"></a>2. <strong>算力基建新突破</strong></h3><p>海南海底智算中心集群启用，单秒支持7000次智能会话，采用海底数据中心节能技术，能耗降低40%。<br><strong>解读</strong>：边缘计算与绿色算力结合，为AI大规模落地提供基础设施保障，可关注液冷、模块化数据中心技术。</p><h3 id="3-行业动态"><a href="#3-行业动态" class="headerlink" title="3. 行业动态"></a>3. <strong>行业动态</strong></h3><ul><li>月之暗面（Kimi）因DeepSeek竞争压力，暂缓市场投放，转向技术优化。  </li><li>比亚迪王传福称中国新能源汽车技术领先3-5年，AI与汽车智能化融合或成下一增长极。</li></ul><hr><h2 id="三、技术趋势与争议"><a href="#三、技术趋势与争议" class="headerlink" title="三、技术趋势与争议"></a>三、技术趋势与争议</h2><h3 id="1-垂类应用爆发"><a href="#1-垂类应用爆发" class="headerlink" title="1. 垂类应用爆发"></a>1. <strong>垂类应用爆发</strong></h3><p>2025年被视为“AI应用落地元年”，市场规模预计从2024年51亿美元增至2030年471亿美元。全球科技巨头计划投资超3200亿美元，同比增长40%，但资本从算力硬件转向应用层趋势明显。<br><strong>案例</strong>：阿里Qwen2.5-Max在编程、数学能力领跑国内榜单；百度Comate已编写内部1&#x2F;4代码。</p><h3 id="2-模型架构革新"><a href="#2-模型架构革新" class="headerlink" title="2. 模型架构革新"></a>2. <strong>模型架构革新</strong></h3><ul><li><strong>白盒模型</strong>：香港大学马毅团队提出可解释的“白盒大模型”，通过清晰框架设计降低试错成本，试图突破数据与算力瓶颈。  </li><li><strong>密度定律</strong>：清华团队发现模型能力密度每100天翻倍，预示终端设备未来可运行更高效模型。<br><strong>挑战</strong>：当前大模型演绎能力随规模扩大反降，需探索新架构突破Scaling Law天花板。</li></ul><hr><h2 id="四、政策与资本动向"><a href="#四、政策与资本动向" class="headerlink" title="四、政策与资本动向"></a>四、政策与资本动向</h2><h3 id="1-政策支持"><a href="#1-政策支持" class="headerlink" title="1. 政策支持"></a>1. <strong>政策支持</strong></h3><ul><li>国家发改委明确支持民营企业参与“两重两新”（重大工程、重点项目；新基建、新型城镇化），优化AI产业准入环境。  </li><li>最高法发布企业名誉权保护案例，规范AI时代的舆情管理。</li></ul><h3 id="2-投资风向"><a href="#2-投资风向" class="headerlink" title="2. 投资风向"></a>2. <strong>投资风向</strong></h3><ul><li><strong>短期</strong>：算力基建仍受关注，中科曙光、浪潮信息等因DeepSeek合作股价走强。  </li><li><strong>长期</strong>：AI编程（年复合增长38%）、多模态应用（如书生万象2.5突破MMMU测试70%）、终端智能（2025年AI手机出货量预计1.18亿部）成焦点。</li></ul><hr><h2 id="五、深度思考与建议"><a href="#五、深度思考与建议" class="headerlink" title="五、深度思考与建议"></a>五、深度思考与建议</h2><h3 id="1-技术路线选择"><a href="#1-技术路线选择" class="headerlink" title="1. 技术路线选择"></a>1. <strong>技术路线选择</strong></h3><ul><li><strong>垂类优先</strong>：企业应结合自身数据优势，深耕医疗、教育等垂直领域，避免与通用模型正面竞争。  </li><li><strong>能效优化</strong>：关注密度定律与终端适配技术，探索“小模型+高精度”路径，降低部署成本。</li></ul><h3 id="2-风险应对"><a href="#2-风险应对" class="headerlink" title="2. 风险应对"></a>2. <strong>风险应对</strong></h3><ul><li><strong>伦理治理</strong>：MIT研究指出39%岗位面临自动化风险，需建立职业转型基金与数据主权框架。  </li><li><strong>供应链安全</strong>：国产GPU替代加速，但需防范美国对量子计算等前沿技术的出口管制。</li></ul><h3 id="3-投资策略"><a href="#3-投资策略" class="headerlink" title="3. 投资策略"></a>3. <strong>投资策略</strong></h3><ul><li><strong>关注标的</strong>：AI编程（恒生电子）、多模态（拓尔思）、算力（寒武纪）。  </li><li><strong>规避领域</strong>：过度依赖开源生态且缺乏自主迭代能力的应用厂商。</li></ul><hr><p><strong>总结</strong><br>2025年AI行业呈现“三足鼎立”格局：<strong>国际巨头竞逐通用模型，国内厂商深耕垂类生态，新兴力量探索差异化创新</strong>。建议从业者把握“场景化、能效化、合规化”三大原则，在技术爆发与伦理约束间寻找平衡点。未来3个月，AI+政务、AI编程、多模态生成等领域或出现标志性突破。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;2025年2月18日-AI领域动态与深度洞察&quot;&gt;&lt;a href=&quot;#2025年2月18日-AI领域动态与深度洞察&quot; class=&quot;headerlink&quot; title=&quot;2025年2月18日 AI领域动态与深度洞察&quot;&gt;&lt;/a&gt;2025年2月18日 AI领域动态与深度</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="人工智能, 技术趋势, 行业动态" scheme="http://ai.mak.cn/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-%E6%8A%80%E6%9C%AF%E8%B6%8B%E5%8A%BF-%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>每日资讯</title>
    <link href="http://ai.mak.cn/posts/63199/"/>
    <id>http://ai.mak.cn/posts/63199/</id>
    <published>2025-02-17T16:00:00.000Z</published>
    <updated>2025-02-19T00:57:57.048Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="2025年2月17日-AI与人工智能领域动态速览"><a href="#2025年2月17日-AI与人工智能领域动态速览" class="headerlink" title="2025年2月17日 AI与人工智能领域动态速览"></a>2025年2月17日 AI与人工智能领域动态速览</h2><h3 id="一、国内AI领域核心进展"><a href="#一、国内AI领域核心进展" class="headerlink" title="一、国内AI领域核心进展"></a>一、国内AI领域核心进展</h3><ol><li><p><strong>DeepSeek大模型生态持续扩展</strong><br>国产大模型DeepSeek在政务、医疗、教育等领域快速落地。深圳市通过政务云向全市提供DeepSeek服务，龙岗区上线34个政务AI应用，福田区推出覆盖240个场景的AI数智员工；深圳大学附属华南医院利用DeepSeek实现实时诊断提示和医院管理优化。微信接入DeepSeek后，用户可通过“AI搜索”整合腾讯生态内容，推动商业化潜力释放。</p></li><li><p><strong>教育场景创新</strong><br>南宁市多所学校在开学典礼中融入AI元素，如机器人迎新、AI生成职业画像、无人机表演等。滨湖路小学通过仿生机器人设计项目激发学生创造力，东葛路小学利用AI工具生成未来职业画像，强化生涯教育。</p></li><li><p><strong>算力需求激增</strong><br>根据《2025年中国人工智能计算力发展评估报告》，中国智能算力规模预计2025年增长43%，达1037.3EFLOPS。DeepSeek推动的算法效率提升与场景扩展，加速数据中心和边缘算力建设，国产GPU需求迎来黄金发展期。</p></li></ol><hr><h3 id="二、国际AI前沿动态"><a href="#二、国际AI前沿动态" class="headerlink" title="二、国际AI前沿动态"></a>二、国际AI前沿动态</h3><ol><li><p><strong>大模型竞争白热化</strong>  </p><ul><li>特斯拉CEO马斯克宣布Grok 3将于2月18日发布，称其性能超越现有公开模型，甚至具备“令人不安的创造力”。</li><li>OpenAI计划未来几周推出GPT-4.5（代号Orion）和GPT-5，整合更复杂的技术（如o3框架），应用于ChatGPT及API平台。</li><li>谷歌Gemini 2.0全面开放，多模态能力进一步升级。</li></ul></li><li><p><strong>技术趋势与挑战</strong>  </p><ul><li><strong>合成数据</strong>成为大模型迭代关键，微软、Anthropic等公司通过生成数据降低成本并提升多样性。</li><li><strong>AI安全治理</strong>被多国重视，OpenAI、蚂蚁集团等提出安全框架，应对模型滥用与伦理风险。</li></ul></li></ol><hr><h3 id="三、政策与行业动向"><a href="#三、政策与行业动向" class="headerlink" title="三、政策与行业动向"></a>三、政策与行业动向</h3><ol><li><p><strong>“人工智能+消费”政策扶持</strong><br>国务院常务会议提出支持“人工智能+消费”，山东、安徽等省推动直播电商与AI融合，打造新型消费场景。商务部强调AI技术对消费升级的驱动作用，计划通过补贴和税收优惠激发市场活力。</p></li><li><p><strong>投资方向切换</strong><br>金鹰基金指出，AI投资主线正从算力硬件转向中下游应用。随着模型成本降低，AI应用渗透率加速提升，教育、医疗、政务等垂直领域成重点方向。</p></li></ol><hr><h3 id="四、深度点评与建议"><a href="#四、深度点评与建议" class="headerlink" title="四、深度点评与建议"></a>四、深度点评与建议</h3><ol><li><p><strong>技术突破与产业机遇</strong>  </p><ul><li><strong>应用端爆发条件成熟</strong>：DeepSeek的推理成本优化和开源策略降低了开发者门槛，结合微信等超级入口的流量优势，AI应用商业化闭环加速形成。</li><li><strong>算力“扩容+提效”并重</strong>：需关注国产算力链（如浪潮信息、华工科技）和边缘计算场景，应对高性能算力短缺问题。</li></ul></li><li><p><strong>风险与挑战</strong>  </p><ul><li><strong>数据安全与就业冲击</strong>：MIT讨论指出，AI普及可能引发数据所有权争议和39%岗位的自动化风险，需强化数据保护法规并探索职业转型路径。</li><li><strong>技术与社会鸿沟</strong>：制造业全流程智能化仍面临软硬件适配难题，需加强产学研合作，推动技术下沉。</li></ul></li><li><p><strong>投资建议</strong>  </p><ul><li><strong>短期关注算力基建</strong>：IDC预测2025年全球AI服务器市场规模达1587亿美元，国产GPU和光模块企业（如紫光股份、光迅科技）或受益。</li><li><strong>长期布局超级应用</strong>：生成式AI与终端设备结合（如Apple Intelligence）可能催生C端爆款，建议跟踪教育、医疗领域的场景创新。</li></ul></li></ol><hr><p><strong>总结</strong><br>2025年AI行业呈现“技术迭代加速、应用场景爆发、政策密集支持”的特征。国内以DeepSeek为核心的生态闭环初现，国际大厂则通过多模态和具身智能争夺技术高地。投资者需平衡短期算力需求与长期应用潜力，同时警惕伦理与就业风险。未来半年，AI+政务、AI+教育等领域的落地案例或成市场焦点。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;2025年2月17日-AI与人工智能领域动态速览&quot;&gt;&lt;a href=&quot;#2025年2月17日-AI与人工智能领域动态速览&quot; class=&quot;headerlink&quot; title=&quot;2025年2月17日 AI与人工智能领域动态速览&quot;&gt;&lt;/a&gt;2025年2月17</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="人工智能, 技术趋势, 行业动态" scheme="http://ai.mak.cn/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-%E6%8A%80%E6%9C%AF%E8%B6%8B%E5%8A%BF-%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>每日资讯</title>
    <link href="http://ai.mak.cn/posts/63198/"/>
    <id>http://ai.mak.cn/posts/63198/</id>
    <published>2025-02-16T16:00:00.000Z</published>
    <updated>2025-02-17T09:22:21.616Z</updated>
    
    <content type="html"><![CDATA[<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>2025年，人工智能领域继续快速发展，大模型、AI Agent、生成式AI等技术不断突破，应用场景持续扩展。本文将整理近期国内外AI领域的最新资讯，并给出精准点评和深入解读，帮助读者把握AI技术的最新趋势。</p><hr><h3 id="1-大模型（LLM）的持续进化"><a href="#1-大模型（LLM）的持续进化" class="headerlink" title="1. 大模型（LLM）的持续进化"></a>1. 大模型（LLM）的持续进化</h3><h4 id="资讯："><a href="#资讯：" class="headerlink" title="资讯："></a>资讯：</h4><ul><li><strong>OpenAI发布GPT-5</strong>：GPT-5在理解力、推理能力和多模态处理上进一步提升，尤其在医疗、法律等专业领域的表现接近人类专家。</li><li><strong>谷歌推出Gemini Ultra 2.0</strong>：Gemini Ultra 2.0在复杂任务处理和多轮对话中展现了更强的稳定性。</li></ul><h4 id="点评："><a href="#点评：" class="headerlink" title="点评："></a>点评：</h4><p>大模型的持续进化标志着AI在专业领域的应用潜力。然而，模型规模的扩大也带来了更高的计算成本和能源消耗。</p><h4 id="建议："><a href="#建议：" class="headerlink" title="建议："></a>建议：</h4><p>企业应关注大模型在垂直领域的应用，同时探索模型压缩和优化技术，以降低部署成本。</p><hr><h3 id="2-AI-Agent的崛起"><a href="#2-AI-Agent的崛起" class="headerlink" title="2. AI Agent的崛起"></a>2. AI Agent的崛起</h3><h4 id="资讯：-1"><a href="#资讯：-1" class="headerlink" title="资讯："></a>资讯：</h4><ul><li><strong>微软推出Copilot Pro 2.0</strong>：Copilot Pro 2.0能够自主完成复杂任务，如代码生成、文档撰写和数据分析。</li><li><strong>Anthropic发布Claude Assistant 2.0</strong>：Claude Assistant 2.0在任务规划和工具使用上表现出色，成为企业自动化的新选择。</li></ul><h4 id="点评：-1"><a href="#点评：-1" class="headerlink" title="点评："></a>点评：</h4><p>AI Agent从”被动回答问题”到”主动完成任务”的跨越，标志着AI应用进入新阶段。</p><h4 id="建议：-1"><a href="#建议：-1" class="headerlink" title="建议："></a>建议：</h4><p>企业可以尝试将AI Agent集成到工作流程中，提升效率，但需注意数据安全和隐私保护。</p><hr><h3 id="3-生成式AI的突破"><a href="#3-生成式AI的突破" class="headerlink" title="3. 生成式AI的突破"></a>3. 生成式AI的突破</h3><h4 id="资讯：-2"><a href="#资讯：-2" class="headerlink" title="资讯："></a>资讯：</h4><ul><li><strong>Stability AI发布Stable Video 2.0</strong>：Stable Video 2.0支持从文本生成高质量视频，为内容创作带来新可能。</li><li><strong>MidJourney V7上线</strong>：V7版本在图像生成的真实性和细节上大幅提升。</li></ul><h4 id="点评：-2"><a href="#点评：-2" class="headerlink" title="点评："></a>点评：</h4><p>生成式AI在创意领域的应用不断扩展，但版权和伦理问题仍需关注。</p><h4 id="建议：-2"><a href="#建议：-2" class="headerlink" title="建议："></a>建议：</h4><p>创作者可以利用生成式AI工具提升效率，但需确保内容的原创性和合法性。</p><hr><h3 id="4-国内AI动态"><a href="#4-国内AI动态" class="headerlink" title="4. 国内AI动态"></a>4. 国内AI动态</h3><h4 id="资讯：-3"><a href="#资讯：-3" class="headerlink" title="资讯："></a>资讯：</h4><ul><li><strong>百度发布文心一言5.0</strong>：文心一言5.0在中文理解和多轮对话中表现优异，成为国内大模型的代表。</li><li><strong>阿里云推出通义千问3.0</strong>：通义千问3.0在电商、金融等领域的应用效果显著。</li></ul><h4 id="点评：-3"><a href="#点评：-3" class="headerlink" title="点评："></a>点评：</h4><p>国内大模型在中文场景下的表现逐渐赶超国际水平，但生态建设和应用落地仍需加强。</p><h4 id="建议：-3"><a href="#建议：-3" class="headerlink" title="建议："></a>建议：</h4><p>国内企业应加大研发投入，同时推动大模型在更多行业的应用落地。</p><hr><h3 id="5-AI伦理与法规"><a href="#5-AI伦理与法规" class="headerlink" title="5. AI伦理与法规"></a>5. AI伦理与法规</h3><h4 id="资讯：-4"><a href="#资讯：-4" class="headerlink" title="资讯："></a>资讯：</h4><ul><li><strong>欧盟通过《AI法案》</strong>：该法案对高风险AI应用进行了严格限制，要求透明性和可解释性。</li><li><strong>中国发布《生成式AI管理办法》</strong>：明确生成式AI的内容安全责任，要求企业加强内容审核。</li></ul><h4 id="点评：-4"><a href="#点评：-4" class="headerlink" title="点评："></a>点评：</h4><p>AI伦理和法规的完善是技术健康发展的重要保障。</p><h4 id="建议：-4"><a href="#建议：-4" class="headerlink" title="建议："></a>建议：</h4><p>企业应关注相关法规，确保AI应用的合规性，同时积极参与行业标准的制定。</p><hr><h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>2025年，AI技术将继续快速发展，大模型、AI Agent和生成式AI等领域将迎来更多突破。企业应抓住机遇，探索AI在垂直领域的应用，同时关注伦理和法规，确保技术的负责任发展。</p><hr><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol><li><a href="https://openai.com/">OpenAI GPT-5 发布公告</a></li><li><a href="https://www.microsoft.com/">微软 Copilot Pro 2.0 介绍</a></li><li><a href="https://ec.europa.eu/">欧盟《AI法案》全文</a></li><li><a href="https://www.gov.cn/">中国《生成式AI管理办法》</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h3&gt;&lt;p&gt;2025年，人工智能领域继续快速发展，大模型、AI Agent、生成式AI等技术不断突破，应用场景持续扩展。本文将整理近期国内外AI领域的最</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="人工智能, 技术趋势, 行业动态" scheme="http://ai.mak.cn/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-%E6%8A%80%E6%9C%AF%E8%B6%8B%E5%8A%BF-%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>Deepseek 技术分析总结</title>
    <link href="http://ai.mak.cn/posts/55960/"/>
    <id>http://ai.mak.cn/posts/55960/</id>
    <published>2025-02-14T16:00:00.000Z</published>
    <updated>2025-02-17T09:12:46.163Z</updated>
    
    <content type="html"><![CDATA[<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>Deepseek 作为一种先进的 AI 技术，在数据处理、模式识别和决策优化方面展现了强大的能力。本文将深入分析 Deepseek 的技术特点，并探讨其在运营商网络运营和运维场景中的应用，为自智能力建设提供新思路。</p><hr><h3 id="1-Deepseek-技术分析"><a href="#1-Deepseek-技术分析" class="headerlink" title="1. Deepseek 技术分析"></a>1. Deepseek 技术分析</h3><h4 id="1-1-核心能力"><a href="#1-1-核心能力" class="headerlink" title="1.1 核心能力"></a>1.1 核心能力</h4><ul><li><strong>高效数据处理</strong>：Deepseek 能够快速处理海量数据，提取关键信息。</li><li><strong>智能模式识别</strong>：通过深度学习算法，Deepseek 可以识别复杂的数据模式，预测潜在问题。</li><li><strong>动态决策优化</strong>：基于实时数据，Deepseek 能够提供最优决策建议，提升运营效率。</li></ul><h4 id="1-2-技术优势"><a href="#1-2-技术优势" class="headerlink" title="1.2 技术优势"></a>1.2 技术优势</h4><ul><li><strong>实时性</strong>：Deepseek 支持实时数据处理和决策，适用于高动态的网络环境。</li><li><strong>可扩展性</strong>：Deepseek 的架构设计支持横向扩展，能够应对不断增长的数据量和计算需求。</li><li><strong>自适应性</strong>：Deepseek 能够根据环境变化自动调整模型参数，保持高效运行。</li></ul><hr><h3 id="2-运营商网络运营与运维的挑战"><a href="#2-运营商网络运营与运维的挑战" class="headerlink" title="2. 运营商网络运营与运维的挑战"></a>2. 运营商网络运营与运维的挑战</h3><h4 id="2-1-数据复杂性"><a href="#2-1-数据复杂性" class="headerlink" title="2.1 数据复杂性"></a>2.1 数据复杂性</h4><p>运营商网络产生的数据量巨大，且类型多样，传统方法难以高效处理。</p><h4 id="2-2-故障预测与诊断"><a href="#2-2-故障预测与诊断" class="headerlink" title="2.2 故障预测与诊断"></a>2.2 故障预测与诊断</h4><p>网络故障的预测和诊断需要高精度的模型和实时分析能力。</p><h4 id="2-3-资源优化"><a href="#2-3-资源优化" class="headerlink" title="2.3 资源优化"></a>2.3 资源优化</h4><p>网络资源的动态分配和优化是提升运营效率的关键。</p><hr><h3 id="3-Deepseek-在运营商网络中的应用"><a href="#3-Deepseek-在运营商网络中的应用" class="headerlink" title="3. Deepseek 在运营商网络中的应用"></a>3. Deepseek 在运营商网络中的应用</h3><h4 id="3-1-智能故障预测"><a href="#3-1-智能故障预测" class="headerlink" title="3.1 智能故障预测"></a>3.1 智能故障预测</h4><ul><li><strong>应用场景</strong>：利用 Deepseek 分析网络流量数据，预测潜在故障。</li><li><strong>具体方案</strong>：<ol><li><strong>数据采集</strong>：采集网络流量、设备状态、日志等数据。</li><li><strong>特征提取</strong>：使用 Deepseek 提取关键特征，如流量异常、设备负载、错误日志等。</li><li><strong>模型训练</strong>：基于历史故障数据，训练故障预测模型。</li><li><strong>实时监控</strong>：部署模型到生产环境，实时监控网络状态。</li><li><strong>预警机制</strong>：当模型检测到潜在故障时，自动触发预警并通知运维人员。</li></ol></li><li><strong>效果</strong>：提前预警，减少故障发生率和影响范围。</li></ul><h4 id="3-2-自动化运维"><a href="#3-2-自动化运维" class="headerlink" title="3.2 自动化运维"></a>3.2 自动化运维</h4><ul><li><strong>应用场景</strong>：通过 Deepseek 实现网络设备的自动化监控和维护。</li><li><strong>具体方案</strong>：<ol><li><strong>设备监控</strong>：利用 Deepseek 实时监控设备状态，如 CPU 使用率、内存占用、端口状态等。</li><li><strong>异常检测</strong>：通过深度学习算法识别设备异常行为，如性能下降、配置错误等。</li><li><strong>自动化修复</strong>：针对常见问题，制定自动化修复脚本，如重启设备、调整配置等。</li><li><strong>知识库构建</strong>：将运维经验转化为知识库，供 Deepseek 学习和参考。</li><li><strong>人机协同</strong>：对于复杂问题，Deepseek 提供建议，由运维人员决策执行。</li></ol></li><li><strong>效果</strong>：降低运维成本，提高运维效率。</li></ul><h4 id="3-3-动态资源优化"><a href="#3-3-动态资源优化" class="headerlink" title="3.3 动态资源优化"></a>3.3 动态资源优化</h4><ul><li><strong>应用场景</strong>：基于 Deepseek 的实时数据分析，动态调整网络资源分配。</li><li><strong>具体方案</strong>：<ol><li><strong>数据采集</strong>：采集网络流量、用户行为、服务质量等数据。</li><li><strong>需求预测</strong>：使用 Deepseek 预测网络资源需求，如带宽、计算资源等。</li><li><strong>资源分配</strong>：根据预测结果，动态调整资源分配策略，如负载均衡、流量调度等。</li><li><strong>性能优化</strong>：通过深度学习算法优化网络性能，如减少延迟、提高吞吐量等。</li><li><strong>效果评估</strong>：实时评估资源优化效果，持续改进模型。</li></ol></li><li><strong>效果</strong>：提升网络资源利用率，优化用户体验。</li></ul><h4 id="3-4-智能客户服务"><a href="#3-4-智能客户服务" class="headerlink" title="3.4 智能客户服务"></a>3.4 智能客户服务</h4><ul><li><strong>应用场景</strong>：利用 Deepseek 提供智能化的客户服务。</li><li><strong>具体方案</strong>：<ol><li><strong>智能问答</strong>：通过 Deepseek 构建智能问答系统，解答用户常见问题。</li><li><strong>故障诊断</strong>：用户反馈问题时，Deepseek 自动分析并定位故障原因。</li><li><strong>个性化推荐</strong>：根据用户需求，推荐合适的套餐或服务。</li><li><strong>情感分析</strong>：通过自然语言处理技术，分析用户情感，提供更人性化的服务。</li><li><strong>数据反馈</strong>：将用户反馈数据用于优化网络和服务。</li></ol></li><li><strong>效果</strong>：提升客户满意度，降低客服成本。</li></ul><h4 id="3-5-网络安全防护"><a href="#3-5-网络安全防护" class="headerlink" title="3.5 网络安全防护"></a>3.5 网络安全防护</h4><ul><li><strong>应用场景</strong>：利用 Deepseek 增强网络安全性。</li><li><strong>具体方案</strong>：<ol><li><strong>威胁检测</strong>：通过 Deepseek 分析网络流量，识别潜在威胁，如 DDoS 攻击、恶意软件等。</li><li><strong>行为分析</strong>：使用深度学习算法分析用户行为，检测异常活动。</li><li><strong>自动响应</strong>：当检测到威胁时，自动触发防护措施，如阻断流量、隔离设备等。</li><li><strong>安全预警</strong>：提前预警潜在安全风险，提供防护建议。</li><li><strong>持续学习</strong>：基于新威胁数据，持续优化安全模型。</li></ol></li><li><strong>效果</strong>：提升网络安全性，减少安全事件发生。</li></ul><h4 id="3-6-智能体构建与意图识别"><a href="#3-6-智能体构建与意图识别" class="headerlink" title="3.6 智能体构建与意图识别"></a>3.6 智能体构建与意图识别</h4><ul><li><strong>应用场景</strong>：通过 Deepseek 构建智能体，实现自然语言交互和任务自动化。</li><li><strong>具体方案</strong>：<ol><li><strong>智能体架构设计</strong>：<ul><li><strong>对话管理</strong>：设计对话流程，支持多轮交互。</li><li><strong>知识库集成</strong>：集成网络运维知识库，提供准确信息。</li><li><strong>API 集成</strong>：与网络管理系统、运维工具等 API 集成，实现任务自动化。</li></ul></li><li><strong>意图识别</strong>：<ul><li><strong>意图定义</strong>：明确用户可能的需求，如”查询网络状态”、”报告故障”、”优化资源”等。</li><li><strong>触发词设计</strong>：为每个意图设计触发词，如”网络状态”、”故障报告”、”资源优化”等。</li><li><strong>槽位填充</strong>：为每个意图设计槽位，如”设备名称”、”故障类型”、”优化目标”等。</li><li><strong>模型训练</strong>：基于历史对话数据，训练意图识别模型。</li></ul></li><li><strong>对话流程设计</strong>：<ul><li><strong>用户输入</strong>：用户通过自然语言表达需求。</li><li><strong>意图识别</strong>：Deepseek 识别用户意图并提取关键信息。</li><li><strong>任务执行</strong>：根据意图调用相应 API 或知识库，执行任务。</li><li><strong>结果反馈</strong>：将任务结果以自然语言形式反馈给用户。</li></ul></li><li><strong>持续优化</strong>：<ul><li><strong>数据收集</strong>：收集用户对话数据，用于模型优化。</li><li><strong>模型更新</strong>：定期更新意图识别模型，提高准确率。</li><li><strong>用户反馈</strong>：通过用户反馈改进对话流程和任务执行。</li></ul></li></ol></li><li><strong>效果</strong>：提升运维效率，改善用户体验。</li></ul><hr><h3 id="4-相关能力建设的思考"><a href="#4-相关能力建设的思考" class="headerlink" title="4. 相关能力建设的思考"></a>4. 相关能力建设的思考</h3><h4 id="4-1-方案落地的困难点"><a href="#4-1-方案落地的困难点" class="headerlink" title="4.1 方案落地的困难点"></a>4.1 方案落地的困难点</h4><ol><li><p><strong>数据质量与整合</strong>：</p><ul><li><strong>问题</strong>：运营商网络数据来源多样，数据质量参差不齐，整合难度大。</li><li><strong>建议</strong>：建立统一的数据治理平台，制定数据标准和清洗流程。</li></ul></li><li><p><strong>模型训练与优化</strong>：</p><ul><li><strong>问题</strong>：网络环境复杂，模型训练需要大量高质量数据，且模型优化周期长。</li><li><strong>建议</strong>：引入迁移学习和联邦学习技术，减少数据依赖，加速模型优化。</li></ul></li><li><p><strong>系统集成与兼容性</strong>：</p><ul><li><strong>问题</strong>：现有网络管理系统和运维工具与 Deepseek 的集成存在技术障碍。</li><li><strong>建议</strong>：采用微服务架构和标准化 API，提高系统兼容性。</li></ul></li><li><p><strong>人才与组织能力</strong>：</p><ul><li><strong>问题</strong>：缺乏既懂 AI 又懂网络运维的复合型人才，组织能力不足。</li><li><strong>建议</strong>：加强内部培训，引入外部专家，构建跨部门协作机制。</li></ul></li></ol><h4 id="4-2-能力建设的待突破点"><a href="#4-2-能力建设的待突破点" class="headerlink" title="4.2 能力建设的待突破点"></a>4.2 能力建设的待突破点</h4><ol><li><p><strong>实时性与稳定性</strong>：</p><ul><li><strong>问题</strong>：网络环境高动态，要求 Deepseek 具备实时处理能力和高稳定性。</li><li><strong>突破点</strong>：优化算法和架构，提升实时性和容错能力。</li></ul></li><li><p><strong>可解释性与可信度</strong>：</p><ul><li><strong>问题</strong>：Deepseek 的决策过程缺乏透明性，影响用户信任。</li><li><strong>突破点</strong>：引入可解释 AI 技术，提高模型的可解释性和可信度。</li></ul></li><li><p><strong>安全与隐私保护</strong>：</p><ul><li><strong>问题</strong>：网络数据涉及用户隐私和商业机密，安全风险高。</li><li><strong>突破点</strong>：采用加密计算和隐私保护技术，确保数据安全。</li></ul></li><li><p><strong>生态建设与标准化</strong>：</p><ul><li><strong>问题</strong>：AI 技术在网络运维中的应用缺乏统一标准和生态支持。</li><li><strong>突破点</strong>：推动行业标准制定，构建开放协同的生态体系。</li></ul></li></ol><h4 id="4-3-值得深度思考的点"><a href="#4-3-值得深度思考的点" class="headerlink" title="4.3 值得深度思考的点"></a>4.3 值得深度思考的点</h4><ol><li><p><strong>人机协同的边界</strong>：</p><ul><li><strong>思考</strong>：在自动化运维中，如何界定人机协同的边界，确保人类的主导作用？</li><li><strong>方向</strong>：探索人机协同的最佳实践，制定明确的角色分工和决策机制。</li></ul></li><li><p><strong>技术伦理与社会责任</strong>：</p><ul><li><strong>思考</strong>：AI 技术在网络运维中的应用可能带来哪些伦理和社会问题？</li><li><strong>方向</strong>：建立技术伦理框架，确保 AI 应用的负责任发展。</li></ul></li><li><p><strong>长期价值与短期收益</strong>：</p><ul><li><strong>思考</strong>：在能力建设中，如何平衡长期价值与短期收益？</li><li><strong>方向</strong>：制定分阶段实施计划，确保短期收益的同时，为长期发展奠定基础。</li></ul></li><li><p><strong>创新与风险控制</strong>：</p><ul><li><strong>思考</strong>：在推动技术创新的同时，如何有效控制风险？</li><li><strong>方向</strong>：建立风险管理机制，确保创新过程中的风险可控。</li></ul></li></ol><hr><h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>Deepseek 为运营商网络运营和运维带来了革命性的技术手段，但在方案落地和能力建设中仍面临诸多挑战。通过解决数据质量、模型优化、系统集成和人才建设等问题，突破实时性、可解释性、安全性和生态建设等瓶颈，运营商可以构建高效、智能的自智网络。同时，深入思考人机协同、技术伦理、长期价值和创新风险等问题，将有助于推动 AI 技术在网络运维中的可持续发展。</p><p>未来，随着技术的不断进步和生态的逐步完善，Deepseek 将在运营商网络中发挥更大的价值，助力实现网络运营的智能化、自动化和高效化。运营商应抓住这一机遇，积极布局 AI 技术，构建开放协同的生态体系，推动自智网络的全面发展，为用户提供更优质的网络服务。</p><hr><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol><li><a href="https://www.deepseek.com/">Deepseek 技术白皮书</a></li><li><a href="https://www.itu.int/">自智网络架构指南</a></li><li><a href="https://www.cisco.com/">运营商智能运维案例</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h3&gt;&lt;p&gt;Deepseek 作为一种先进的 AI 技术，在数据处理、模式识别和决策优化方面展现了强大的能力。本文将深入分析 Deepseek 的技术特</summary>
      
    
    
    
    <category term="AI, 网络运维" scheme="http://ai.mak.cn/categories/AI-%E7%BD%91%E7%BB%9C%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="Deepseek, 自智网络, 运营商, 网络运维" scheme="http://ai.mak.cn/tags/Deepseek-%E8%87%AA%E6%99%BA%E7%BD%91%E7%BB%9C-%E8%BF%90%E8%90%A5%E5%95%86-%E7%BD%91%E7%BB%9C%E8%BF%90%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>3月份马拉松计划</title>
    <link href="http://ai.mak.cn/posts/17232/"/>
    <id>http://ai.mak.cn/posts/17232/</id>
    <published>2025-01-29T16:00:00.000Z</published>
    <updated>2025-02-17T09:24:22.068Z</updated>
    
    <content type="html"><![CDATA[<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>2024年4月，我开始了跑步之旅，经过8个月的训练，总跑量达到了1700公里。12月，成功突破了300公里的月跑量，这一年，在11月的高淳马拉松中创造了1小时35分15秒的半马PB。然而，1月的止点跟腱炎让我不得不停跑一个月。3月新的赛季开始，想要计划在3月和4月的全马中突破3小时40分钟的大关，请deepseek训练计划和评估。</p><h3 id="当前状态评估"><a href="#当前状态评估" class="headerlink" title="当前状态评估"></a>当前状态评估</h3><ul><li><strong>身高&#x2F;体重</strong>：172cm &#x2F; 69kg</li><li><strong>跑量</strong>：2024年4-12月总跑量1700公里，12月跑量突破300公里</li><li><strong>半马PB</strong>：1小时35分15秒（11月3日高淳马拉松）</li><li><strong>LSD</strong>：12月完成2次3公里以上LSD（30公里和35公里）</li><li><strong>伤病</strong>：1月因止点跟腱炎停跑一个月，2月恢复跑步</li></ul><h3 id="全马目标评估"><a href="#全马目标评估" class="headerlink" title="全马目标评估"></a>全马目标评估</h3><p>根据我的半马PB（1小时35分15秒），使用跑力公式推算，全马目标时间约为3小时20分钟至3小时30分钟。然而，考虑到1月的伤病和停跑，3小时40分钟是一个合理且具有挑战性的目标。</p><h3 id="训练计划"><a href="#训练计划" class="headerlink" title="训练计划"></a>训练计划</h3><p>为了在3月和4月的全马中突破3小时40分钟，我制定了以下训练计划：</p><h4 id="1-基础期（2月）"><a href="#1-基础期（2月）" class="headerlink" title="1. 基础期（2月）"></a>1. 基础期（2月）</h4><ul><li><strong>目标</strong>：恢复体能，避免伤病</li><li><strong>周跑量</strong>：40-50公里</li><li><strong>训练内容</strong>：<ul><li>轻松跑（E pace）：80%的跑量</li><li>力量训练：每周2次，重点加强下肢和核心力量</li><li>拉伸和按摩：每天进行，预防伤病</li></ul></li></ul><h4 id="2-提升期（3月）"><a href="#2-提升期（3月）" class="headerlink" title="2. 提升期（3月）"></a>2. 提升期（3月）</h4><ul><li><strong>目标</strong>：提高有氧能力和速度</li><li><strong>周跑量</strong>：60-70公里</li><li><strong>训练内容</strong>：<ul><li>轻松跑（E pace）：60%的跑量</li><li>节奏跑（T pace）：每周1次，6-8公里</li><li>间歇跑（I pace）：每周1次，5x1公里</li><li>LSD：每周1次，25-30公里</li></ul></li></ul><h4 id="3-巅峰期（4月）"><a href="#3-巅峰期（4月）" class="headerlink" title="3. 巅峰期（4月）"></a>3. 巅峰期（4月）</h4><ul><li><strong>目标</strong>：调整状态，准备比赛</li><li><strong>周跑量</strong>：50-60公里</li><li><strong>训练内容</strong>：<ul><li>轻松跑（E pace）：70%的跑量</li><li>节奏跑（T pace）：每周1次，5-6公里</li><li>LSD：每周1次，20-25公里</li><li>减量：比赛前2周逐渐减少跑量，保持轻松跑和短距离节奏跑</li></ul></li></ul><h3 id="力量训练计划"><a href="#力量训练计划" class="headerlink" title="力量训练计划"></a>力量训练计划</h3><p>力量训练是预防伤病和提高跑步效率的关键。以下是我的力量训练计划：</p><h4 id="1-下肢力量训练"><a href="#1-下肢力量训练" class="headerlink" title="1. 下肢力量训练"></a>1. 下肢力量训练</h4><ul><li><strong>深蹲</strong>：3组，每组12次</li><li><strong>弓步蹲</strong>：3组，每组12次（每条腿）</li><li><strong>单腿硬拉</strong>：3组，每组12次（每条腿）</li><li><strong>小腿提踵</strong>：3组，每组15次</li></ul><h4 id="2-核心力量训练"><a href="#2-核心力量训练" class="headerlink" title="2. 核心力量训练"></a>2. 核心力量训练</h4><ul><li><strong>平板支撑</strong>：3组，每组保持60秒</li><li><strong>俄罗斯转体</strong>：3组，每组20次</li><li><strong>仰卧卷腹</strong>：3组，每组15次</li><li><strong>侧桥</strong>：3组，每组保持45秒（每侧）</li></ul><h4 id="3-灵活性训练"><a href="#3-灵活性训练" class="headerlink" title="3. 灵活性训练"></a>3. 灵活性训练</h4><ul><li><strong>动态拉伸</strong>：每次训练前进行10分钟</li><li><strong>静态拉伸</strong>：每次训练后进行15分钟</li><li><strong>泡沫轴放松</strong>：每周3次，重点放松大腿、小腿和臀部</li></ul><h3 id="比赛策略"><a href="#比赛策略" class="headerlink" title="比赛策略"></a>比赛策略</h3><ul><li><strong>配速</strong>：目标配速为5分12秒&#x2F;公里，前半程保持5分15秒&#x2F;公里，后半程根据状态调整</li><li><strong>补给</strong>：每5公里补充一次能量胶，每10公里补充一次电解质饮料</li><li><strong>心理</strong>：保持积极心态，合理分配体力，避免前半程过快</li></ul><p>通过科学的训练和合理的比赛策略，我有信心在3月和4月的全马中突破3小时40分钟的大关，希望我的经验能够帮助到同样在追求全马目标的跑友们。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol><li><a href="https://www.runningquotient.com/">跑力公式计算器</a></li><li><a href="https://www.halhigdon.com/">马拉松训练计划</a></li><li><a href="https://www.runnersworld.com/">跑步伤病预防</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h3&gt;&lt;p&gt;2024年4月，我开始了跑步之旅，经过8个月的训练，总跑量达到了1700公里。12月，成功突破了300公里的月跑量，这一年，在11月的高淳马</summary>
      
    
    
    
    <category term="跑步" scheme="http://ai.mak.cn/categories/%E8%B7%91%E6%AD%A5/"/>
    
    
    <category term="马拉松" scheme="http://ai.mak.cn/tags/%E9%A9%AC%E6%8B%89%E6%9D%BE/"/>
    
  </entry>
  
  <entry>
    <title>AI 智能体：学习路线与应用</title>
    <link href="http://ai.mak.cn/posts/8d6f7176/"/>
    <id>http://ai.mak.cn/posts/8d6f7176/</id>
    <published>2025-01-24T16:00:00.000Z</published>
    <updated>2025-02-21T08:45:27.715Z</updated>
    
    <content type="html"><![CDATA[<hr><h1 id="AI智能体技术全解析：学习路线、构建流程与应用实践"><a href="#AI智能体技术全解析：学习路线、构建流程与应用实践" class="headerlink" title="AI智能体技术全解析：学习路线、构建流程与应用实践"></a>AI智能体技术全解析：学习路线、构建流程与应用实践</h1><hr><h2 id="一、AI智能体技术全景图"><a href="#一、AI智能体技术全景图" class="headerlink" title="一、AI智能体技术全景图"></a>一、AI智能体技术全景图</h2><h3 id="1-AI智能体定义与层级架构"><a href="#1-AI智能体定义与层级架构" class="headerlink" title="1. AI智能体定义与层级架构"></a>1. AI智能体定义与层级架构</h3><p><strong>核心定义</strong>：具有感知-决策-行动闭环能力的自主系统，具备环境交互、持续学习和目标导向特性。<br><strong>技术层级</strong>：  </p><ul><li><strong>感知层</strong>：多模态输入处理（CV&#x2F;NLP&#x2F;传感器）  </li><li><strong>认知层</strong>：知识图谱&#x2F;记忆网络&#x2F;推理引擎  </li><li><strong>决策层</strong>：强化学习&#x2F;符号逻辑&#x2F;博弈策略  </li><li><strong>执行层</strong>：机器人控制&#x2F;API调用&#x2F;自然语言生成</li></ul><h3 id="2-技术发展脉络"><a href="#2-技术发展脉络" class="headerlink" title="2. 技术发展脉络"></a>2. 技术发展脉络</h3><table><thead><tr><th>阶段</th><th>技术特征</th><th>典型代表</th></tr></thead><tbody><tr><td>规则驱动</td><td>专家系统&#x2F;有限状态机</td><td>早期聊天机器人</td></tr><tr><td>数据驱动</td><td>深度学习+端到端训练</td><td>AlphaGo&#x2F;DALLE</td></tr><tr><td>认知驱动</td><td>世界模型+具身智能</td><td>Tesla Optimus&#x2F;Meta AI</td></tr><tr><td>社会智能</td><td>多智能体协作+价值对齐</td><td>Anthropic宪法AI</td></tr></tbody></table><hr><h2 id="二、AI智能体学习路线规划"><a href="#二、AI智能体学习路线规划" class="headerlink" title="二、AI智能体学习路线规划"></a>二、AI智能体学习路线规划</h2><h3 id="1-基础阶段"><a href="#1-基础阶段" class="headerlink" title="1. 基础阶段"></a>1. 基础阶段</h3><p><strong>知识储备</strong>：  </p><ul><li><strong>编程基础</strong>：Python（NumPy&#x2F;Pandas）、Rust（高性能场景）  </li><li><strong>数学基础</strong>：线性代数（张量运算）、概率论（贝叶斯网络）、最优化理论  </li><li><strong>工具链</strong>：Git&#x2F;GitHub、Linux基础、Docker容器化</li></ul><p><strong>推荐学习资源</strong>：  </p><ul><li>书籍：《Artificial Intelligence: A Modern Approach》  </li><li>课程：Stanford CS224N（NLP）、DeepMind x UCL RL系列  </li><li>实践：Kaggle基础竞赛（如Titanic）、OpenAI Gym环境</li></ul><h3 id="2-进阶阶段"><a href="#2-进阶阶段" class="headerlink" title="2. 进阶阶段"></a>2. 进阶阶段</h3><p><strong>核心技术栈</strong>：  </p><ul><li><strong>深度学习框架</strong>：PyTorch（动态图优势）、JAX（高性能计算）  </li><li><strong>智能体架构</strong>：  <ul><li><strong>反应式</strong>：基于规则的有限状态机（FSM）  </li><li><strong>认知式</strong>：BERT+知识图谱（医疗诊断场景）  </li><li><strong>混合式</strong>：LLM+RLHF（ChatGPT类系统）</li></ul></li></ul><p><strong>实践项目</strong>：  </p><ul><li>搭建客服对话系统（Rasa框架+意图识别）  </li><li>开发简易游戏AI（Unity ML-Agents）  </li><li>构建股票交易策略引擎（Q-Learning+市场数据）</li></ul><h3 id="3-高阶阶段"><a href="#3-高阶阶段" class="headerlink" title="3. 高阶阶段"></a>3. 高阶阶段</h3><p><strong>前沿方向</strong>：  </p><ul><li><strong>多模态融合</strong>：CLIP模型跨模态对齐  </li><li><strong>分布式训练</strong>：Ray框架实现参数服务器架构  </li><li><strong>具身智能</strong>：NVIDIA Isaac Sim物理仿真  </li><li><strong>伦理安全</strong>：Constitutional AI约束机制</li></ul><p><strong>研究热点</strong>：  </p><ul><li>世界模型构建（如DeepMind的Genie）  </li><li>小样本持续学习（Meta-Learning）  </li><li>多智能体博弈（博弈论+MARL）</li></ul><hr><h2 id="三、AI智能体构建流程详解"><a href="#三、AI智能体构建流程详解" class="headerlink" title="三、AI智能体构建流程详解"></a>三、AI智能体构建流程详解</h2><h3 id="1-需求分析与架构设计"><a href="#1-需求分析与架构设计" class="headerlink" title="1. 需求分析与架构设计"></a>1. 需求分析与架构设计</h3><p><strong>关键checklist</strong>：  </p><ul><li>任务类型：单任务&#x2F;多任务&#x2F;元任务  </li><li>环境复杂度：完全可观测&#x2F;部分可观测  </li><li>实时性要求：毫秒级（自动驾驶）&#x2F;分钟级（文档处理）</li></ul><p><strong>架构选择矩阵</strong>：  </p><table><thead><tr><th>场景</th><th>推荐架构</th><th>技术方案</th></tr></thead><tbody><tr><td>客服对话</td><td>LLM+知识库</td><td>LangChain+RAG</td></tr><tr><td>工业质检</td><td>CV+强化学习</td><td>YOLOv8+PPO</td></tr><tr><td>量化交易</td><td>时序预测+风险控制</td><td>LSTM+蒙特卡洛模拟</td></tr><tr><td>家庭服务机器人</td><td>多模态+运动控制</td><td>CLIP+ROS2</td></tr></tbody></table><h3 id="2-核心开发流程"><a href="#2-核心开发流程" class="headerlink" title="2. 核心开发流程"></a>2. 核心开发流程</h3><p><strong>五步构建法</strong>：  </p><ol><li><p><strong>数据工程</strong>  </p><ul><li>多源数据采集（API&#x2F;爬虫&#x2F;传感器）  </li><li>数据增强策略：GAN生成&#x2F;时空变换  </li><li>特征工程工具：TSFresh（时序数据）、OpenFE</li></ul></li><li><p><strong>模型开发</strong>  </p><ul><li>基线模型选择：  <ul><li>小样本场景：Few-Shot Learning（Prototypical Networks）  </li><li>高维状态空间：Transformer+Memory Networks</li></ul></li><li>训练技巧：课程学习（Curriculum Learning）、自监督预训练</li></ul></li><li><p><strong>仿真测试</strong>  </p><ul><li>虚拟环境搭建：  <ul><li>Web应用：Selenium+Playwright  </li><li>物理世界：NVIDIA Omniverse</li></ul></li><li>评估指标设计：  <ul><li>对话系统：BLEU-4 + 人工评分  </li><li>控制类智能体：收敛速度+稳态误差</li></ul></li></ul></li><li><p><strong>部署优化</strong>  </p><ul><li>模型压缩：  <ul><li>量化：FP32 → INT8（TensorRT）  </li><li>蒸馏：教师-学生模型（DistilBERT）</li></ul></li><li>边缘部署方案：  <ul><li>手机端：TFLite + CoreML  </li><li>嵌入式：ONNX Runtime + NCNN</li></ul></li></ul></li><li><p><strong>持续进化</strong>  </p><ul><li>在线学习：Bandit算法实时调参  </li><li>联邦学习：保护数据隐私  </li><li>可解释性：LIME&#x2F;SHAP分析决策路径</li></ul></li></ol><hr><h2 id="四、典型应用场景与技术方案"><a href="#四、典型应用场景与技术方案" class="headerlink" title="四、典型应用场景与技术方案"></a>四、典型应用场景与技术方案</h2><h3 id="1-行业应用案例库"><a href="#1-行业应用案例库" class="headerlink" title="1. 行业应用案例库"></a>1. 行业应用案例库</h3><table><thead><tr><th>领域</th><th>典型场景</th><th>技术方案</th><th>性能指标</th></tr></thead><tbody><tr><td><strong>医疗</strong></td><td>手术辅助机器人</td><td>3D视觉+力反馈控制（达芬奇系统）</td><td>操作精度±0.1mm</td></tr><tr><td><strong>金融</strong></td><td>智能投顾</td><td>组合优化+风险价值模型（VaR）</td><td>年化收益波动率&lt;15%</td></tr><tr><td><strong>制造</strong></td><td>柔性生产线调度</td><td>MARL+数字孪生</td><td>设备利用率提升30%</td></tr><tr><td><strong>教育</strong></td><td>个性化学习助手</td><td>认知诊断模型+BKT</td><td>知识点掌握预测准确率92%</td></tr></tbody></table><h3 id="2-开源项目推荐"><a href="#2-开源项目推荐" class="headerlink" title="2. 开源项目推荐"></a>2. 开源项目推荐</h3><ul><li><strong>AutoGPT</strong>：自主任务分解与执行  </li><li><strong>BabyAGI</strong>：基于LangChain的任务管理系统  </li><li><strong>Meta’s Habitat</strong>：具身智能仿真平台  </li><li><strong>DeepMind OpenSpiel</strong>：多智能体博弈研究框架</li></ul><hr><h2 id="五、技术选型指南"><a href="#五、技术选型指南" class="headerlink" title="五、技术选型指南"></a>五、技术选型指南</h2><h3 id="1-框架对比矩阵"><a href="#1-框架对比矩阵" class="headerlink" title="1. 框架对比矩阵"></a>1. 框架对比矩阵</h3><table><thead><tr><th>框架</th><th>适用场景</th><th>优势</th><th>局限性</th></tr></thead><tbody><tr><td><strong>LangChain</strong></td><td>知识密集型应用</td><td>灵活的知识库集成</td><td>推理延迟较高</td></tr><tr><td><strong>Ray</strong></td><td>分布式强化学习</td><td>支持千万级参数并行</td><td>学习曲线陡峭</td></tr><tr><td><strong>ROS2</strong></td><td>机器人控制</td><td>完善的传感器驱动生态</td><td>实时性依赖硬件</td></tr><tr><td><strong>AutoML</strong></td><td>快速原型开发</td><td>自动化超参优化</td><td>可解释性较差</td></tr></tbody></table><h3 id="2-硬件选型建议"><a href="#2-硬件选型建议" class="headerlink" title="2. 硬件选型建议"></a>2. 硬件选型建议</h3><ul><li><strong>云端训练</strong>：NVIDIA A100&#x2F;H100（混合精度训练）  </li><li><strong>边缘推理</strong>：Jetson Orin（32TOPS算力）  </li><li><strong>专用芯片</strong>：Graphcore IPU（稀疏计算优化）</li></ul><hr><p><strong>结语</strong><br>AI智能体正从实验室走向产业落地，开发者既需要掌握深度学习、强化学习等核心技术，也要深入理解垂直领域的业务逻辑。随着世界模型、具身智能等方向的突破，智能体将逐步具备人类水平的环境认知与复杂任务处理能力。建议持续关注AutoGPT等开源项目演进，在实践中构建可进化、可解释、可对齐的智能体系统。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;hr&gt;
&lt;h1 id=&quot;AI智能体技术全解析：学习路线、构建流程与应用实践&quot;&gt;&lt;a href=&quot;#AI智能体技术全解析：学习路线、构建流程与应用实践&quot; class=&quot;headerlink&quot; title=&quot;AI智能体技术全解析：学习路线、构建流程与应用实践&quot;&gt;&lt;/a&gt;AI智能体技</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="AI 智能体" scheme="http://ai.mak.cn/tags/AI-%E6%99%BA%E8%83%BD%E4%BD%93/"/>
    
  </entry>
  
  <entry>
    <title>2024年人工智能进展及展望</title>
    <link href="http://ai.mak.cn/posts/16164/"/>
    <id>http://ai.mak.cn/posts/16164/</id>
    <published>2024-12-30T16:00:00.000Z</published>
    <updated>2025-02-11T07:46:37.048Z</updated>
    
    <content type="html"><![CDATA[<h1 id="2024年人工智能进展及展望"><a href="#2024年人工智能进展及展望" class="headerlink" title="2024年人工智能进展及展望"></a>2024年人工智能进展及展望</h1><p>2024年是人工智能领域快速发展的一年，大模型、AI Agent、云原生AI等技术取得了显著突破。本文将从技术进展、行业应用和未来展望三个方面，回顾2024年AI领域的重要发展，并展望2025年的趋势。</p><h2 id="一、2024年人工智能技术进展"><a href="#一、2024年人工智能技术进展" class="headerlink" title="一、2024年人工智能技术进展"></a>一、2024年人工智能技术进展</h2><h3 id="1-大模型（LLM）的持续进化"><a href="#1-大模型（LLM）的持续进化" class="headerlink" title="1. 大模型（LLM）的持续进化"></a>1. 大模型（LLM）的持续进化</h3><p>2024年，大语言模型（LLM）在规模、能力和应用场景上都有了显著提升。GPT-4、Claude 3等模型在理解力、推理能力和多模态处理上取得了突破，尤其是在医疗、法律等专业领域的表现令人瞩目。 </p><h3 id="2-AI-Agent的崛起"><a href="#2-AI-Agent的崛起" class="headerlink" title="2. AI Agent的崛起"></a>2. AI Agent的崛起</h3><p>AI Agent成为2024年的热门话题，它通过结合大模型、任务规划和工具使用，实现了从”被动回答问题”到”主动完成任务”的跨越。AI Agent在个人助理、企业自动化等场景中展现了巨大潜力。</p><h3 id="3-云原生AI的普及"><a href="#3-云原生AI的普及" class="headerlink" title="3. 云原生AI的普及"></a>3. 云原生AI的普及</h3><p>云原生AI技术（CNAI）在2024年得到了广泛应用。通过容器化、微服务和Kubernetes等技术，AI应用的开发、部署和运维变得更加高效和灵活。Hugging Face、OpenAI等公司在这一领域取得了显著进展。</p><figure class="highlight plaintext"><figcaption><span>CNCF 推出的云原生 AI 白皮书.md</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">startLine: 1</span><br><span class="line">endLine: 30</span><br></pre></td></tr></table></figure><h2 id="二、2024年人工智能行业应用"><a href="#二、2024年人工智能行业应用" class="headerlink" title="二、2024年人工智能行业应用"></a>二、2024年人工智能行业应用</h2><h3 id="1-医疗领域"><a href="#1-医疗领域" class="headerlink" title="1. 医疗领域"></a>1. 医疗领域</h3><p>AI在医疗领域的应用取得了突破性进展。例如，谷歌的Med-PaLM模型在医师职业测试中达到了与人类医生相当的水平，为AI问诊和辅助诊断提供了新的可能性。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">startLine: 52</span><br><span class="line">endLine: 56</span><br></pre></td></tr></table></figure><h3 id="2-音乐与创意产业"><a href="#2-音乐与创意产业" class="headerlink" title="2. 音乐与创意产业"></a>2. 音乐与创意产业</h3><p>AI在音乐创作和艺术生成领域的应用也取得了显著进展。例如，Riffusion工具通过微调AI画图算法，实现了根据文本生成音乐的功能，展示了AI在创意领域的潜力。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">startLine: 44</span><br><span class="line">endLine: 50</span><br></pre></td></tr></table></figure><h3 id="3-企业数字化"><a href="#3-企业数字化" class="headerlink" title="3. 企业数字化"></a>3. 企业数字化</h3><p>AI在企业数字化中的应用进一步深化，尤其是在数据治理、智能决策和自动化流程方面。MaaS（Model as a Service）模式成为企业利用AI技术的重要方式。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">startLine: 1</span><br><span class="line">endLine: 10</span><br></pre></td></tr></table></figure><h2 id="三、2025年人工智能展望"><a href="#三、2025年人工智能展望" class="headerlink" title="三、2025年人工智能展望"></a>三、2025年人工智能展望</h2><h3 id="1-更强的自主性与智能化"><a href="#1-更强的自主性与智能化" class="headerlink" title="1. 更强的自主性与智能化"></a>1. 更强的自主性与智能化</h3><p>2025年，AI Agent将进一步提升自主性和智能化水平，能够在更多复杂场景中自主决策和执行任务。随着技术的进步，AI将更加贴近人类的行为模式。</p><h3 id="2-深度行业化与定制化"><a href="#2-深度行业化与定制化" class="headerlink" title="2. 深度行业化与定制化"></a>2. 深度行业化与定制化</h3><p>AI技术将进一步渗透到各个行业，尤其是在医疗、金融、制造等领域，定制化的AI解决方案将成为主流。行业化的AI模型和应用将更加成熟。</p><h3 id="3-伦理与法规的完善"><a href="#3-伦理与法规的完善" class="headerlink" title="3. 伦理与法规的完善"></a>3. 伦理与法规的完善</h3><p>随着AI技术的普及，隐私、安全和伦理问题将受到更多关注。2025年，相关法规和标准将逐步完善，确保AI技术的负责任发展。</p><h3 id="4-持续学习与自适应能力"><a href="#4-持续学习与自适应能力" class="headerlink" title="4. 持续学习与自适应能力"></a>4. 持续学习与自适应能力</h3><p>未来的AI系统将具备更强的持续学习和自适应能力，能够根据环境变化和新数据进行自我调整和优化，进一步提升智能水平。</p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>2024年，人工智能技术在多个领域取得了显著进展，尤其是在大模型、AI Agent和云原生AI方面。展望2025年，AI将继续向更智能化、行业化和伦理化的方向发展，成为推动社会进步的重要力量。我们期待AI技术在未来带来更多创新和突破，为人类生活和工作带来更多便利。</p><hr><p><strong>参考文献：</strong></p><ol><li><a href="https://example.com/ai-agent">AI Agent简述</a></li><li><a href="https://www.cncf.io/reports/cloud-native-artificial-intelligence-whitepaper/">云原生AI白皮书</a></li><li><a href="https://example.com/data-insight">2022年中国数智融合发展洞察</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;2024年人工智能进展及展望&quot;&gt;&lt;a href=&quot;#2024年人工智能进展及展望&quot; class=&quot;headerlink&quot; title=&quot;2024年人工智能进展及展望&quot;&gt;&lt;/a&gt;2024年人工智能进展及展望&lt;/h1&gt;&lt;p&gt;2024年是人工智能领域快速发展的一年，大模</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="人工智能" scheme="http://ai.mak.cn/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>大模型概念总结</title>
    <link href="http://ai.mak.cn/posts/57547/"/>
    <id>http://ai.mak.cn/posts/57547/</id>
    <published>2024-12-05T16:00:00.000Z</published>
    <updated>2025-02-11T03:10:23.311Z</updated>
    
    <content type="html"><![CDATA[<p><strong>尽管大部分人是在LLM（大语言模型）兴起后才接触AI Agent，但它并不是一个完全新生的概念（RAG也是一样），只是因为LLM给AI Agent带来了全新的可能与突破。所以本文的</strong> <strong>AI Agent也是特指基于LLM的自主型人工智能实体。</strong></p><p>01</p><p>为什么需要Agent？</p><p>大模型已经非常强大，能够生成内容、回答问题甚至协助编程。那为什么我们还需要 AI Agent？</p><p>简单的说，大模型就像一个“超级大脑”，知识丰富、能力强大，但它的问题是“只懂回答，不懂行动”。你可以让它生成一篇文章、回答一个问题，但如果你希望它主动完成一系列复杂任务，仅靠大模型自身是不够的。 比如，你可以问大模型：</p><p><em><strong>“如何调查与获取竞争对手产品的信息？”</strong></em></p><p>甚至也可以结合RAG让大模型来回答：</p><p><em><strong>“总结我们公司最新某某产品的特点？”</strong></em></p><p>但是如果你让大模型来帮你完成如下任务：</p><p><em><strong>“对比A公司竞品与我公司产品的差异，把结果发送到我邮箱。“</strong></em></p><p>这时候大模型就无能为力了。原因是它只有聪明的”大脑“，但却没有”手脚“、也没有”工具“，因此无法自主的完成任务。所以AI需要这样的进化：</p><p><img src="https://p6-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/f2d2298685fb486ebde35a1df8d8435a~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1736404376&x-signature=ZGp+KKOm/CRCSpLlBSuTVYBc1pA=" alt="picture.image"></p><p>这就是为什么需要Agent —— 因为我们需要AI <strong>不 *<em>仅*</em></strong> <strong>是被动的回答问题，更需要能够主动的解决问题。</strong></p><p>02</p><p>什么是Agent？</p><p>所以，AI Agent（智能体） 是一种能利用大模型进行自主的任务规划、决策与执行的系统。 <strong>它的核心思路是让人工智能不仅能回答问题，还能像人一样主动完成一系列关联性的任务；不仅有聪明的“大脑”，还有灵活的“手脚”，必要的时候还会使用“工具”。</strong></p><p><img src="https://p6-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/2605f5e64e1e40b0a0b61e3fd897f235~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1736404376&x-signature=WCt4ivDAQtu/YkpUYKjgmcScL6A=" alt="picture.image"></p><p>如果说大模型像一位百科全书式的学者，而AI Agent就像一个“办事能力强的大管家”。这位管家会根据你的需求，把任务拆解成多个步骤，并主动找到资源或工具来完成。比如这个任务：</p><p>“对比A公司与我公司产品的差异，把结果发送到我邮箱。“</p><p>Agent会借助大模型规划任务步骤并执行：</p><ol><li>先从互联网搜索A公司产品信息（使用Web搜索工具）</li><li>再从企业知识库检索我公司信息（使用本地查询工具）</li><li>生成对比报告（让大模型完成）</li><li>发送邮件到邮箱（使用邮件发送工具）</li></ol><p>可以看到，基于大模型的AI Agent，就是把强大的语言模型和一套可以主动行动的机制结合起来，让它不仅能“懂”能“想”，还会“做”。</p><p>所以 <strong>Agent与大模型之间的区别</strong> 可以总结为：</p><ul><li>大模型只是一个大脑，而Agent是一个完整体</li><li>大模型只会告诉你怎么做，而Agent会帮你做</li><li>模型本身不会使用工具，而Agent会使用工具</li><li>大模型通常不会记忆，而Agent则具备记忆能力</li><li>Agent借助大模型来实现理解与规划能力</li></ul><p>03</p><p>Agent的常见应用场景？</p><p>AI Agent可以在大量的领域与场景下展现出非凡的能力，包括但不限于个人助理、客户服务、市场营销、决策支持、游戏仿真、智能家居、无人驾驶、机器人等。以下是一些实际的例子：</p><p><strong>1.智能客服</strong></p><p>比如一家公司需要全天候解答客户问题。AI Agent可以根据客户问题调用大模型生成答案，还能主动查询库存信息、处理订单甚至提供物流状态。</p><p><strong>2.编程助手</strong></p><p>开发人员需要解决某个技术问题，AI Agent不仅能提供代码示例，还能直接运行代码，调试错误，甚至优化性能。</p><p><strong>3.个人助理</strong></p><p>Agent可以帮你管理日程、订餐、处理邮件、监控股票市场，并根据你的偏好提供个性化建议，而不只是回答问题。</p><p><strong>4.智能家居</strong></p><p>家庭中的Agent可以连接灯光、空调、安防摄像头等设备，根据家庭成员的指令与设定，主动调节环境，控制家具设备。</p><p><strong>5.科学研究</strong></p><p>在科研领域，AI Agent可以自动收集最新文献、设计实验流程、分析实验数据，并生成总结报告。</p><p>04</p><p>Agent的基本工作原理？</p><p>AI Agent的工作原理可以总结为以下几个步骤：</p><p><img src="https://p6-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/7dd44afc14c747c58b06a9818cfb967f~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1736404376&x-signature=B/I/jLELGQw5pXIknqfUVDvIwbY=" alt="picture.image"></p><p><strong>1.输入理解：</strong> 用户提出一个任务（比如发送一份产品对比报告），Agent首先借助大模型对用户输入指令进行理解和解析，识别任务目标和约束条件。</p><p><strong>2.任务规划：</strong> 基于理解的目标，Agent 会规划完成任务的步骤，并决定采取哪些行动。这可能涉及将目标分解成多个子任务，确定任务优先级与执行顺序等（如获取竞品信息、查询企业产品信息、生成对比报告、发送电子邮件）。</p><p><strong>3.任务执行与反馈：</strong> 通过大模型或外部工具完成每个子任务（如调用搜索引擎、查询数据库、生成对比结果、调用电子邮件发送服务）；在此过程中，Agent会搜集与观察子任务结果，及时处理问题，必要时对任务进行调整（如任务执行发生了错误，可能会进行多次迭代尝试）。</p><p><strong>4.任务完成与交付：</strong> 将任务的结果汇总并输出（如生成对比报告与邮件发送回执）。</p><p>当然，这只是Agent的核心处理流程。在实际应用中，根据环境与需求的差异，可能存在高度定制且复杂Agent工作流。</p><p>05</p><p>Agent系统的基本组成？</p><p>获得广泛认可的Agent架构来自于OpenAI公司的总结：</p><p><img src="https://p6-volc-community-sign.byteimg.com/tos-cn-i-tlddhu82om/2481f33663cc452b847e51789dc6659d~tplv-tlddhu82om-image.image?=&rk3s=8031ce6d&x-expires=1736404376&x-signature=4QZRFK0up8P6l6ERZQtZP47QnGE=" alt="picture.image"></p><p>可以总结成：</p><p><strong>Agent &#x3D; LLM + 记忆 + 规划技能 + 工具使用</strong></p><ol><li><strong>大模型：</strong> 提供核心的语言理解、推理与生成能力，是整个Agent的“大脑”。</li><li><strong>任务规划：</strong> 对复杂任务借助大模型进行分解、规划和调度，并及时观察子任务执行的结果与反馈，对任务及时调整。</li><li><strong>工具使用：</strong> 与外部工具（如API、数据库、硬件设备）进行交互，扩展智能体的能力，执行任务，相当于Agent的“手脚”。</li><li><strong>记忆：</strong> 这是Agent的“存储器”，可用来存储短期的记忆（如一次任务过程中的多次人类交互）或长期记忆（如记录使用者的任务历史、个人信息、兴趣便好等）。</li></ol><p>除此之外，通常Agent还需要提供 一个直观的入口，让用户可以方便地给Agent下达指令或查看结果，这个入口可以是可视化的文字输入、语音输入，或者对外开放的API接口。</p><p>05</p><p>Agent面临最大的挑战？</p><p>尽管LLM的横空出世与爆炸式发展给Agent开辟了新的天地，但必须看到，当前AI Agent仍然处于技术积累与实验阶段，尽管很多大模型厂家推出了Agent平台甚至商店，但主要集中在个人助理、娱乐、写作等对可靠性与确定性相对较低的领域，而在真正的生产力场景，还面临众多挑战。而最主要的问题来自：</p><p>AI Agent将LLM作为核心组件，用于理解用户需求、计划任务、生成响应并执行操作。但在一些对准确性、可预测性、可追溯性要求极高的场景中，LLM的不确定性会带来一些潜在问题。</p><ul><li><strong>错误的任务规划</strong></li></ul><p>LLM误解了用户的意图或语义，可能会导致错误的计划与结果</p><ul><li><strong>错误的工具调用</strong></li></ul><p>如果LLM生成了错误的工具调用逻辑，可能会导致任务失败</p><ul><li><strong>生成错误的建议</strong></li></ul><p>在医疗、法律、金融等需要高度准确的领域，不确定性可能带来严重后果</p><ul><li><strong>安全与伦理问题</strong></li></ul><p>LLM可能会根据不完整的上下文生成带有潜在风险甚至违反伦理的建议</p><ul><li><strong>稳定性和可重复性</strong></li></ul><p>在工业应用中，系统的行为需要可重复且稳定，而LLM由于其生成概率特性，可能在相同条件下输出不同的结果</p><p>在模型厂家、开发工具提供商、应用开发商的共同努力下，这些问题正在不断得到优化与改善。</p><p>06</p><p>Agent未来的发展趋势？</p><p>AI Agent虽然还处于发展的初期，但未来潜力巨大，简单展望其发展趋势：</p><p><strong>1.更强的自主性与智能化</strong></p><p>随着技术进步，AI Agent将拥有更强的人类意图理解、逻辑推理和复杂任务处理能力，能够在更多场景下自主决策，执行多样的任务。</p><p><strong>2.深度行业化与定制化</strong></p><p>更多的领域与行业会定制化自己的AI Agent，比如IT领域的开发助手、医疗领域的诊断助手、智能家居的家庭助手、智能实体机器人等。</p><p><strong>3.更强的个性化，人性化</strong></p><p>AI Agent会具备更强的个性化能力，能够在与使用者的长期交互中学习使用者的习惯、个人信息与兴趣偏好等，以提供更贴心的服务。</p><p><strong>4. 持续学习和自适应能力</strong></p><p>AI Agent将具备持续学习的能力，能够根据环境变化和新数据进行自我调整和优化，持续提升自身的智能水平。</p><p><strong>5. 伦理与法规考量更受重视</strong></p><p>随着AI Agent的普及，对隐私、安全和伦理的关注将促使相关法规和标准的制定，确保AI技术的负责任发展。</p><p>AI Agent的出现，为人工智能技术赋予了主动行动的能力，让它从“被动回答问题”进化到“主动完成任务”。无论是个人生活、企业运营还是科学研究，AI Agent都在逐步展现它的潜力。可以预见，随着技术的不断进步，AI Agent将成为我们工作和生活中不可或缺的助手。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;尽管大部分人是在LLM（大语言模型）兴起后才接触AI Agent，但它并不是一个完全新生的概念（RAG也是一样），只是因为LLM给AI Agent带来了全新的可能与突破。所以本文的&lt;/strong&gt; &lt;strong&gt;AI Agent也是特指基于LLM的自主型</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="深度学习" scheme="http://ai.mak.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>系统稳定性建设</title>
    <link href="http://ai.mak.cn/posts/47183/"/>
    <id>http://ai.mak.cn/posts/47183/</id>
    <published>2024-10-01T16:00:00.000Z</published>
    <updated>2025-02-11T03:10:23.679Z</updated>
    
    <content type="html"><![CDATA[<h1 id="系统稳定性建设"><a href="#系统稳定性建设" class="headerlink" title="系统稳定性建设"></a>系统稳定性建设</h1><blockquote><p>这篇文章以京东为例，从后端研发视角谈系统稳定性建设，包括研发和上线阶段。研发阶段要把控技术方案和代码质量，技术方案需评审，关注限流、熔断降级、超时、重试、兼容、隔离等，还要进行代码 Review。上线阶段是故障高发期，需做到可监控、可灰度、可回滚，应对线上问题要分类、明确生命周期、预防、发现、响应、定位、修复和复盘。</p></blockquote><blockquote><p>作者：京东云开发者<br>链接：<a href="https://mp.weixin.qq.com/s/lPSNDH872Wmy7rkrq_U6_w">https://mp.weixin.qq.com/s/lPSNDH872Wmy7rkrq_U6_w</a></p></blockquote><h1 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h1><p>京东的期中考试：618即将到来，各个团队都在进行期中考试前的模拟考试：军演压测，故障演练，系统的梳理以检测系统的稳定性以应对高可用，高性能，高并发。我们知道系统的稳定性建设是贯穿整个研发流程：需求阶段，研发阶段，测试阶段，上线阶段，运维阶段；整个流程中的所有参与人员：产品，研发，测试，运维人员都应关注系统的稳定性。业务的发展及系统建设过程中，稳定性就是那个1，其他的是1后面的0，没有稳定性，就好比将万丈高楼建于土沙之上。本篇文章主要从后端研发的视角针对研发阶段和上线阶段谈下稳定性建设，希望起到抛砖引玉的作用，由于本人的水平有限，文中难免有理解不到位或者不全面的地方，欢迎批评指正。</p><h1 id="2-研发阶段"><a href="#2-研发阶段" class="headerlink" title="2. 研发阶段"></a>2. 研发阶段</h1><p>研发阶段主要参与人员是研发，主要产出物是技术方案设计文档和代码，一个是研发阶段的开始，一个是研发阶段的结束，我们要把控好技术文档和代码质量，从而减少线下bug率及线上的故障；</p><h2 id="2-1-技术方案"><a href="#2-1-技术方案" class="headerlink" title="2.1 技术方案"></a>2.1 技术方案</h2><h3 id="2-1-1-技术方案评审"><a href="#2-1-1-技术方案评审" class="headerlink" title="2.1.1 技术方案评审"></a>2.1.1 技术方案评审</h3><p>技术文档的评审需要有本团队的架构师和相关研发，测试，产品，上下游系统的研发同学参与，这样能够最大限度的保证技术方案的实现和产品需求对齐，上下游系统同学也知道我们的实现，采取更加合理的交互方式，测试同学也可以从测试视角给出一些风险点建议，架构师可以确保我们的实现和业界最佳实践的差异，确保合理性，避免过度设计；我们所要做的是开放心态采取大家的意见，严控技术文档的质量；</p><p>技术文档的评审可以采用提问的方式，会议开始前可以将技术文档分享给大家，让大家先阅读10分钟，所有同学开始提问，技术文档设计人其实不用读自己的技术文档给大家介绍，只要将大家的问题回答完，并能够思考下大家的建议，合理的采纳后，其实技术文档的质量就有了很大的保证，有的同学在技术文档评审时，比较反感大家的提问，总感觉在挑战自己，有些问题回答不上来，其实可以换种思路：有些问题回答不上来是正常的，可以先将大家的建议采纳了，会后再思考下合理性；大家对自己技术方案是建言献策，是保证自己技术方案的质量，避免在技术方案阶段就存在重大的线上隐患。</p><h3 id="2-1-2-技术方案关注点"><a href="#2-1-2-技术方案关注点" class="headerlink" title="2.1.2 技术方案关注点"></a>2.1.2 技术方案关注点</h3><p>当我们遇到一个问题的时候，首先要思考的这是一个新问题还是老问题，99.99%遇到的都是老问题，因为我们所从事的是工程技术，不是科学探索；我们所要做的就是看下国内外同行针对这个问题的解法，learn from best practices；所以技术方案的第一步是<strong>对标</strong>，学习最佳实践，这样能让我们避免走弯路；</p><p>同时根据奥卡姆剃刀原理，我们力求技术方案简单，避免过度设计，针对一个复杂的问题，我们的技术方案相对复杂些，简单的问题技术方案相对简单些，我们所要追求的是复杂的问题通过拆解划分，用一个个简单的技术方案解决掉。同时技术文档不仅关注功能的实现，更重要的是关注架构，性能，质量，安全；即如何打造一个高可用系统。打造一个高可用的系统是进行系统稳定性建设的前提，如果我们的系统都不能保证高可用，又谈何系统稳定系建设那，下面介绍下进行系统稳定性建设我们在技术方案中常用的方法及关注点。</p><h4 id="2-1-2-1-限流"><a href="#2-1-2-1-限流" class="headerlink" title="2.1.2.1 限流"></a>2.1.2.1 限流</h4><p>限流一般是从服务提供者provider的视角提供的针对自我保护的能力，对于流量负载超过我们系统的处理能力，限流策略可以防止我们的系统被激增的流量打垮。京东内部无论是同步交互的JSF, 还是异步交互的JMQ都提供了限流的能力，大家可以根据自己系统的情况进行设置；我们知道常见的限流算法包括：计数器算法，滑动时间窗口算法，漏斗算法，令牌桶算法，具体算法可以网上google下，下面是这些算法的优缺点对比。</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cba4342107a24b2a8f579efcdc78cede~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1752&h=704&s=173199&e=png&b=ffffff" alt="img"></p><p>﻿﻿</p><h4 id="2-1-2-2-熔断降级"><a href="#2-1-2-2-熔断降级" class="headerlink" title="2.1.2.2 熔断降级"></a>2.1.2.2 熔断降级</h4><p>熔断和降级是两件事情，但是他们一般是结合在一起使用的。熔断是防止我们的系统被下游系统拖垮，比如下游系统接口性能严重变差，甚至下游系统挂了；这个时候会导致大量的线程堆积，不能释放占用的CPU，内存等资源，这种情况下不仅影响该接口的性能，还会影响其他接口的性能，严重的情况会将我们的系统拖垮，造成雪崩效应，通过打开熔断器，流量不再请求到有问题的系统，可以保护我们的系统不被拖垮。降级是一种有损操作，我们作为服务提供者，需要将这种损失尽可能降到最低，无论是返回友好的提示，还是返回可接受的降级数据。降级细分的话又分为人工降级，自动降级。</p><p><strong>人工降级</strong>：人工降级一般采用降级开关来控制，公司内部一般采用配置中心Ducc来做开关降级，开关的修改也是线上操作，这块也需要做好监控</p><p><strong>自动降级</strong>：自动降级是采用自动化的中间件例如Hystrix，公司的小盾龙等；如果采用自动降级的话；我们必须要对降级的条件非常的明确，比如失败的调用次数等；</p><h4 id="2-1-2-3-超时"><a href="#2-1-2-3-超时" class="headerlink" title="2.1.2.3 超时"></a>2.1.2.3 超时</h4><p>分布式系统中的难点之一：不可靠的网络，京东物流现有的微服务架构下，服务之间都是通过JSF网络交互进行同步通信，我们探测下游依赖服务是否可用的最快捷的方式是设置超时时间。超时的设置可以让系统快速失败，进行自我保护，避免无限等待下游依赖系统，将系统的线程耗尽，系统拖垮。</p><p>超时时间如何设置也是一门学问，如何设置一个合理的超时时间也是一个逐步迭代的过程，比如下游新开发的接口，一般会基于压测提供一个TP99的耗时，我们会基于此配置超时时间；老接口的话，会基于线上的TP99耗时来配置超时时间。</p><p>超时时间在设置的时候需要遵循漏斗原则，从上游系统到下游系统设置的超时时间要逐渐减少，如下图所示。为什么要满足漏斗原则，假设不满足漏斗原则，比如服务A调取服务B的超时时间设置成500ms，而服务B调取服务C的超时时间设置成800ms，这个时候回导致服务A调取服务B大量的超时从而导致可用率降低，而此时服务B从自身角度看是可用的；</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2fc89904ae9d4cc9a52b81bcf63e9102~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1580&h=422&s=40692&e=png&b=fefefe" alt="img"></p><p>﻿﻿</p><h4 id="2-1-2-4-重试"><a href="#2-1-2-4-重试" class="headerlink" title="2.1.2.4 重试"></a>2.1.2.4 重试</h4><p>分布式系统中性能的影响主要是通信，无论是在分布式系统中还是垮团队沟通，communication是最昂贵的；比如我们研发都知道需求的交付有一半以上甚至更多的时间花在跨团队的沟通上，真正写代码的时间是很少的；分布式系统中我们查看调用链路，其实我们系统本身计算的耗时是很少的，主要来自于外部系统的网络交互，无论是下游的业务系统，还是中间件：Mysql, redis, es等等；</p><p>所以在和外部系统的一次请求交互中，我们系统是希望尽最大努力得到想要的结果，但往往事与愿违，由于不可靠网络的原因，我们在和下游系统交互时，都会配置超时重试次数，希望在可接受的SLA范围内一次请求拿到结果，但重试不是无限的重试，我们一般都是配置重试次数的限制，偶尔抖动的重试可以提高我们系统的可用率，如果下游服务故障挂掉，重试反而会增加下游系统的负载，从而增加故障的严重程度。在一次请求调用中，我们要知道对外提供的API，后面是有多少个service在提供服务，如果调用链路比较长，服务之间rpc交互都设置了重试次数，这个时候我们需要警惕重试风暴。如下图service D 出现问题，重试风暴会加重service D的故障严重程度。对于API的重试，我们还要区分该接口是读接口还是写接口，如果是读接口重试一般没什么影响，写接口重试一定要做好接口的幂等性。</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2e97c5176a3d4712852076328a54b24c~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1576&h=434&s=35294&e=png&b=ffffff" alt="img"></p><p>﻿﻿</p><h4 id="2-1-2-5-兼容"><a href="#2-1-2-5-兼容" class="headerlink" title="2.1.2.5 兼容"></a>2.1.2.5 兼容</h4><p>我们在对老系统，老功能进行重构迭代的时候，一定要做好兼容，否则上线后会出现重大的线上问题，公司内外有大量因为没有做好兼容性，而导致资损的情况。兼容分为：向前兼容性和向后兼容性，需要好好的区分他们，如下是他们的定义:</p><p><strong>向前兼容性</strong>：向前兼容性指的是旧版本的软件或硬件能够与将来推出的新版本兼容的特性，简而言之旧版本软件或系统兼容新的数据和流量。</p><p><strong>向后兼容性</strong>：向后兼容性则是指新版本的软件或硬件能够与之前版本的系统或组件兼容的特性，简而言之新版本软件或系统兼容老的数据和流量。</p><p>根据新老系统和新老数据我们可以将系统划分为四个象限：<strong>第一象限</strong>：新系统和新数据是我们系统改造上线后的状态，<strong>第三象限</strong>：老系统和老数据是我们系统改造上线前的状态，第一象限和第三象限的问题我们在研发和测试阶段一般都能发现排除掉，线上故障的高发期往往出现在第二和第四象限，<strong>第二象限</strong>是因为没有做好向前兼容性，例如上线过程中，发现问题进行了代码回滚，但是在上线过程中产生了新数据，回滚后的老系统不能处理上线过程中新产生的数据，导致线上故障。<strong>第四象限</strong>是因为没有做好向后兼容性，上线后新系统影响了老流程。针对第二象限的问题，我们可以构造新的数据去验证老的系统，针对第四象限的问题，我们可以通过流量的录制回放解决，录制线上的老流量，对新功能进行验证。</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b9ce1bec87cc4778867a0edd7c03efae~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1566&h=1082&s=111193&e=png&b=ffffff" alt="img"></p><p>﻿﻿</p><h4 id="2-1-2-6-隔离"><a href="#2-1-2-6-隔离" class="headerlink" title="2.1.2.6 隔离"></a>2.1.2.6 隔离</h4><p>隔离是将故障爆炸半径最小化的有效手段，在技术方案设计中，我们通过不同层面的隔离来控制影响范围：</p><h5 id="2-1-2-6-1-系统层面隔离"><a href="#2-1-2-6-1-系统层面隔离" class="headerlink" title="2.1.2.6.1 系统层面隔离"></a>2.1.2.6.1 系统层面隔离</h5><p>我们知道系统的分类可以分为：在线的系统，离线系统（批处理系统），近实时系统（流处理系统），如下是这些系统的定义：</p><p><strong>在线系统</strong>：服务端等待请求的到达，接收到请求后，服务尽可能快的处理，然后返回给客户端一个响应，响应时间通常是在线服务性能的主要衡量指标。我们生活中在手机使用的APP大部分都是在线系统；</p><p><strong>离线系统</strong>：或称批处理系统，接收大量的输入数据，运行一个作业来处理数据，并产出输出数据，作业往往需要定时，定期运行一段时间，比如从几分钟到几天，所以用户通常不会等待作业完成，吞吐量是离线系统的主要衡量指标。例如我们看到的报表数据：日订单量，月订单量，日活跃用户数，月活跃用户数都是批处理系统运算一段时间得到的；</p><p><strong>近实时系统</strong>：或者称流处理系统，其介于在线系统和离线系统之间，流处理系统一般会有触发源：用户的行为操作，数据库的写操作，传感器等，触发源作为消息会通过消息代理中间件：JMQ, KAFKA等进行传递，消费者消费到消息后再做其他的操作，例如构建缓存，索引，通知用户等；</p><p>以上三种系统是需要进行隔离建设的，因为他们的衡量指标及对资源的使用情况完全不一样的，比如我们小组会将在线系统作为一个服务单独部署：jdl-uep-main, 离线系统和近实时系统作为一个服务单独部署：jdl-uep-worker；</p><h5 id="2-1-2-6-2-环境的隔离"><a href="#2-1-2-6-2-环境的隔离" class="headerlink" title="2.1.2.6.2 环境的隔离"></a>2.1.2.6.2 环境的隔离</h5><p>从研发到上线阶段我们会使用不同的环境，比如业界常见的环境分为：开发，测试，预发和线上环境；研发人员在开发环境进行开发和联调，测试人员在测试环境进行测试，运营和产品在预发环境进行UAT，最终交付的产品部署到线上环境提供给用户使用。在研发流程中，我们部署时要遵循从应用层到中间件层再到存储层，都要在一个环境，严禁垮环境的调用，比如测试环境调用线上，预发环境调用线上等。</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6e611ff2840f4d948add3e1580f93b07~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1554&h=516&s=48556&e=png&b=ffffff" alt="img"></p><p>﻿﻿</p><h5 id="2-1-2-6-3-数据的隔离"><a href="#2-1-2-6-3-数据的隔离" class="headerlink" title="2.1.2.6.3 数据的隔离"></a>2.1.2.6.3 数据的隔离</h5><p>随着业务的发展，我们对外提供的服务往往会支撑多业务，多租户，所以这个时候我们会按照业务进行数据隔离；比如我们组产生的物流订单数据业务方就包含京东零售，其他电商平台，ISV等，为了避免彼此的影响我们需要在存储层对数据进行隔离，数据的隔离可以按照不同粒度，第一种是通过租户id字段进行区分，所有的数据存储在一张表中，另外一个是库粒度的区分，不同的租户单独分配对应的数据库。</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6bf57661c94a4410ad9d385adf1cd069~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1568&h=1624&s=194739&e=png&b=fefefe" alt="img"></p><p>﻿﻿</p><p>数据的隔离除了按照业务进行隔离外，还有按照环境进行隔离的，比如我们的数据库分为测试库，预发库，线上库，全链路压测时，我们为了模拟线上的环境，同时避免污染线上的数据，往往会创建影子库，影子表等。根据数据的访问频次进行隔离，我们将经常访问的数据称为热数据，不经常访问的数据称为冷数据；将经常访问的数据缓存到缓存，提高系统的性能。不经常访问的数据持久化到数据库或者将不使用的数据结转归档到</p><h5 id="2-1-2-6-4-核心，非核心隔离"><a href="#2-1-2-6-4-核心，非核心隔离" class="headerlink" title="2.1.2.6.4 核心，非核心隔离"></a>2.1.2.6.4 核心，非核心隔离</h5><p>我们知道应用是分级的，京东内部针对应用的重要程度会将应用分为0，1，2，3级应用。业务的流程也分为黄金流程和非黄金流程。在业务流程中，针对不同级别的应用交互，需要将核心和非核心的流程进行隔离。例如在交易业务过程中，会涉及到订单系统，支付系统，通知系统，那这个过程中核心系统是订单系统和支付系统，而通知相对来说重要性不是那么高，所以我们会投入更多的资源到订单系统和支付系统，优先保证这两个系统的稳定性，通知系统可以采用异步的方式与其他两个系统解耦隔离，避免对其他另外两个系统的影响。</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/30513d12b06f4508bc1872b578d3a539~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1562&h=414&s=35529&e=png&b=fefefe" alt="img"></p><p>﻿﻿</p><h5 id="2-1-2-6-5-读写隔离"><a href="#2-1-2-6-5-读写隔离" class="headerlink" title="2.1.2.6.5 读写隔离"></a>2.1.2.6.5 读写隔离</h5><p>应用层面，领域驱动设计（DDD）中最著名的CQRS（Command Query Responsibility Segregation）将写服务和读服务进行隔离。写服务主要处理来自客户端的command写命令，而读服务处理来自客户端的query读请求，这样从应用层面进行读写隔离，不仅可以提高系统的可扩展性，同时也会提高系统的可维护性，应用层面我们都采用微服务架构，应用层都是无状态服务，可以扩容加机器随意扩展，存储层需要持久化，扩展就比较费劲。除了应用层面的CQRS，在存储层面，我们也会进行读写隔离，例如数据库都会采用一主多从的架构，读请求可以路由到从库从而分担主库的压力，提高系统的性能和吞吐量。所以应用层面通过读写隔离主要解决可扩展问题，存储层面主要解决性能和吞吐量的问题。</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d77b07186a0f460085945023de56420c~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1508&h=1050&s=381840&e=png&b=fefefe" alt="img"></p><p>﻿﻿</p><p>﻿</p><h5 id="2-1-2-6-6-线程池隔离"><a href="#2-1-2-6-6-线程池隔离" class="headerlink" title="2.1.2.6.6 线程池隔离"></a>2.1.2.6.6 线程池隔离</h5><p>线程是昂贵的资源，为了提高线程的使用效率，避免创建和销毁的消耗，我们采用了池化技术，线程池来复用线程，但是在使用线程池的过程中，我们也做好线程池的隔离，避免多个API接口复用同一个线程。</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/59cfe0297d904a949fff209ee14598f5~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1574&h=622&s=73589&e=png&b=fefefe" alt="img"></p><p>﻿﻿</p><h2 id="2-2-代码Review"><a href="#2-2-代码Review" class="headerlink" title="2.2 代码Review"></a>2.2 代码Review</h2><p>codeReview是研发阶段的最后一个流程，对线下的bug率和线上质量及稳定性有着重要的作用，针对于代码如何review，谈一些自己的看法：</p><p>•<strong>形成团队代码风格</strong>：首先一个团队的代码应该形成该团队的代码风格，这样能够提高codeReview的效率及协作的效率，作为新加入的成员，应该遵循团队的代码风格规范。</p><p>•<strong>Review的关注点</strong>：代码review切记不要陷入细节，主要以review代码风格为主，如果一个团队形成统一的代码风格，我们通过review风格就能将大部分问题发现，在关注功能的同时，再关注下性能，安全。</p><p>•<strong>结对编程</strong>：在代码编写过程中，我们要培养结对编程的习惯，这样针对某次需求，codeReview时，熟悉该模块的同事把控下细节，架构师把控风格。</p><p>•<strong>控制每次review代码量</strong>：每次提交代码进行review时，不要一次性提交review大量的代码，要将review的内容细分，比如一个方法的实现，一个类等。</p><p>•<strong>开放心态</strong>：review的过程其实是学习提升的过程，通过代码review，虚心接收别人的意见，学习优雅代码的编写方式，提高自己的代码水平。</p><h1 id="3-上线阶段"><a href="#3-上线阶段" class="headerlink" title="3 上线阶段"></a>3 上线阶段</h1><p>我们可以看下公司的故障管理平台白虎所记录的故障：发生系统故障一般都是外部对系统做了改变，往往发生在上线阶段：代码的部署，数据库的更改，配置中心的变动等；上线阶段是故障的高发期；一个系统不可能不出线上问题，我们所要追求的是，降低线上的故障频率，缩短故障恢复时间。针对上线过程出现问题，我们知道业界有著名的上线过程三板斧：可监控，可灰度，可回滚。</p><h2 id="3-1-上线三板斧"><a href="#3-1-上线三板斧" class="headerlink" title="3.1 上线三板斧"></a>3.1 上线三板斧</h2><h3 id="3-1-1-可监控"><a href="#3-1-1-可监控" class="headerlink" title="3.1.1 可监控"></a>3.1.1 可监控</h3><p>上线的过程中，我们的系统要做到可监控，如果没有监控，上线过程中我们对系统的状态是一无所知，是很可怕的。监控什么东西那，其实监控的就是指标。这就涉及到指标的定义，指标我们分为业务指标和技术指标，技术指标又分为软件和硬件。业务指标一般是我们定义的观测业务变化情况的度量，例如订单量，支付量等。技术层面的软件指标：可用率，TP99, 调用量，技术层面的硬件指标：cpu 内存 磁盘 网络IO。目前我们二级部门在做OpsReview，主要review的是可用率，TP99，调用量这几个指标，分别对应系统的可用性，性能，并发。</p><p>做好这些指标的监控后，我们接下来需要做的是针对这些指标做好告警，如果某个指标突破设定的阈值后，需要进行告警通知给我们，针对监控告警指标阈值的设置，建议先严后松，即系统建设初始阶段设置的严格些，避免遗漏告警，出现线上问题，后续随着系统建设的迭代需要设置更合理的告警阈值，避免告警泛滥，造成狼来了的效应。总之上线发布过程的一段时间是事故和问题发生的高峰，这块一定做好指标监控，日志监控，对报警要敏感。</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9711b4d6ff324945a072d878de935cfe~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1288&h=1482&s=161810&e=png&b=ffffff" alt="img"></p><p>﻿﻿</p><h3 id="3-1-2-可灰度"><a href="#3-1-2-可灰度" class="headerlink" title="3.1.2 可灰度"></a>3.1.2 可灰度</h3><p>上线过程中，我们要做到可灰度，通过灰度执行变更以限制爆炸半径，降低影响范围，同时灰度过程要做好兼容。灰度分为不同维度的灰度：机器维度，机房维度，地域维度，业务维度：用户，商家，仓，承运商等。</p><p><strong>机器维度</strong>：我们用行云部署时，可以每个分组先部署一部分机器进行灰度，灰度一段时间比如：24小时没什么问题后，再部署剩余的机器。</p><p><strong>机房维度</strong>：微服务架构下，我们的应用会部署在不同的机房中，可以按照机房维度灰度，比如先部署发布代码在某个机房分组下，观察一段时间再按照比例扩大灰度机房范围直至全量。例如先部署中云信的机房，灰度一段时间后，再逐步灰度有孚的机房。</p><p><strong>地域维度</strong>：现在的部署架构都是多机房互为灾备，异地多活，单元化部署，例如业界美团的外卖业务非常适合做异地多活，单元化部署，因为外卖业务的商户，用户，骑手天然具有聚合性，北京的用户大概率不会在上海点外卖，这样根据业务的属性，在系统建设的时候，从应用层到中间件层，再到存储层可以单元化部署在上海地域的机房和北京地域的机房，功能发布的时候可以灰度某个地域，做到地域级别的容灾。</p><p><strong>业务维度：</strong> 在上线过程中，我们也可以根据业务属性进行灰度，例如上线了某个功能或者产品，根据用户维度灰度，某些用户或者某些商户才能使用该功能，产品。</p><h3 id="3-1-3-可回滚"><a href="#3-1-3-可回滚" class="headerlink" title="3.1.3 可回滚"></a>3.1.3 可回滚</h3><p>线上出现问题时，我们应该优先止损，其次才是分析根因。止损的最快方式就是回滚，<strong>回滚分为代码回滚和数据回滚</strong>，代码回滚即将我们代码恢复到原有的逻辑，代码回滚有两种方式：开关控制和部署回滚。最快捷的方式是开关控制，一键开关打开或者关闭就可以实现回滚到原有的逻辑，操作成本最低，止损最快速。第二种方式就是部署回滚，通过发布平台，例如行云将代码回滚到上个稳定运行的版本。有时候我们代码回滚完，如果没有做好向前兼容性，系统应用依然有问题，例如上线过程中产生了新数据，回滚完后，代码不能处理新的数据。所以这个时候又涉及到数据的回滚，数据的回滚涉及到修数：将产生的新数据无效掉，或者修改为正确的数据等，当数据量比较大时，数据的回滚一般耗时费力，所以建议做好向前兼容性，直接代码回滚。</p><h2 id="3-2-线上问题应对"><a href="#3-2-线上问题应对" class="headerlink" title="3.2 线上问题应对"></a>3.2 线上问题应对</h2><h3 id="3-2-1-常见问题分类"><a href="#3-2-1-常见问题分类" class="headerlink" title="3.2.1 常见问题分类"></a>3.2.1 常见问题分类</h3><p>针对线上的问题，我们第一步是识别出是什么问题，然后才能解决问题，针对线上各种各样的问题我们可以进行聚合，归并分类下，针对每种问题去参考业界的处理方法和团队的内的紧急预案，做到临阵不乱。</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/da68cadd57934caca7f07d2d25c3a5a2~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=494&h=1556&s=117823&e=png&b=ffffff" alt="img"></p><p>﻿﻿</p><h3 id="3-2-2-问题生命周期"><a href="#3-2-2-问题生命周期" class="headerlink" title="3.2.2 问题生命周期"></a>3.2.2 问题生命周期</h3><p>当出现问题时，我们也需要清楚一个线上问题的生命周期：从问题发生，到我们发现问题，进而进行响应处理，观测问题是否修复，服务是否恢复正常，到最终针对该问题进行复盘，当发生系统发生问题时，我们越早发现问题，对业务的影响越小，整个流程如下图所示。</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f551b0758e664597bccf745008052e3f~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1558&h=510&s=58318&e=png&b=fefefe" alt="img"></p><p>﻿﻿</p><h3 id="3-2-3-如何预防问题"><a href="#3-2-3-如何预防问题" class="headerlink" title="3.2.3 如何预防问题"></a>3.2.3 如何预防问题</h3><p>就像人的身体生病一样，当问题发生已经晚了，我们要投入更多时间和精力到如何预防中，就像扁鹊的大哥一样治未病，防患于未然。根据破窗原理，一个问题出现了，如果放任不管，问题的严重性会越来越大，直到不可挽回。我们可以从研发的规范，研发的流程，变更流程这几个方面进行预防。</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/aae8de2df4ae45648418909cf6e30d6d~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=910&h=1272&s=137124&e=png&b=ffffff" alt="img"></p><p>﻿﻿</p><h3 id="3-2-4-如何发现问题"><a href="#3-2-4-如何发现问题" class="headerlink" title="3.2.4 如何发现问题"></a>3.2.4 如何发现问题</h3><p>对于一个系统，如果外界不对其做功，根据熵增原理，其会越来越混乱，直到出现问题，外界对其做功，就涉及到改变，因为改变是人在操作，由于各种不可控的因素，也会导致各种线上问题，所以我们可以看到对于一个系统上线后不出现问题是不可能的，当出现问题时，我们第一步是如何快速的发现问题？对于问题发现的渠道，工作中接触到的有如下几种：自我意识，监控告警，业务反馈；</p><p><strong>自我意识</strong>：我们C2部门每周有一个重要会议OpsReview，各个C3团队会对个团队的核心接口的不规律跳点，毛刺进行可用率，性能，调用量的review，以通过这种主动的，自我意识行为发现潜在的线上问题。同时我们组每天早会的重要一项：UMP监控全域看板的review，我们会对昨天核心接口的可用率，TP99，调用量，进行分析的，对于可用率降低，TP99有毛刺，不规范的流量调用会进行排查原因，尽早自我发现问题，同时也会对机器的CPU, 内存使用率，Mysql, redis , es各种存储进行review。</p><p><strong>监控告警</strong>：这是我们发现问题最常用的渠道，通过主动的监控指标，被动的接收告警来发现问题，告警指标我们分为业务指标和技术指标，具体分类可详见3.1.1可监控部分</p><p><strong>业务反馈</strong>：这种发现问题的方式是我们最不愿意看到的，如果等到业务反馈，说明线上问题已经影响到用户，我们常常因为监控告警的缺失，漏报而导致落后于业务发现问题，所以我们最希望每个人，团队都有这种自我意识，将线上问题提早发现，防患于未然。</p><h3 id="3-2-5-如何响应问题"><a href="#3-2-5-如何响应问题" class="headerlink" title="3.2.5 如何响应问题"></a>3.2.5 如何响应问题</h3><p>出现线上问题后，我们个人对问题的认知是非常有限的，并且这个时候人处于一种高度紧张的状态，所以这个时候一定要群里周知自己的leader，将情况如实表达，不要夸大和缩小问题的范围和影响，同时将问题进行通告。整个问题的响应过程包含以下几步：</p><p>1.<strong>保留现场：</strong> 问题发生的现场是我们排查问题的依据，所以要将现场的日志，数据等信息保存好，比如内存dump, 线程dump，避免机器重启后这些信息的丢失。</p><p>2.<strong>提供信息</strong>：提供自己所知道的信息，协助排查，不要扩大和缩小问题</p><p>3.<strong>恢复服务</strong>：当出现线上问题是，我们追求的是以最快的速度恢复服务，快速止损，业界有快速止血，恢复服务的几板斧：回滚：服务回滚，数据回滚，重启，扩容，禁用节点，功能降级</p><p>4.<strong>双重确认：</strong> 服务恢复后，我们需要确认是否恢复了，可以通过观察：业务指标是否正常，技术指标是否正常，数据是否正常，日志是否正常等来观测问题的恢复情况</p><p>5.<strong>故障通告：</strong> 确认问题没有什么问题后，需要再应急群中周知大家：业务人员，产品经理，系统的上下游，测试人员，SRE等。并让产品和业务进行确认，然后周知用户。</p><h3 id="3-2-6-如何定位问题"><a href="#3-2-6-如何定位问题" class="headerlink" title="3.2.6 如何定位问题"></a>3.2.6 如何定位问题</h3><p>服务恢复后，我们可以回过头来细致的分析下到底是什么原因导致了线上的问题。定位问题也要讲究方法论，这就涉及到定位问题三要素：知识，工具，方法。</p><p><strong>知识</strong>：相对其他行业，计算机行业应该是知识更新迭代最快的行业，所以我们需要不断的去学习，更新自己的知识库，不给自己设限。例如你想解决FullGC问题，你必须对JVM进行系统的学习，想解决慢sql，必须对Mysql进行系统的学习，现在AI大模型这么火，我们也需要对prompt engineering， RAG ， Agent, 多模态等进行学习了解。有了知识我们才能遇到问题时，知道是什么，为什么？</p><p><strong>工具：</strong> 工欲善其事，必先利其器，工程师要善于借助公司工具来提高解决问题的效率，熟练使用公司各种中间件工具，公司已经有的中间件，优先使用公司的中间件，公司内一个中间件团队维护的中间件工具要优于业务研发小组内维护的中间件工具，不要小组内部，或者团队内部重复造轮子，并且小组内人员的流动变更，容易造成中间件没人维护。下图是公司常用的中间件工具：</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9bdeed0714f646dd99e6ecff69a3c6e0~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1080&h=1410&s=169542&e=png&b=ffffff" alt="img"></p><p>﻿﻿</p><p><strong>方法</strong>：解决问题我们要讲究方法，选择正确的方法可以事半功倍，提高我们定位问题及解决问题的效率，下面是我们研发人员常见的排查问题的方法</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b3c3b597ca0f4da48a20cf6412deda63~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1082&h=1614&s=362937&e=png&b=ffffff" alt="img"></p><p>﻿﻿</p><h3 id="3-2-7-如何修复问题"><a href="#3-2-7-如何修复问题" class="headerlink" title="3.2.7 如何修复问题"></a>3.2.7 如何修复问题</h3><p>有了知识，工具和方法后，其实我们很快的就定位到问题了，定位到问题后，我们就要想办法如何去把问题修复了，以下是问题修复的流程：</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/07a4c47142e541308af2898b444c52b4~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1576&h=488&s=64103&e=png&b=ffffff" alt="img"></p><p>﻿﻿</p><h3 id="3-2-8-如何复盘问题"><a href="#3-2-8-如何复盘问题" class="headerlink" title="3.2.8 如何复盘问题"></a>3.2.8 如何复盘问题</h3><p>问题发生后，我们需要从此次问题中分析根因，并汲取教训和经验，避免犯同样的错误。这就涉及到问题的复盘，如何进行问题的复盘那，一般会经过如下几个步骤：回顾目标，评价结果，分析原因，总结经验。例如我们C2部门每周的opsReview会议上都会有线上问题的复盘：coe，如何进行coe复盘谈一些自己的思考。</p><p>•参考业界的5WHY分析法剖析问题的根因</p><p>•5WHY分析法：5代表的是问题的深度，而不是问题的数量</p><p>•基于问题的答案继续进行提问，5个问题是有关联的，层层递进的，找到问题的根因</p><p>﻿</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/98a9b75f31474104a2fda8d66a5ca778~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1564&h=418&s=36158&e=png&b=ffffff" alt="img"></p><p>﻿﻿</p><h1 id="4-参考资料"><a href="#4-参考资料" class="headerlink" title="4 参考资料"></a>4 参考资料</h1><p>•﻿<a href="https://link.juejin.cn/?target=https://itrevolution.com/articles/20-years-of-google-sre-10-key-lessons-for-reliability/">itrevolution.com&#x2F;articles&#x2F;20…</a>﻿</p><p>•﻿<a href="https://link.juejin.cn/?target=https://learn.microsoft.com/en-us/previous-versions/msp-n-p/jj591573(v=pandp.10)?redirectedfrom=MSDN">learn.microsoft.com&#x2F;en-us&#x2F;previ…</a>﻿</p><p>•﻿<a href="https://link.juejin.cn/?target=https://sre.google/books/">sre.google&#x2F;books&#x2F;</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;系统稳定性建设&quot;&gt;&lt;a href=&quot;#系统稳定性建设&quot; class=&quot;headerlink&quot; title=&quot;系统稳定性建设&quot;&gt;&lt;/a&gt;系统稳定性建设&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;这篇文章以京东为例，从后端研发视角谈系统稳定性建设，包括研发和上线阶段。研</summary>
      
    
    
    
    <category term="技术小栈" scheme="http://ai.mak.cn/categories/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/"/>
    
    
    <category term="架构" scheme="http://ai.mak.cn/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>实时通信的关键差异解析</title>
    <link href="http://ai.mak.cn/posts/24447/"/>
    <id>http://ai.mak.cn/posts/24447/</id>
    <published>2024-09-14T16:00:00.000Z</published>
    <updated>2025-02-11T03:10:23.667Z</updated>
    
    <content type="html"><![CDATA[<h1 id="实时通信的关键差异解析"><a href="#实时通信的关键差异解析" class="headerlink" title="实时通信的关键差异解析"></a>实时通信的关键差异解析</h1><blockquote><p>文章介绍了 OSI 七层网络协议模型相关知识，详细阐述了 WebSocket 和 Server-Sent Events (SSE)的工作原理、特点、适用场景等。重点比较了二者在多个维度的差异，如通信模式、连接建立、适用场景等，并分析了豆包选择 SSE 而非 WebSocket 的原因，最后总结二者均是实现实时通信的有效技术，各有适用场景。</p></blockquote><blockquote><p>链接：<a href="https://juejin.cn/post/7411406818025717770">https://juejin.cn/post/7411406818025717770</a><br>来源：稀土掘金</p></blockquote><h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><p>在我们平时使用豆包的过程中，不知道大家有没有发现，界面上的内容不是一次性显示出来的，而是像是以一种实时的方式打印出来的，这种方式我们把他称之为流式打印。这种效果感觉互动性更强，更加真实，那么这种技术是如何实现的呢？其实传统的请求-响应模型（如HTTP&#x2F;HTTPS）并不能很好地满足这种实时流式输出。为此，目前主流的web实时通信技术主要是以以WebSocket和Server-Sent Events (SSE)为主，下面我们就一起介绍一下这两者之间的差异，以及为什么豆包选择使用SSE而不是Websocket？</p><p><img src="https://p3-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/b4e3a8c5623b483db90b0d0444cdca50~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5LqU5Y-35Y6C5oi_:q75.awebp?rk3s=f64ab15b&x-expires=1734923281&x-signature=F4lz8ACEYugkjodb+ZKCP5bSkx0=" alt="image.png"></p><h2 id="二、一些网络协议相关的知识补充"><a href="#二、一些网络协议相关的知识补充" class="headerlink" title="二、一些网络协议相关的知识补充"></a>二、一些网络协议相关的知识补充</h2><h3 id="1-OSI网络协议模型"><a href="#1-OSI网络协议模型" class="headerlink" title="1. OSI网络协议模型"></a>1. OSI网络协议模型</h3><p>OSI（Open System Interconnection）参考模型即开放式系统互联通信参考模型，是一种概念模型，由国际标准化组织（ISO）提出，目的是为了使各种计算机在世界范围内互连为网络。OSI 模型将计算机网络体系结构划分为七层，从下到上分别是：</p><p><img src="https://p3-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/4b14ba20de584e908d2e622a9a0d237c~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5LqU5Y-35Y6C5oi_:q75.awebp?rk3s=f64ab15b&x-expires=1734923281&x-signature=IkykC1FIer//Lqj/OA3TYgq2Dww=" alt="image.png"></p><p><strong>物理层</strong></p><ol><li>定义：物理层主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。它的主要作用是传输比特流（就是由 1、0 转化为电流强弱来进行传输，到达目的地后在转化为 1、0，也就是我们常说的数模转换与模数转换）。</li></ol><p><strong>数据链路层</strong></p><ol><li>定义：数据链路层主要将从物理层接收的数据进行 MAC 地址（网卡的地址）的封装与解封装。常把这一层的数据叫做帧。在这一层工作的设备是交换机，数据通过交换机来传输时，会根据数据中包含的 MAC 地址信息进行转发，实现不同设备之间的通信。以太网协议、PPP 协议等。以太网协议是最常见的数据链路层协议之一，它规定了如何在局域网中传输数据帧。PPP 协议则常用于广域网连接中，实现数据的可靠传输。</li></ol><p><strong>网络层</strong></p><ol><li>定义：网络层主要将从下层接收到的数据进行 IP 地址的封装与解封装。在这一层工作的设备是路由器，它根据 IP 地址将数据包从一个网络转发到另一个网络，实现不同网络之间的通信。IP 协议、ICMP 协议等。IP 协议是网络层的核心协议，它规定了如何给网络中的设备分配 IP 地址，以及如何将数据包从源地址传输到目的地址。ICMP 协议用于在 IP 网络中发送控制消息，例如报告错误或进行网络诊断。</li></ol><p><strong>传输层</strong></p><ol><li>定义：传输层定义了一些传输数据的协议和端口号，如 TCP 和 UDP。它主要是将从下层接收的数据进行分段和重组，为应用层提供端到端的可靠数据传输服务。例如，当你在浏览器中访问一个网页时，浏览器和服务器之间的通信就是通过传输层的协议来实现的。TCP（Transmission Control Protocol，传输控制协议）是一种面向连接的、可靠的传输层协议。它通过三次握手建立连接，在数据传输过程中进行流量控制和拥塞控制，确保数据的准确无误传输。UDP（User Datagram Protocol，用户数据报协议）是一种无连接的、不可靠的传输层协议。它不保证数据的可靠传输，但具有传输速度快、开销小的优点，适用于一些对实时性要求较高的应用，如视频会议、在线游戏等。</li></ol><p><strong>会话层</strong></p><ol><li>定义：会话层主要负责建立、管理和终止表示层实体之间的通信会话。它通过在通信双方之间建立、维护和管理会话，确保数据的有序传输。例如，在进行远程登录时，会话层负责建立和管理用户与远程服务器之间的会话，确保用户的输入和服务器的响应能够正确地交互。会话层的主要功能包括会话建立、会话管理和会话终止。在会话建立阶段，通信双方通过协商确定会话的参数，如会话标识符、加密方式等。在会话管理阶段，会话层负责维护会话的状态，确保数据的正确传输和接收。在会话终止阶段，会话层负责安全地终止会话，释放资源。</li></ol><p><strong>表示层</strong></p><ol><li>定义：表示层主要负责数据的表示、加密和压缩等功能。它将应用层的数据转换为适合网络传输的格式，并进行加密和压缩等处理，以提高数据的安全性和传输效率。例如，当你在网上购物时，你的信用卡信息需要进行加密处理，以确保信息的安全传输。表示层就是负责这种加密和转换的工作。表示层的主要功能包括数据格式转换、数据加密和数据压缩。在数据格式转换方面，它可以将不同格式的数据转换为统一的网络标准格式，以便在不同的系统之间进行通信。在数据加密方面，它可以使用各种加密算法对数据进行加密，保护数据的安全性。在数据压缩方面，它可以对数据进行压缩，减少数据的传输量，提高传输效率。</li></ol><p><strong>应用层</strong></p><ol><li>定义：应用层是 OSI 模型的最高层，它直接面向用户，为用户提供各种网络应用服务。例如，电子邮件、文件传输、网页浏览等都是应用层的服务。应用层通过调用下层的服务，实现各种具体的网络应用功能。HTTP（HyperText Transfer Protocol，超文本传输协议）是用于在 Web 上传输超文本的协议。SMTP（Simple Mail Transfer Protocol，简单邮件传输协议）用于发送电子邮件。FTP（File Transfer Protocol，文件传输协议）用于在网络上传输文件等。 总之，OSI 七层网络协议模型为计算机网络的通信提供了一个标准化的框架，使得不同的计算机系统和网络设备能够相互通信和协作。每一层都有其特定的功能和协议，它们共同构成了一个完整的网络通信体系。</li></ol><h3 id="2-WebSocket"><a href="#2-WebSocket" class="headerlink" title="2. WebSocket"></a>2. WebSocket</h3><p>WebSocket 是一种在单个 TCP 连接上进行全双工通信的协议。它使得客户端和服务器之间可以实现实时、双向的数据传输。</p><p><img src="https://p3-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/c3933ff01fa94c51b9a0a1a1008fb706~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5LqU5Y-35Y6C5oi_:q75.awebp?rk3s=f64ab15b&x-expires=1734923281&x-signature=I2pCsBywY8c0pBK5WAg7ogJdAko=" alt="image.png"></p><h4 id="2-1-工作原理"><a href="#2-1-工作原理" class="headerlink" title="2.1 工作原理"></a>2.1 工作原理</h4><p>WebSocket是一种独立的协议，用于在单个TCP连接上提供全双工通信。它通过HTTP&#x2F;HTTPS协议完成初始握手，然后升级到WebSocket协议。</p><p><strong>握手过程</strong></p><ul><li>• 客户端发送一个HTTP请求给服务器，包含特殊的WebSocket头信息，用于请求协议升级（从HTTP&#x2F;HTTPS升级到WebSocket协议）。</li><li>• 服务器接收到这个请求后，检查头信息并确认是否同意升级。如果同意，它会返回一个带有101状态码的HTTP响应，表示协议切换（Switching Protocols）。</li></ul><p><strong>通信过程</strong></p><ul><li>• 在握手成功后，客户端和服务器通过WebSocket协议持久连接进行通信。此连接将保持打开状态，双向数据流可以在任一端发起，而不需要每次发消息都重新建立连接。WebSocket的消息是帧格式的，分为数据帧和控制帧。</li></ul><h4 id="2-2-特点"><a href="#2-2-特点" class="headerlink" title="2.2 特点"></a>2.2 特点</h4><ul><li>• <strong>双向通信</strong>：支持客户端和服务器之间的全双工通信。</li><li>• <strong>低延迟</strong>：适合要求低延迟的实时应用，如在线聊天、多人游戏。</li><li>• <strong>数据帧格式</strong>：WebSocket协议规定了消息的帧格式，包括控制帧和数据帧。</li></ul><h4 id="2-3-适用场景"><a href="#2-3-适用场景" class="headerlink" title="2.3 适用场景"></a>2.3 适用场景</h4><ol><li>实时聊天应用：WebSocket 非常适合实时聊天应用，用户可以即时发送和接收消息，无需不断刷新页面。聊天消息可以实时推送给所有在线用户，提供良好的交互体验。</li><li>在线游戏：在在线游戏中，需要实时传输玩家的操作和游戏状态。WebSocket 可以实现低延迟的通信，确保玩家能够及时响应游戏中的变化。</li><li>股票行情和金融数据：对于股票行情和金融数据的实时更新，WebSocket 可以提供快速的数据传输，使投资者能够及时了解市场动态。</li><li>协作工具：如在线文档编辑、实时绘图等协作工具需要实时同步用户的操作。WebSocket 可以实现多个用户之间的实时协作，提高工作效率。</li><li>物联网（IoT）：在物联网应用中，设备需要实时向服务器发送数据并接收指令。WebSocket 可以为物联网设备提供可靠的通信渠道，实现远程监控和控制。</li></ol><h3 id="3-Server-Sent-Events-SSE"><a href="#3-Server-Sent-Events-SSE" class="headerlink" title="3. Server-Sent Events (SSE)"></a>3. Server-Sent Events (SSE)</h3><h4 id="3-1-工作原理"><a href="#3-1-工作原理" class="headerlink" title="3.1 工作原理"></a>3.1 工作原理</h4><p>Server-Sent Events (SSE) 是一种在客户端和服务器之间传递事件的机制，主要用于<strong>服务器向客户端推送实时数据</strong>。<strong>SSE并不是一种协议而是一种机制</strong>，这也是区别于WebSocket的地方之一。</p><p>虽然SSE并没有像WebSocket那样定义出一个独立的协议，但它却通过标准的HTTP协议实现了类似长连接的功能。SSE规定了特定的<strong>MIME类型和数据格式</strong>，来让服务器持续发送数据流。</p><p><img src="https://p3-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/184fbdff2937467b901993bd34350b96~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5LqU5Y-35Y6C5oi_:q75.awebp?rk3s=f64ab15b&x-expires=1734923281&x-signature=qCf6DSSspZxXzw3LkLbGoui5QXQ=" alt="image.png"></p><h4 id="3-2-特点"><a href="#3-2-特点" class="headerlink" title="3.2 特点"></a>3.2 特点</h4><p>\1. <strong>使用标准HTTP协议</strong></p><p>SSE在现有的HTTP&#x2F;HTTPS协议之上构建，不需要额外的协议或端口。客户端向服务器发送一个普通HTTP请求，服务器响应该请求，并持续发送数据。 如下图所示：</p><p><img src="https://p3-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/075669e9968d4c36b98f70b2570a4861~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5LqU5Y-35Y6C5oi_:q75.awebp?rk3s=f64ab15b&x-expires=1734923281&x-signature=0lGOiKE8nBvzb6oLA/hue27lRx4=" alt="image.png"></p><p>\2. <strong>特定的MIME类型</strong></p><p>在SSE中，服务器的响应内容类型必须是 <code>text/event-stream</code>，这告诉浏览器或者客户端这是一个SSE数据流。 如下图所示：</p><p><img src="https://p3-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/204d08548ec24c869d76cbf91c11ea3f~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5LqU5Y-35Y6C5oi_:q75.awebp?rk3s=f64ab15b&x-expires=1734923281&x-signature=ZOSJ9TZHvGudhbOvsiDyafT9h4I=" alt="image.png"></p><p>\3. <strong>单向通信</strong></p><p>SSE是一种单向通信方式，即服务器推送数据到客户端，客户端通常只是接收和处理数据，不向服务器发送响应的数据流。需要额外进行双向通信时，可以通过Ajax等其他技术辅助手段实现。</p><p>\4. <strong>自动重连和事件流ID</strong>（Last-Event-ID）</p><p>SSE具有自动重连功能。如果连接中断，浏览器会自动重新连接，并且可以通过 <code>Last-Event-ID</code> 头来继续从断开点接收数据。</p><p><img src="https://p3-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/22664beed55d464a8552d6649c30ece4~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5LqU5Y-35Y6C5oi_:q75.awebp?rk3s=f64ab15b&x-expires=1734923281&x-signature=7BmGc4RND6Cv0Jt2V9QjEbGRCQQ=" alt="image.png"></p><h4 id="3-3-适用场景"><a href="#3-3-适用场景" class="headerlink" title="3.3 适用场景"></a>3.3 适用场景</h4><ol><li>实时通知：SSE 可以用于实现实时通知，如邮件通知、系统警报等。当有新的通知时，服务器可以立即将通知推送给客户端，用户无需手动刷新页面即可获取最新的通知。</li><li>股票行情和金融数据：与 WebSocket 类似，SSE 也可以用于实时更新股票行情和金融数据。服务器可以将最新的股票价格、指数等数据推送给客户端，让用户能够及时了解市场动态。</li><li>日志监控：在服务器端进行日志监控时，可以使用 SSE 将日志信息实时推送给客户端。这样，管理员可以在浏览器中实时查看服务器的日志，及时发现和解决问题。</li><li>社交网络更新：社交网络应用可以使用 SSE 来实时推送新的动态、消息和通知。用户可以在不刷新页面的情况下获取最新的社交网络更新。</li></ol><h2 id="三、-豆包为什么选择SSE而不是websocket的呢"><a href="#三、-豆包为什么选择SSE而不是websocket的呢" class="headerlink" title="三、 豆包为什么选择SSE而不是websocket的呢?"></a>三、 豆包为什么选择SSE而不是websocket的呢?</h2><p>SSE建立在已有的HTTP协议之上，这是Web开发中最常用和最成熟的协议之一。以下是这两者各个维度的比较</p><table><thead><tr><th>比较类别</th><th>Server-Sent Events（SSE）</th><th>WebSocket</th></tr></thead><tbody><tr><td>通信模式</td><td>单向，服务器向客户端发送数据</td><td>双向，客户端和服务器可互相发送数据</td></tr><tr><td>连接建立</td><td>基于 HTTP 协议，客户端发起特殊请求，服务器响应</td><td>通过握手协议建立全双工连接</td></tr><tr><td>适用场景</td><td>适用于单向的服务器推送场景，如实时通知、股票行情等</td><td>适用于双向通信的实时应用，如在线游戏、实时协作等</td></tr><tr><td>重连机制</td><td>如果连接中断，客户端自动尝试重新连接</td><td>如果连接中断，客户端可尝试重新连接</td></tr><tr><td>数据传输格式</td><td>事件流格式，每个事件由事件类型和数据组成</td><td>可以是文本数据或二进制数据</td></tr><tr><td>复杂性</td><td>相对简单，基于 HTTP 协议，无需处理复杂的双向通信状态</td><td>相对复杂，需要处理更多协议细节和状态管理</td></tr><tr><td>浏览器支持</td><td>广泛支持</td><td>广泛支持</td></tr><tr><td>协议开销</td><td>通常较小，因为基于 HTTP 协议且单向通信</td><td>相对较大一些，由于要建立全双工连接和处理更多状态</td></tr><tr><td>服务器资源占用</td><td>一般情况下相对较低，因为主要是单向推送</td><td>可能较高，因为需要处理双向通信和更多的连接状态变化</td></tr><tr><td>安全性</td><td>依赖于底层 HTTP 的安全机制</td><td>可以使用加密等安全措施，与 HTTP 类似但需额外配置</td></tr><tr><td>开发难度</td><td>对于简单的服务器推送场景较容易开发</td><td>双向通信场景下开发难度相对较高，需要处理更多复杂情况</td></tr><tr><td>与代理服务器兼容性</td><td>通常较好，因为基于 HTTP 协议，与常见代理服务器兼容性高</td><td>可能会遇到一些代理服务器不兼容的情况，需要进行额外配置</td></tr></tbody></table><p>综上所述，豆包选择了SSE而不是Websocket。</p><h2 id="四、-总结"><a href="#四、-总结" class="headerlink" title="四、 总结"></a>四、 总结</h2><p>WebSocket和Server-Sent Events (SSE) 都是实现长连接、实时通信的有效技术，各有优劣。WebSocket适合需要低延迟、双向通信的应用场景，如聊天应用、在线游戏和实时协作工具。SSE则更适用于单向数据推送场景，是一种简单而有效的服务器推送技术，非常适用于各种需要实时更新的应用场景，如网页对话、新闻实时更新、股票行情和实时投票结果展示，它基于 HTTP 协议，具有自动重连和事件流格式等特点，使得客户端能够轻松地接收服务器推送的信息。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;实时通信的关键差异解析&quot;&gt;&lt;a href=&quot;#实时通信的关键差异解析&quot; class=&quot;headerlink&quot; title=&quot;实时通信的关键差异解析&quot;&gt;&lt;/a&gt;实时通信的关键差异解析&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;文章介绍了 OSI 七层网络协议模型相关知</summary>
      
    
    
    
    <category term="技术小栈" scheme="http://ai.mak.cn/categories/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/"/>
    
    
    <category term="架构" scheme="http://ai.mak.cn/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>LSTM详解</title>
    <link href="http://ai.mak.cn/posts/5864/"/>
    <id>http://ai.mak.cn/posts/5864/</id>
    <published>2024-09-07T16:00:00.000Z</published>
    <updated>2025-02-11T03:10:23.341Z</updated>
    
    <content type="html"><![CDATA[<p>咱们简单从 what、why、how三方面进行介绍~</p><p><strong>what：一句话介绍</strong></p><p>咱们一句话介绍：LSTM，全名是「长短期记忆网络」（Long Short-Term Memory），是一种特殊的人工神经网络，主要用来处理和预测时间序列数据（就是那些有时间顺序的数据，比如天气预报、股市行情等）。</p><p><strong>why：为什么需要 LSTM</strong></p><p>其次，咱们要明白，为什么需要LSTM。</p><p>传统的神经网络在处理时间序列数据时有个很大的问题：它们记不住长期的依赖关系。举个例子，如果你在看一部电视剧，前几集提到的一个重要线索在后面几集才会揭示它的意义。普通神经网络就像是有点健忘的观众，只能记住最近几集的内容，早前的线索都忘了。而LSTM就像是一个记性很好的观众，它能够记住前面提到的重要细节，并在需要的时候利用这些信息。</p><p><strong>how：LSTM 怎么做到</strong></p><p>LSTM 是怎么做到的？</p><p>LSTM 通过一个巧妙的设计，让网络能够记住之前的信息，并且在合适的时候把这些信息传递下去。具体来说，LSTM 有几个特殊的「门」（gate）来控制信息的流动：</p><p><strong>1. 遗忘门（Forget Gate）</strong>：决定要忘记哪些信息。比如，不重要的剧情细节可以被遗忘。</p><p><strong>2. 输入门（Input Gate）</strong>：决定要记住哪些新的信息。比如，新出现的重要线索要记住。</p><p><strong>3. 输出门（Output Gate）</strong>：决定输出哪些信息。比如，根据前面的情节做出预测或解释当前情节。</p><p>通过这三个门的控制，LSTM 能够在时间序列数据中选择性地记住和忘记信息，从而在需要的时候准确地做出预测或分类。</p><p><strong>一个简单的例子</strong></p><p>想象一下，你在学习一门语言。刚开始学的时候，你会记住很多新的单词和语法（输入门打开），但随着学习的深入，你会逐渐忘记那些不常用的单词和语法（遗忘门打开）。当你在用这门语言交流时，你会根据上下文选择性地使用你记住的单词和语法（输出门打开）。</p><p>LSTM 就像是这样一个学习过程，能够灵活地记住重要信息并在需要的时候使用这些信息。</p><h2 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h2><h3 id="数学原理与公式推导"><a href="#数学原理与公式推导" class="headerlink" title="数学原理与公式推导"></a>数学原理与公式推导</h3><p>LSTM的核心是通过引入不同的“门”机制来控制信息的流动。这些“门”包括遗忘门、输入门和输出门。</p><h4 id="遗忘门"><a href="#遗忘门" class="headerlink" title="遗忘门"></a>遗忘门</h4><p>遗忘门决定了哪些信息需要丢弃。它的输出是一个介于0和1之间的向量，表示每个单元状态应该保留多少信息。</p><h4 id="输入门"><a href="#输入门" class="headerlink" title="输入门"></a>输入门</h4><p>输入门决定了哪些新的信息需要存储到单元状态中。</p><p>接着，会生成候选单元状态，它表示可以加入到单元状态中的新信息。</p><h4 id="更新单元状态"><a href="#更新单元状态" class="headerlink" title="更新单元状态"></a>更新单元状态</h4><p>通过遗忘门和输入门来更新单元状态。</p><h4 id="输出门"><a href="#输出门" class="headerlink" title="输出门"></a>输出门</h4><p>输出门决定当前单元状态的哪部分需要输出，并且通过一个激活函数（通常是tanh）处理后的结果作为输出。</p><blockquote><p>公式说明：</p><ul><li>：当前时刻的输入。</li><li>：前一时刻的隐状态。</li><li>：当前时刻的单元状态。</li><li>：前一时刻的单元状态。</li><li>：当前时刻的候选单元状态。</li><li>：遗忘门的激活值。</li><li>：输入门的激活值。</li><li>：输出门的激活值。</li><li>：表示sigmoid激活函数。</li><li>：表示tanh激活函数。</li><li>：权重矩阵。</li><li>：偏置向量。</li></ul></blockquote><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p><strong>1. 输入预处理</strong>：</p><ul><li>取当前时刻的输入 和前一时刻的隐状态 。</li></ul><p><strong>2. 计算遗忘门</strong>：</p><ul><li>使用 和 计算遗忘门 。</li><li></li></ul><p><strong>3. 计算输入门</strong>：</p><ul><li>使用 和 计算输入门 。</li><li>。</li></ul><p><strong>4. 计算候选单元状态</strong>：</p><ul><li>计算新的候选单元状态 。</li><li>。</li></ul><p><strong>5. 更新单元状态</strong>：</p><ul><li>根据遗忘门和输入门的结果更新单元状态 。</li><li>。</li></ul><p><strong>6. 计算输出门</strong>：</p><ul><li>使用 和 计算输出门 。</li><li>。</li></ul><p><strong>7. 计算当前时刻的隐状态</strong>：</p><ul><li>通过输出门的结果和更新后的单元状态计算当前时刻的隐状态 。</li><li>。</li></ul><p>通过遗忘门、输入门和输出门的机制，LSTM能够有效地记住重要信息，忘记不必要的信息，从而在处理长时间依赖的序列数据时表现出色。每一个时间步的计算过程相对复杂，但通过这些步骤，LSTM可以在保持长期记忆和处理当前输入之间找到平衡。</p><h2 id="一个完整案例"><a href="#一个完整案例" class="headerlink" title="一个完整案例"></a>一个完整案例</h2><p>这里，咱们给到大家一个完整的、详细的LSTM应用示例。</p><p>这个案例中，使用电力消费数据集，该数据集包含自2011年开始的每小时电力消耗数据。目标是根据历史数据预测未来的电力消耗。</p><p>整个代码是完整的，大家可以粘贴在自己的编译器中进行调试，同时也做了很完整的注释供大家学习~</p><h3 id="数据集下载与预处理"><a href="#数据集下载与预处理" class="headerlink" title="数据集下载与预处理"></a>数据集下载与预处理</h3><p>大家可后台回复，“数据集”即可获取所有的数据集~</p><p>使用 <code>pandas</code> 处理数据。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"># 下载并读取数据</span><br><span class="line">df = pd.read_csv(&#x27;LD2011_2014.txt&#x27;, sep=&#x27;;&#x27;, index_col=0, parse_dates=True, decimal=&#x27;,&#x27;)</span><br><span class="line"></span><br><span class="line"># 选取其中一个列作为示例</span><br><span class="line">df = df[&#x27;MT_001&#x27;]</span><br><span class="line"></span><br><span class="line"># 处理数据：将数据按小时取平均值，并填补缺失值</span><br><span class="line">df = df.resample(&#x27;H&#x27;).mean().fillna(method=&#x27;ffill&#x27;)</span><br><span class="line"></span><br><span class="line"># 查看数据</span><br><span class="line">print(df.head())</span><br></pre></td></tr></table></figure><h3 id="创建时间序列数据"><a href="#创建时间序列数据" class="headerlink" title="创建时间序列数据"></a>创建时间序列数据</h3><p>创建时间序列数据，以便可以将其输入到LSTM模型中。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># 创建时间序列数据</span><br><span class="line">def create_dataset(data, time_step=1):</span><br><span class="line">    X, Y = [], []</span><br><span class="line">    for i in range(len(data) - time_step - 1):</span><br><span class="line">        a = data[i:(i + time_step)]</span><br><span class="line">        X.append(a)</span><br><span class="line">        Y.append(data[i + time_step])</span><br><span class="line">    return np.array(X), np.array(Y)</span><br><span class="line"></span><br><span class="line"># 使用过去24小时的数据预测下一小时的消耗</span><br><span class="line">time_step = 24</span><br><span class="line">data = df.values</span><br><span class="line"></span><br><span class="line"># 归一化数据</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler(feature_range=(0, 1))</span><br><span class="line">data = scaler.fit_transform(data.reshape(-1, 1))</span><br><span class="line"></span><br><span class="line">X, Y = create_dataset(data, time_step)</span><br><span class="line"></span><br><span class="line"># 划分训练集和测试集</span><br><span class="line">train_size = int(len(X) * 0.7)</span><br><span class="line">test_size = len(X) - train_size</span><br><span class="line">X_train, X_test = X[0:train_size], X[train_size:len(X)]</span><br><span class="line">Y_train, Y_test = Y[0:train_size], Y[train_size:len(Y)]</span><br><span class="line"></span><br><span class="line"># 重塑数据为 [样本, 时间步, 特征]</span><br><span class="line">X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)</span><br><span class="line">X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)</span><br></pre></td></tr></table></figure><h3 id="构建LSTM模型"><a href="#构建LSTM模型" class="headerlink" title="构建LSTM模型"></a>构建LSTM模型</h3><p>使用 <code>tensorflow</code> 构建并训练LSTM模型。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.keras.models import Sequential</span><br><span class="line">from tensorflow.keras.layers import Dense, LSTM</span><br><span class="line"></span><br><span class="line"># 构建LSTM模型</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))</span><br><span class="line">model.add(LSTM(50, return_sequences=False))</span><br><span class="line">model.add(Dense(25))</span><br><span class="line">model.add(Dense(1))</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;mean_squared_error&#x27;)</span><br><span class="line"></span><br><span class="line"># 训练模型</span><br><span class="line">model.fit(X_train, Y_train, batch_size=64, epochs=10, validation_data=(X_test, Y_test))</span><br></pre></td></tr></table></figure><h3 id="预测和可视化结果"><a href="#预测和可视化结果" class="headerlink" title="预测和可视化结果"></a>预测和可视化结果</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 预测</span><br><span class="line">train_predict = model.predict(X_train)</span><br><span class="line">test_predict = model.predict(X_test)</span><br><span class="line"></span><br><span class="line"># 反归一化预测结果</span><br><span class="line">train_predict = scaler.inverse_transform(train_predict)</span><br><span class="line">test_predict = scaler.inverse_transform(test_predict)</span><br><span class="line">Y_train = scaler.inverse_transform([Y_train])</span><br><span class="line">Y_test = scaler.inverse_transform([Y_test])</span><br><span class="line"></span><br><span class="line"># 可视化结果</span><br><span class="line">plt.figure(figsize=(14, 8))</span><br><span class="line">plt.plot(df.index[:len(Y_train[0])], Y_train[0], label=&#x27;Training Data&#x27;)</span><br><span class="line">plt.plot(df.index[len(Y_train[0]):len(Y_train[0]) + len(Y_test[0])], Y_test[0], label=&#x27;Test Data&#x27;)</span><br><span class="line">plt.plot(df.index[:len(train_predict)], train_predict, label=&#x27;Train Predict&#x27;)</span><br><span class="line">plt.plot(df.index[len(Y_train[0]):len(Y_train[0]) + len(test_predict)], test_predict, label=&#x27;Test Predict&#x27;)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(&#x27;Date&#x27;)</span><br><span class="line">plt.ylabel(&#x27;Power Consumption&#x27;)</span><br><span class="line">plt.title(&#x27;Electricity Consumption Prediction&#x27;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://mmbiz.qpic.cn/sz_mmbiz_png/kibwfTuPM4licXEYiaiafok1IK1FhiaWMF9Tfsjv3OibfQ5hYPJq3uIiczDSBMax3OKmzBtQsNBgic5NEAgDwSw9umrjqw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><h3 id="模型优化"><a href="#模型优化" class="headerlink" title="模型优化"></a>模型优化</h3><p>可以通过调整模型参数、使用更复杂的架构或更好的优化器来改进模型。</p><p>下面是一些改进模型的建议：</p><ul><li>增加LSTM层的单元数量或层数。</li><li>使用不同的激活函数。</li><li>尝试不同的优化器，如AdamW。</li><li>使用交叉验证进行超参数调优。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">from tensorflow.keras.optimizers import Adam</span><br><span class="line"></span><br><span class="line"># 构建优化后的LSTM模型</span><br><span class="line">model_optimized = Sequential()</span><br><span class="line">model_optimized.add(LSTM(100, return_sequences=True, input_shape=(time_step, 1)))</span><br><span class="line">model_optimized.add(LSTM(100, return_sequences=True))</span><br><span class="line">model_optimized.add(LSTM(100, return_sequences=False))</span><br><span class="line">model_optimized.add(Dense(50))</span><br><span class="line">model_optimized.add(Dense(1))</span><br><span class="line"></span><br><span class="line">optimizer = Adam(learning_rate=0.001)</span><br><span class="line">model_optimized.compile(optimizer=optimizer, loss=&#x27;mean_squared_error&#x27;)</span><br><span class="line"></span><br><span class="line"># 训练优化后的模型</span><br><span class="line">model_optimized.fit(X_train, Y_train, batch_size=64, epochs=20, validation_data=(X_test, Y_test))</span><br><span class="line"></span><br><span class="line"># 预测并可视化结果</span><br><span class="line">train_predict_optimized = model_optimized.predict(X_train)</span><br><span class="line">test_predict_optimized = model_optimized.predict(X_test)</span><br><span class="line"></span><br><span class="line">train_predict_optimized = scaler.inverse_transform(train_predict_optimized)</span><br><span class="line">test_predict_optimized = scaler.inverse_transform(test_predict_optimized)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(14, 8))</span><br><span class="line">plt.plot(df.index[:len(Y_train[0])], Y_train[0], label=&#x27;Training Data&#x27;)</span><br><span class="line">plt.plot(df.index[len(Y_train[0]):len(Y_train[0]) + len(Y_test[0])], Y_test[0], label=&#x27;Test Data&#x27;)</span><br><span class="line">plt.plot(df.index[:len(train_predict_optimized)], train_predict_optimized, label=&#x27;Optimized Train Predict&#x27;)</span><br><span class="line">plt.plot(df.index[len(Y_train[0]):len(Y_train[0]) + len(test_predict_optimized)], test_predict_optimized, label=&#x27;Optimized Test Predict&#x27;)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(&#x27;Date&#x27;)</span><br><span class="line">plt.ylabel(&#x27;Power Consumption&#x27;)</span><br><span class="line">plt.title(&#x27;Optimized Electricity Consumption Prediction&#x27;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://mmbiz.qpic.cn/sz_mmbiz_png/kibwfTuPM4licXEYiaiafok1IK1FhiaWMF9TfgtzzzTKibr4SjFk5devCS3z3XwBZicIQQthNDFSomkibZhLykH2BvVsBA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>通过以上所有的步骤，咱们成功地构建并优化了一个LSTM模型，预测电力消耗，并对结果进行了可视化，更加容易接受~</p><h2 id="模型分析"><a href="#模型分析" class="headerlink" title="模型分析"></a>模型分析</h2><p>这里，咱们从模型的优缺点、以及与相似算法的对比，讨论在什么情况下该算法是优选，什么情况下可以考虑其他算法。</p><h3 id="LSTM-模型-优缺点"><a href="#LSTM-模型-优缺点" class="headerlink" title="LSTM 模型 优缺点"></a>LSTM 模型 优缺点</h3><p><strong>优点</strong></p><p><strong>1. 处理长时间依赖性</strong>：LSTM可以有效地捕捉长时间依赖关系，在序列数据中能够记住和利用远距离的相关信息。</p><p><strong>2. 梯度消失问题</strong>：通过门机制（遗忘门、输入门、输出门），LSTM解决了传统RNN中的梯度消失问题，使得模型在训练时更稳定。</p><p><strong>3. 广泛适用</strong>：适用于各种时间序列数据，包括股票预测、天气预报、自然语言处理等。</p><p><strong>缺点</strong></p><p><strong>1. 计算复杂度高</strong>：LSTM结构复杂，训练时间长，尤其在大数据集上，计算资源消耗较大。</p><p><strong>2. 需要大量数据</strong>：LSTM需要大量的训练数据才能发挥出最佳效果，对小数据集的泛化能力较差。</p><p><strong>3. 参数调优复杂</strong>：LSTM有较多的超参数，模型优化需要进行大量的实验和调优，过程复杂且耗时。</p><h3 id="与相似算法的对比"><a href="#与相似算法的对比" class="headerlink" title="与相似算法的对比"></a>与相似算法的对比</h3><p><strong>LSTM vs. 简单RNN</strong></p><ul><li><strong>优点</strong>：LSTM能更好地处理长时间依赖关系，解决了简单RNN中的梯度消失问题。</li><li><strong>缺点</strong>：LSTM结构比简单RNN复杂，训练时间更长。</li></ul><p><strong>LSTM vs. GRU（门控循环单元）</strong></p><ul><li><strong>优点</strong>：LSTM通过三个门（遗忘门、输入门、输出门）控制信息流动，理论上可以捕捉更复杂的依赖关系。</li><li><strong>缺点</strong>：GRU只有两个门（更新门和重置门），结构较简单，计算量小于LSTM，但在很多实际应用中，GRU性能接近甚至优于LSTM。</li></ul><p><strong>LSTM vs. 一维卷积神经网络（1D-CNN）</strong></p><ul><li><strong>优点</strong>：LSTM适用于序列数据，能捕捉时间上的依赖关系。</li><li><strong>缺点</strong>：1D-CNN通过卷积操作捕捉局部时间特征，计算效率高于LSTM。在一些短时间依赖性较强的数据集上，1D-CNN可能表现更好。</li></ul><h3 id="选择LSTM的情境"><a href="#选择LSTM的情境" class="headerlink" title="选择LSTM的情境"></a>选择LSTM的情境</h3><p><strong>适用场景</strong></p><p><strong>1. 长时间依赖关系</strong>：需要捕捉数据中长期的依赖关系时，如自然语言处理中的句子理解，气象数据中的季节变化。</p><p><strong>2. 序列生成</strong>：生成类似文本、时间序列数据时，LSTM能够很好地建模数据的顺序和依赖关系。</p><p><strong>3. 大数据集</strong>：在有足够多训练数据的情况下，LSTM能充分学习复杂的模式和特征。</p><p><strong>考虑其他算法的情境</strong></p><p><strong>1. 短时间依赖关系</strong>：如果数据的依赖关系主要集中在短时间内，1D-CNN或简单RNN可能更适合。</p><p><strong>2. 计算资源有限</strong>：在计算资源受限的情况下，GRU或1D-CNN的计算效率更高。</p><p><strong>3. 小数据集</strong>：在数据量较小的情况下，较为简单的模型（如ARIMA，简单RNN）可能更适合，避免过拟合。</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>LSTM在处理复杂的长时间序列数据方面表现出色，尤其适合需要捕捉长期依赖关系的任务。</p><p>但是，LSTM 复杂度和计算资源要求较高，需要大量的训练数据。与其他算法相比，LSTM在处理长时间依赖关系上有明显优势，但在短时间依赖关系或计算资源受限的情况下，其他算法如GRU、1D-CNN可能更为优选。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;咱们简单从 what、why、how三方面进行介绍~&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;what：一句话介绍&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;咱们一句话介绍：LSTM，全名是「长短期记忆网络」（Long Short-Term Memory），是一种特殊的人工神经网络，主要用来处</summary>
      
    
    
    
    <category term="AI" scheme="http://ai.mak.cn/categories/AI/"/>
    
    
    <category term="深度学习" scheme="http://ai.mak.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>5公里成绩跑进20分钟！</title>
    <link href="http://ai.mak.cn/posts/4692/"/>
    <id>http://ai.mak.cn/posts/4692/</id>
    <published>2024-08-24T16:00:00.000Z</published>
    <updated>2025-02-11T03:10:23.775Z</updated>
    
    <content type="html"><![CDATA[<h1 id="5公里成绩跑进20分钟！"><a href="#5公里成绩跑进20分钟！" class="headerlink" title="5公里成绩跑进20分钟！"></a>5公里成绩跑进20分钟！</h1><p>5km，在跑者眼里是一个很有意义的路程。</p><p>5km，它不算长，也不算短，是很多跑者从初阶晋级到高阶的一个点。</p><p>唯有突破了5km，才能往更远的距离去跑，实现更大的突破。</p><p>5km，也是很多跑者需要着重训练的一个路程，既可以看出一个人的爆发力，还可以大概预测出你的半马、全马的成绩。</p><p>5km成绩如果能够突破20分钟，是很多业余跑者的梦想。</p><p>一旦5km跑进了20分钟，也就意味着你是业余跑者中的大神般的存在。</p><p><strong>贰</strong></p><p><strong>5km跑进20分，是什么概念？</strong></p><p>也就是意味着，你每公里的配速不能低于4分配速，也就是你的奔跑时速要达到15km&#x2F;h。</p><p>如果能够一直维持在4分配速，那么10km只需要40分钟，半马84分钟，全马2小时48分就能够跑完。</p><p>这在业余跑者中已经算是很高的成就了。</p><p>所以，以此类推，如果想要全马破3小时，你的5km速度就必须要破20分钟！</p><p><strong>叁</strong></p><p>下面介绍三种非常有效的训练方式，只要经过科学系统的训练，想要5km成绩突破20分，是很有希望的。</p><p><strong>1、加强力量训练：</strong></p><p>5km要破20分钟，需要你要有强大的肌肉力量。只有强有力的核心力量以及大小腿力量，你在奔跑的时候才能够完好的控制身体，不至于力量不足导致身体发软。</p><p>很多人在跑步时，往往都会忽视力量训练，认为我只要每天跑就行了。实际上这种认识是错误的。</p><p>在平时，有条件的可以到健身房进行锻炼，腰腹力量，背部力量，腿部力量都要锻炼到。</p><p>没有条件的，也要在家自己练习。比较实用的动作有深蹲、靠墙静蹲、卷腹、平板支撑等。</p><p><strong>2、练好有氧基础：</strong></p><p>想要跑得快，就必须要有足够的有氧能力。</p><p>有氧能力是决定你能跑多远的基础，但凡能够跑得又快又远的人，他的有氧基础都是响当当的。</p><p>在一周时间里，可以花个两三天时间来锻炼有氧基础。</p><p>有氧能力就是指在最大心率的60%强度下奔跑，距离可以控制在10km左右，长期坚持下去，个人的有氧能力会得到很大提升。</p><p><strong>3、提高乳酸阈值：</strong></p><p>想要跑得快，乳酸阈值一定要得到有效提高。</p><p>乳酸阈值是指人体在渐增负荷运动中，血乳酸浓度随运动负荷的渐增而增加，当运动强度达到某一负荷时，血乳酸浓度急剧上升，而在上升的这个起点就是阈值。</p><p>当我们跑得很快的时候，没过多久就会觉得大小腿发酸，就像灌铅了似的，这就是因为你体内的乳酸积累多了，所以就会非常容易感到疲惫。</p><p>而为了跑得更远跑得更快，我们就必须提高自己的乳酸阈值。</p><p>那么，如何才能提高乳酸阈值门槛呢？</p><p><strong>最简单有效的就是间歇跑和法特莱克跑。</strong></p><p>在有氧基础得到有效提高，肌肉力量也足够强大的时候，就可以开始练习间歇跑和冲刺跑了。因为间歇跑和冲刺跑强度都比较大，一星期练一次就够了。</p><p>所为法特莱克跑，是一种加速跑与慢跑交替进行的中长跑训练方法，在跑中插入一系列不定时间、不定距离的加速跑、反复跑甚至快速冲刺，使它们和慢跑或走步交替进行。法特莱克跑是无氧训练中经常用到的一个方法。</p><p>相信经过一段时间的训练，突破5公里成绩能够成功跑进20分钟，也是指日可待的事情。</p><p><strong>事实会证明，所有的辛苦和汗水，都不会白费。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;5公里成绩跑进20分钟！&quot;&gt;&lt;a href=&quot;#5公里成绩跑进20分钟！&quot; class=&quot;headerlink&quot; title=&quot;5公里成绩跑进20分钟！&quot;&gt;&lt;/a&gt;5公里成绩跑进20分钟！&lt;/h1&gt;&lt;p&gt;5km，在跑者眼里是一个很有意义的路程。&lt;/p&gt;
&lt;p&gt;5k</summary>
      
    
    
    
    <category term="跑步" scheme="http://ai.mak.cn/categories/%E8%B7%91%E6%AD%A5/"/>
    
    
    <category term="健康" scheme="http://ai.mak.cn/tags/%E5%81%A5%E5%BA%B7/"/>
    
  </entry>
  
  <entry>
    <title>提升跑步能力，这三项训练缺一不可</title>
    <link href="http://ai.mak.cn/posts/31560/"/>
    <id>http://ai.mak.cn/posts/31560/</id>
    <published>2024-08-10T16:00:00.000Z</published>
    <updated>2025-02-11T03:10:23.776Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://mp.weixin.qq.com/s/DfBvo1-iVbBgpoj1Dfwgyw">https://mp.weixin.qq.com/s/DfBvo1-iVbBgpoj1Dfwgyw</a></p></blockquote><h1 id="提升跑步能力，这三项训练缺一不可"><a href="#提升跑步能力，这三项训练缺一不可" class="headerlink" title="提升跑步能力，这三项训练缺一不可"></a>提升跑步能力，这三项训练缺一不可</h1><p>马拉松世界冠军基普乔格，全名埃利乌德·基普乔格，1984年11月5日出生于肯尼亚西部的裂谷省南迪郡，他的母亲是一位教师，父亲在他刚出生不久就去世了，基普乔格是家里四个孩子中最小的一个。</p><p>据说，基普乔格每天都要跑3公里去上学，因为迟到的学生，要接受老师的体罚。就这样，基普乔格一直跑到16岁，这也不知不觉中锻炼了他跑步的能力。</p><p>2000年，基普乔格结识了肯尼亚的奥运长跑冠军帕特里克·桑(Patrick Sang)。帕特里克·桑和基普乔格住处离得不远，基普乔格很想让帕特里克·桑为自己做一份训练计划。</p><p>而帕特里克·桑一眼就看中了这个跑步的苗子，在几次交流之后，帕特里克·桑就成为了基普乔格的教练。</p><p>而这也开启了属于基普大神的黄金20年时光。</p><p>2019年10月，基普乔格在奥地利维也纳的路拉特公园参加了Ineos 159挑战，再次向两小时的极限发起冲刺。最终以1小时59分40秒完成挑战，成为人类历史上，第一个跑进2小时的马拉松选手。</p><p>虽然这项成绩不被国际田联认可，但基普乔格还是创造了历史，成为人类体育史上的一大亮点。</p><p><strong>二、基普乔格推荐的3项身体素质训练</strong></p><p>我们都以为出生于肯尼亚的基普乔格，天生就是跑步的天才，实际上能够取得今天这样的成就，除了长跑的天赋，就是老天爷赏饭吃之外，也不能缺少他个人的刻苦训练。</p><p>如果我们以为基普乔格，只是靠跑步天分，就能够成为马拉松届的天花板，那么就误解了乔大侠颇为重视的身体素质训练。</p><p>以下分别罗列一下基普乔格推荐并且始终坚持的3项身体素质训练，相信也会对我们自身的跑步训练课有所启发和借鉴。</p><p>正如乔神的教练帕特里克·桑所言：“<strong>心理素质要比身体素质更重要，肯尼亚从不缺才华横溢的苗子，只有心理强大的人才会走的很远。</strong>”。</p><p>从2012年转战马拉松开始， 基普乔格已经驰骋马拉松赛场10年，创造了10年的辉煌，自律和坚持才是基普乔格成功的关键。</p><p><strong>素质训练①：肌肉力量训练</strong></p><p>1、深蹲</p><p>主要用来发展臀部和大腿前侧的力量</p><p>2、弓箭步提膝</p><p>可以模拟跑步发力，增强臀腿肌肉力量</p><p>3、单腿硬拉</p><p>可以增强腘绳肌耐力，增强髋外旋外展肌肉耐力，同时，维持跑步过程中髋关节的稳定性</p><p>4、单腿提踵</p><p>可有效增强脚踝和小腿的肌肉耐力</p><p><strong>素质训练②：核心训练</strong></p><p>1、平板交替抬腿</p><p>可以模拟跑步伸髋动作，增加腹横肌稳定和身体抗旋转的能力</p><p>2、仰卧蹬自行车</p><p>可以增加腹部内外斜肌肌肉耐力，好的跑步姿势，离不开强大的核心肌肉群。</p><p>3、俯身登山跑</p><p>可以模拟跑步发力，提升腹部肌肉和腰大肌肌肉耐力</p><p>4、摸膝卷腹</p><p>可以很好地刺激到腹部肌肉群，增强核心肌肉能力</p><p><strong>素质训练③：跑步专项技术</strong></p><p>1、垫歩提膝</p><p>可有效提升髋关节灵活性</p><p>2、折叠腿</p><p>学会脚跟拉向臀部，增大跑步的车轮半径</p><p>3、直腿跑</p><p>学会用髋关节发力，脚掌落地下压并快速提拉</p><p>4、后蹬跑</p><p>可以提升肌肉弹性以及爆发力，增强腿部韧带刚性，可以有效增大步幅</p><p>基普乔格的马拉松生涯并没有划上句号，正如他所说：<strong>记录就是应该被打破的。</strong></p><p>希望乔大侠能够继续挑战新的世界记录。即使无法再创造之前的运动传奇，也不会影响我们对这位伟大运动员的尊重和热爱。</p><p>乔大侠的成功，与严格的自律和坚持是分不开的，最后以他的一句名言结尾，希望我们也能够通过适合自己强度的训练，能够有所收获。</p><p><strong>“人人皆可超越自己的极限！”</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/DfBvo1-iVbBgpoj1Dfwgyw&quot;&gt;https://mp.weixin.qq.com/s/DfBvo1-iVbBgpoj1Dfwgyw&lt;/a&gt;&lt;/p&gt;
&lt;/bloc</summary>
      
    
    
    
    <category term="跑步" scheme="http://ai.mak.cn/categories/%E8%B7%91%E6%AD%A5/"/>
    
    
    <category term="健康" scheme="http://ai.mak.cn/tags/%E5%81%A5%E5%BA%B7/"/>
    
  </entry>
  
  <entry>
    <title>一米奇迹：怎样让你的工位更健康？</title>
    <link href="http://ai.mak.cn/posts/7721/"/>
    <id>http://ai.mak.cn/posts/7721/</id>
    <published>2024-08-02T16:00:00.000Z</published>
    <updated>2025-02-11T03:10:23.704Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>节选自：得到头条 | 377期</p></blockquote><p>今天，我将从两个话题出发，为你提供知识服务。第一个是，全国第36个爱国卫生健康月活动落下帷幕。第二个是，2024年一季度，可可价格大幅上涨。</p><p>先来看今天的第一条。刚刚结束的4月，是全国第36个爱国卫生健康月，今年的主题是“健康城镇，健康体重”。很多地方都组织了相关的活动，包括倡导绿色出行、推广卫生习惯，还有针对上班族的运动建议，等等。</p><p>但是，你也知道，这些建议对特别忙的职场人来说，落实起来多少有点难度。你在办公室里度过了最多的时间，但这部分时间的健康体验，往往很难保证。</p><p>因此今天，借着这个话题，我们就说几个，在办公室就能执行的健康方案。</p><p>这些方法来自斯坦福大学医学院的神经科学家安德鲁·休伯曼。他的主要研究课题之一，就是借用神经科学的原理，给上班族设计办公室里的健康方案。休伯曼还把这些内容做成了一个播客，叫休伯曼实验室，有50多万名用户。</p><p>我们给这些方案起了个名字，叫一米奇迹。也就是，在你工位一米之内的范围就能完成，并且效果不错的方法。掌握这些方法既能提升你的工作体验，让人身心变得更健康，同时也能提升工作效率。好，咱们正式开始。</p><p>先介绍个背景信息，休伯曼教授从神经科学的角度，把一天分为三个阶段，这三个阶段你身体内部的激素水平不同，工作状态也不同。</p><p>第一个阶段，是从起床开始算起的7到8小时，也就是从早上到下午的这段时间。这时你体内的多巴胺、去甲肾上腺素、皮质醇的含量都在一个比较高的状态。你整个人也高度专注，适合做逻辑分析之类的工作。咱们可以把这个阶段叫做“分析期”。</p><p>第二个阶段，是起床后的8到16个小时，也就是下午和傍晚。这时你体内的血清素等神经调节剂含量会提高，这些激素会提高大脑的抽象思维能力，适合做一些创造性的工作。咱们可以把这个阶段叫做“创意期”。</p><p>第三个阶段，就是睡前和睡眠阶段，这个时候，最关键的就是好好休息。</p><p>咱们的工作时间主要集中在前两个阶段，也就是，分析阶段和创意阶段。休伯曼教授说，你可以针对性地做一些调节，让这两个阶段的工作更健康。这些调节主要分三种。</p><p>第一种，是调节光照。</p><p>按照上面的分类，<strong>在第一阶段，也就是起床后的7到8小时，你应该尽可能地照亮自己的工作环境，促进体内多巴胺、去甲肾上腺素和皮质醇的释放。</strong> 这能让你更清醒、更专注。假如你在室内工作，最好的座位是自然光线充足的窗户边，而且最好打开窗户，因为玻璃会过滤掉自然光中50%的蓝光，而蓝光对神经的唤醒作用是非常重要的。假如不在窗边，你也要让自己的办公环境足够亮。并且，注意，要打开头顶的灯。<strong>头顶的灯光会直接刺激你眼睛里的一组神经元细胞，叫做“黑质神经节细胞”，这可以让你的大脑更敏锐。</strong></p><p>同时，你还可以通过一个小调整，帮自己保持这种敏锐。这就是，把电脑屏幕，调高一点。视觉焦点，也就是眼神对焦的地方，会对神经产生不同的影响。当你向上看时，神经会变得兴奋，向下看时，你会变得平静甚至犯困。因此，<strong>你可以把电脑高度调高，调到和眼睛平齐，或者更高一点的地方，让自己的视觉焦点在斜上方。这能帮助你保持专注。</strong></p><p>而到了第二阶段，也就是下午3点之后，这时你的抽象思考开始活跃，适合做一些创意性的工作。这时，你需要降低光照强度，可以关掉头顶的主灯，留一些环境灯。光线稍微暗一点，有利于体内血清素的释放，更适合去做一些创造性的工作。</p><p>总之，光照这方面，其实不复杂，主要就是遵循自然规律，早上强，下午弱，天黑就休息。</p><p>休伯曼说的第二种，是调节空间范围。这里他引用很有名的“大教堂效应”，也就是，建筑的高度，会对人的思考模式产生影响。<strong>在天花板低的空间，人更善于处理具象的东西，也就是更有分析能力，而在天花板高的空间里，人更善于处理抽象的东西，也就是更有创意。</strong></p><p>因此，还是按照前面的阶段，起床后的7到8小时，你可以在一个小空间里干活，保持高度的专注力，处理需要逻辑分析的工作。假如环境不允许，比如你就是得处在一个空旷嘈杂的环境里，那么休伯曼说，你可以人为地给自己创造一个小空间。他观察到，斯坦福附近有很多在咖啡厅工作和学习的人，会穿帽衫，戴帽子，这就是人为地给自己创造一个低天花板的小空间。</p><p>而到了第二个阶段，创意工作期，你就可以找一个空间大的地方，去处理偏抽象的工作。</p><p>同时，休伯曼还提到一个因素，叫双耳频率。也就是两只耳朵同时听一段声音，但两只耳朵听到的频率有所不同。当你听这种双耳频率的时候，大脑会慢慢调节出一种特定的专注状态。休伯曼说，听30分钟左右的40赫兹双耳频率，对工作的效果最好。相关的音频网上就有，你可以找来试试看。</p><p>最后咱们接着来看休伯曼说的第三种方法，是调节身体姿势。</p><p>这个方法不算新。关于坐着办公好，还是站着办公好，咱们之前也说过，单独采用哪种姿势，都不如交替着来好，一会儿站着，一会儿坐着。有研究指出，<strong>假如每天有一半以上的时间站着工作，就可以减缓脖子和肩膀的疼痛，改善驼背，并且能让你燃烧更多的卡路里。</strong></p><p>不过，这都是从身体健康层面来理解这个问题，休伯曼提醒，这对大脑的效率也有所影响。人在躺着的时候，警觉性是最低的，坐着次之，而当你站起来或者动起来的时候，大脑中的“蓝斑神经元”会变得活跃，它能促进多巴胺和肾上腺素的释放，让我们变得更加警觉。因此，站着办公和坐着办公五五开，比如半个小时交换一次，效果是最好的。另外，尤其要注意的一点是，休伯曼说，当你站着的时候，要注意保持独立，不要靠在桌子上。</p><p>好，以上就是休伯曼提供的行动清单。简单总结一下，在上午和中午的工作中，你可以打开顶灯，把显示器抬高，在小空间里办公。假如想更专注，你可以戴上帽子，听点儿双耳频率。下午和傍晚，你可以把光线调暗，在大空间里办公。同时，一天中，你最好时常站起来，保证有一半的时间站着办公。最后，也祝你有一个高效健康的办公空间。</p><p>再来看今天的第二条。最近，可可豆又涨价了。就在第一季度，美国可可豆期货的价格突破一万美元，即便近期有回落的迹象，也稳定在9700美元&#x2F;吨左右。英国可可豆期货的价格也同样上涨，最高时8672英镑&#x2F;吨，创下历史新高。根据“彭博社”的报道，从20世纪80年代以来，可可豆的交易价格基本保持在3500美元&#x2F;吨左右。而在今年第一季度，价格却涨了好几倍。</p><p>可可豆涨价会带来哪些影响？</p><p>第一，巧克力可能会涨价。比如，瑞士的巧克力品牌瑞士莲，去年上半年价格就上涨了9%左右。再比如，北美最大的巧克力及糖果制造商好时，2023年第三季度的价格同比上涨了11%左右。再比如，今年，雀巢、费列罗等国际知名巧克力品牌都陆续宣布涨价计划。</p><p>第二，未来巧克力的包装尺寸可能会越来越小，可可的纯度可能也会越来越低。根据“大洋网”的报道，在人均巧克力消费排名全球第一的瑞士，2023年瑞士人均购买的巧克力是11公斤，跟2022年相比有所下降。再比如，根据美国糖果协会的数据显示，2023年，美国的巧克力销量，跟2022年比萎缩了5.3%。换句话说，消费者对巧克力价格的反应很敏感。因此，为了保持市场竞争力，很多品牌开始从包装着手，也就是通过更小的包装，降低价格来维持销量。</p><p>第三，可可豆价格持续上涨，可能会导致可可添加剂产业增长。说白了，就是给可可脂找平替。比如，代可可脂。原来，代可可脂因为含有反式脂肪酸，在市面上不太受欢迎。但由于这次的可可豆危机，代可可脂又出现了翻红的迹象。</p><p>但话说回来，为什么这两年可可豆一直在涨价呢？</p><p>表面上看，是因为极端天气。也就是从2023年5月开始的厄尔尼诺现象，导致可可豆产量下降。再加上可可豆的种植地很集中。目前全世界75%的可可豆，集中在非洲的加纳、喀麦隆、科特迪瓦以及尼日利亚。这就好比鸡蛋都装在同一个篮子里，抗风险能力自然有限。</p><p>但是，假如深入观察，影响可可豆价格的，还有另一个更关键的原因，这就是金融因素。</p><p>作为全球交易量大的农产品之一，可可豆也是种期货。由于全球灾害性天气频发，再加上，可可树本身种植3到5年后才能结果。因此，欧美国家的期货市场就预测可可豆的产量很难在短期内提高，价格也会持续上涨。</p><p>比如，根据《金融时报》的报道，对冲基金们已经在伦敦和纽约的可可期货合约中，投入了将近87亿美元，主要就是押注未来可可豆的价格会继续上涨。</p><p>再比如，根据“彭博社”的报道，还有一些公司会采取“套期保值”策略，也就是在买进可可豆本身的同时，会买入同等数量的期货合约，来降低这笔货物的赔钱风险。</p><p>这些金融市场的行为，会进一步放大气候变化对可可豆价格造成的影响。</p><p>之前，薛兆丰老师在他的经济学课中就讲过，对未来天气变化的趋势，期货市场比国家气象局还要敏感。其中的道理就是，对气候的预测，会影响对农产品产量的预测，从而直接影响期货市场对价格的预测。</p><p>你看，说到这，我们又回到了经济学的视角。借用薛兆丰老师的话说，<strong>经济学研究的并不是关于钱的知识，而是真实世界的运行规律，是人与人之间的协作方式。而一切自然因素带来的影响，都会被人类的协作网络放大。</strong> 从这个角度看，懂一点经济学，是不是很有必要？最近，薛兆丰老师的经济学课又有加餐，假如你对经济学感兴趣，这门课推荐你来看一看。</p><p>最后，总结一下，今天说了两个话题。</p><p>第一，怎样借助神经科学提升工作健康度？我们说了一组很具体的建议。包括，上午找一个小点的空间，把光线调亮，把显示器抬高，并多做逻辑性的工作。下午反过来，把光线调暗，找一个大点的空间，多做创意性的工作。</p><p>第二，可可豆价格为什么上涨？自然因素只是一个基础，关键是人的预期，给这个基础提供了杠杆。换句话说，决定涨价的不仅是产量，更是人的预期。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;节选自：得到头条 | 377期&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天，我将从两个话题出发，为你提供知识服务。第一个是，全国第36个爱国卫生健康月活动落下帷幕。第二个是，2024年一季度，可可价格大幅上涨。&lt;/p&gt;
&lt;p&gt;先来看今天的第一条</summary>
      
    
    
    
    <category term="杂记" scheme="http://ai.mak.cn/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
    <category term="杂记" scheme="http://ai.mak.cn/tags/%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>微服务核心架构梳理</title>
    <link href="http://ai.mak.cn/posts/3999/"/>
    <id>http://ai.mak.cn/posts/3999/</id>
    <published>2024-07-27T16:00:00.000Z</published>
    <updated>2025-02-11T03:10:23.687Z</updated>
    
    <content type="html"><![CDATA[<h1 id="通用的高并发架构设计"><a href="#通用的高并发架构设计" class="headerlink" title="通用的高并发架构设计"></a>通用的高并发架构设计</h1><p>关键词：读&#x2F;写分离、数据缓存、缓存更新、CQRS、数据分片、异步写</p><p>本文节选自电子工业出版社博文视点刚刚出版的<strong>《亿级流量系统架构设计与实战》</strong>一书。</p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><blockquote><p>链接 <a href="https://mp.weixin.qq.com/s/KcPIR5jB6bJUGpEzcmlAGA">https://mp.weixin.qq.com/s/KcPIR5jB6bJUGpEzcmlAGA</a></p></blockquote><p><strong>高并发架构设计的要点</strong></p><p>高并发意味着系统要应对海量请求。从笔者多年的面试经验来看，很多面试者在面对“什么是高并发架构”的问题时，往往会粗略地认为一个系统的设计是否满足高并发架构，就是看这个系统是否可以应对海量请求。再细问具体的细节时，回答往往显得模棱两可，比如每秒多少个请求才是高并发请求、系统的性能表现如何、系统的可用性表现如何，等等。</p><p>为了可以清晰地评判一个系统的设计是否满足高并发架构，在正式给出通用的高并发架构设计方案前，我们先要厘清形成高并发系统的必要条件、高并发系统的衡量指标和高并发场景分类。</p><h3 id="形成高并发系统的必要条件"><a href="#形成高并发系统的必要条件" class="headerlink" title="形成高并发系统的必要条件"></a><strong>形成高并发系统的必要条件</strong></h3><p><strong>◎高性能：</strong>性能代表一个系统的并行处理能力，在同样的硬件设备条件下，性能越高，越能节约硬件资源；同时性能关乎用户体验，如果系统响应时间过长，用户就会产生抱怨。</p><p><strong>◎高可用性：</strong>系统可以长期稳定、正常地对外提供服务，而不是经常出故障、宕机、崩溃。</p><p><strong>◎可扩展性：</strong>系统可以通过水平扩容的方式，从容应对请求量的日渐递增乃至突发的请求量激增。</p><p>我们可以将形成高并发系统的必要条件类比为一个篮球运动员的各项属性：“高性能”相当于这个球员在赛场上的表现力强，“高可用性”相当于这个球员在赛场上总可以稳定发挥，“可扩展性”相当于这个球员的未来成长性好。</p><p><strong>高并发系统的衡量指标</strong></p><h4 id="1-高性能指标"><a href="#1-高性能指标" class="headerlink" title="1. 高性能指标"></a><strong>1. 高性能指标</strong></h4><p>一个很容易想到的可以体现系统性能的指标是，在一段时间内系统的平均响应时间。例如，在一段时间内有10000个请求被成功响应，那么在这段时间内系统的平均响应时间是这10000个请求响应时间的平均值。</p><p>然而，平均值有明显的硬伤并在很多数据统计场景中为大家所调侃。假设你和传奇篮球巨星姚明被分到同一组，你的身高是174cm，姚明的身高是226cm，那么这组的平均身高是2m！这看起来非常不合理。假设在10000个请求中有9900个请求的响应时间分别是1ms，另外100个请求的响应时间分别是100ms，那么平均响应时间仅为1.99ms，完全掩盖了那100个请求的100ms响应时间的问题。平均值的主要缺点是易受极端值的影响，这里的极端值是指偏大值或偏小值——当出现偏大值时，平均值将会增大；当出现偏小值时，平均值将会减小。</p><p>笔者推荐的系统性能的衡量指标是响应时间PCTn统计方式，PCTn表示请求响 应时间按从小到大排序后第n分位的响应时间。假设在一段时间内100个请求的响应时间从小到大排序如图所示，则第99分位的响应时间是100ms，即PCT99&#x3D; 100ms。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/PW0wIHxgg3kOkTPoPAr4hibU1UzUVsKg2tQruDR4cyliaic6QlVKSvjFMw9bVJlSuywW51hczIaQ3uB1adRXjGOkw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>分位值越大，对响应时间长的请求越敏感。比如统计10000个请求的响应时间：</p><p>◎PCT50&#x3D;1ms，表示在10000个请求中50%的请求响应时间都在1ms以内。</p><p>◎PCT99&#x3D;800ms，表示在10000个请求中99%的请求响应时间都在800ms以内。</p><p>◎PCT999&#x3D;1.2s，表示在10000个请求中99.9%的请求响应时间都在1.2s以内。</p><p>从笔者总结的经验数据来看，请求的平均响应时间&#x3D;200ms，且PCT99&#x3D;1s的高并发系统基本能够满足高性能要求。如果请求的响应时间在200ms以内，那么用户不会感受到延迟；而如果请求的响应时间超过1s，那么用户会明显感受到延迟。</p><h4 id="2-高可用性指标"><a href="#2-高可用性指标" class="headerlink" title="2. 高可用性指标"></a><strong>2. 高可用性指标</strong></h4><p>可用性&#x3D;系统正常运行时间&#x2F;系统总运行时间，表示一个系统正常运行的时间占比，也可以将其理解为一个系统对外可用的概率。我们一般使用N个9来描述系统的可用性如何，如表所示。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/PW0wIHxgg3kOkTPoPAr4hibU1UzUVsKg2stWwyc9UN5PY33xWAkR2w0hRguae7icvIVBUCb3LiaQg2NPgpRRtR58w/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>高可用性要求系统至少保证3个9或4个9的可用性。在实际的系统指标监控中，很多公司会取3个9和4个9的中位数：99.95%（3个9、1个5），作为系统可用性监控的阈值。当监控到系统可用性低于99.95%时及时发出告警信息，以便系统维护者可以及时做出优化，如系统可用性补救、扩容、分析故障原因、系统改造等。</p><h4 id="3-可扩展性指标"><a href="#3-可扩展性指标" class="headerlink" title="3. 可扩展性指标"></a><strong>3. 可扩展性指标</strong></h4><p>面对到来的突发流量，我们明显来不及对系统做架构改造，而更快捷、有效的做法是增加系统集群中的节点来水平扩展系统的服务能力。可扩展性&#x3D;吞吐量提升比例&#x2F;集群节点增加比例。在最理想的情况下，集群节点增加几倍，系统吞吐量就能增加几倍。一般来说，拥有70%～80%可扩展性的系统基本能够满足可扩展性要求。</p><p><strong>高并发场景分类</strong></p><p>我们使用计算机实现各种业务功能，最终将体现在对数据的两种操作上，即读和写，于是高并发请求可以被归类为高并发读和高并发写。比如有的业务场景读多写少，需要重点解决高并发读的问题；有的业务场景写多读少，需要重点解决高并发写的问题；而有的业务场景读多写多，则需要同时解决高并发读和高并发写的问题。将高并发场景划分为高并发读场景和高并发写场景，是因为在这两种场景中往往有不同的高并发解决方案。</p><hr><p><strong>数据库读&#x2F;写分离</strong></p><p>大部分互联网应用都是读多写少的，比如刷帖的请求永远比发帖的请求多，浏览商品的请求永远比下单购买商品的请求多。数据库承受的高并发请求压力，主要来自读请求。我们可以把数据库按照读&#x2F;写请求分成专门负责处理写请求的数据库（写库）和专门负责处理读请求的数据库（读库），让所有的写请求都落到写库，写库将写请求处理后的最新数据同步到读库，所有的读请求都从读库中读取数据。这就是数据库读&#x2F;写分离的思路。</p><p>数据库读&#x2F;写分离使大量的读请求从数据库中分离出来，减少了数据库访问压力，缩短了请求响应时间。</p><p><strong>读&#x2F;写分离架构</strong></p><p>我们通常使用数据库主从复制技术实现读&#x2F;写分离架构，将数据库主节点Master作为“写库”，将数据库从节点Slave作为“读库”，一个Master可以与多个Slave连接，如图所示。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/PW0wIHxgg3kOkTPoPAr4hibU1UzUVsKg2cib2X6fOvlu35U5MGlqZ6oe8eeSWK1G2ZWSyNg2LW74ozZKJKibbIrpQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>市面上各主流数据库都实现了主从复制技术。</p><h3 id="读-x2F-写请求路由方式"><a href="#读-x2F-写请求路由方式" class="headerlink" title="读&#x2F;写请求路由方式"></a><strong>读&#x2F;写请求路由方式</strong></h3><p>在数据库读&#x2F;写分离架构下，把写请求交给Master处理，而把读请求交给Slave处理，那么由什么角色来执行这样的读&#x2F;写请求路由呢？一般可以采用如下两种方式。</p><h4 id="1-基于数据库Proxy代理的方式"><a href="#1-基于数据库Proxy代理的方式" class="headerlink" title="1. 基于数据库Proxy代理的方式"></a><strong>1. 基于数据库Proxy代理的方式</strong></h4><p>在业务服务和数据库服务器之间增加数据库Proxy代理节点（下文简称Proxy），业务服务对数据库的一切操作都需要经过Proxy转发。Proxy收到业务服务的数据库操作请求后，根据请求中的SQL语句进行归类，将属于写操作的请求（如insert&#x2F;delete&#x2F;update语句）转发到数据库Master，将属于读操作的请求（如select语句）转发到数据库任意一个Slave，完成读&#x2F;写分离的路由。开源项目如中心化代理形式的MySQL-Proxy和MyCat，以及本地代理形式的MySQL-Router等都实现了读&#x2F;写分离功能。</p><h4 id="2-基于应用内嵌的方式"><a href="#2-基于应用内嵌的方式" class="headerlink" title="2. 基于应用内嵌的方式"></a><strong>2. 基于应用内嵌的方式</strong></h4><p>基于应用内嵌的方式与基于数据库Proxy代理的方式的主要区别是，它在业务服务进程内进行请求读&#x2F;写分离，数据库连接框架开源项目如gorm、shardingjdbc等都实现了此形式的读&#x2F;写分离功能。</p><h3 id="主从延迟与解决方案"><a href="#主从延迟与解决方案" class="headerlink" title="主从延迟与解决方案"></a><strong>主从延迟与解决方案</strong></h3><p>数据库读&#x2F;写分离架构依赖数据库主从复制技术，而数据库主从复制存在数据复制延迟（主从延迟），因此会导致在数据复制延迟期间主从数据的不一致，Slave获取不到最新数据。针对主从延迟问题有如下三种解决方案。</p><h4 id="1-同步数据复制"><a href="#1-同步数据复制" class="headerlink" title="1. 同步数据复制"></a><strong>1. 同步数据复制</strong></h4><p>数据库主从复制默认是异步模式，Master在写完数据后就返回成功了，而不管Slave是否收到此数据。我们可以将主从复制配置为同步模式，Master在写完数据后，要等到全部Slave都收到此数据后才返回成功。</p><p>这种方案可以保证数据库每次写操作成功后，Master和Slave都能读取到最新数据。这种方案相对简单，将数据库主从复制修改为同步模式即可，无须改造业务服务。</p><p>但是由于在处理业务写请求时，Master要等到全部Slave都收到数据后才能返回成功，写请求的延迟将大大增加，数据库的吞吐量也会有明显的下滑。这种方案的实用价值较低，仅适合在低并发请求的业务场景中使用。</p><h4 id="2-强制读主"><a href="#2-强制读主" class="headerlink" title="2. 强制读主"></a><strong>2. 强制读主</strong></h4><p>不同的业务场景对主从延迟的容忍性不一样。例如，用户a刚刚发布了一条状态，他浏览个人主页时应该展示这条状态，这个场景不太能容忍主从延迟；而好友用户b此时浏览用户a的个人主页时，可以暂时看不到用户a最新发布的状态，这个场景可以容忍主从延迟。我们可以对业务场景按照主从延迟容忍性的高低进行划分，对于主从延迟容忍性高的场景，执行正常的读&#x2F;写分离逻辑；而对于主从延迟容忍性低的场景，强制将读请求路由到数据库Master，即强制读主。</p><h4 id="3-会话分离"><a href="#3-会话分离" class="headerlink" title="3. 会话分离"></a><strong>3. 会话分离</strong></h4><p>比如某会话在数据库中执行了写操作，那么在接下来极短的一段时间内，此会话的读请求暂时被强制路由到数据库Master，与“强制读主”方案中的例子很像，保证每个用户的写操作立刻对自己可见。暂时强制读主的时间可以被设定为略高于数据库完成主从数据复制的延迟时间，尽量使强制读主的时间段覆盖主从数据复制的实际延迟时间。</p><hr><p><strong>本地缓存</strong></p><h3 id="-1"><a href="#-1" class="headerlink" title=""></a></h3><p>在计算机世界中，缓存（Cache）无处不在，如CPU缓存、DNS缓存、浏览器缓存等。值得一提的是，Cache在我国台湾地区被译为“快取”，更直接地体现了它的用途：快速读取。缓存的本质是通过空间换时间的思路来保证数据的快速读取。</p><p>业务服务一般需要通过网络调用向其他服务或数据库发送读数据请求。为了提高数据的读取效率，业务服务进程可以将已经获取到的数据缓存到本地内存中，之后业务服务进程收到相同的数据请求时就可以直接从本地内存中获取数据返回，将网络请求转化为高效的内存存取逻辑。这就是本地缓存的主要用途。在本书后面的核心服务设计篇中会大量应用本地缓存，本节先重点介绍本地缓存的技术原理。</p><p><strong>基本的缓存淘汰策略</strong></p><p>虽然缓存使用空间换时间可以提高数据的读取效率，但是内存资源的珍贵决定了本地缓存不可无限扩张，需要在占用空间和节约时间之间进行权衡。这就要求本地缓存能自动淘汰一些缓存的数据，淘汰策略应该尽量保证淘汰不再被使用的数据，保证有较高的缓存命中率。基本的缓存淘汰策略如下。</p><p><strong>◎FIFO（First In First Out）策略：</strong>优先淘汰最早进入缓存的数据。这是最简单的淘汰策略，可以基于队列实现。但是此策略的缓存命中率较低，越是被频繁访问的数据是越早进入队列的，于是会被越早地淘汰。此策略在实践中很少使用。</p><p><strong>◎LFU（Least Frequently Used）策略：</strong>优先淘汰最不常用的数据。LFU策略会为每条缓存数据维护一个访问计数，数据每被访问一次，其访问计数就加1，访问计数最小的数据是被淘汰的目标。此策略很适合缓存在短时间内会被频繁访问的热点数据，但是最近最新缓存的数据总会被淘汰，而早期访问频率高但最近一直未被访问的数据会长期占用缓存。</p><p><strong>◎LRU（Least Recent Used）策略：</strong>优先淘汰缓存中最近最少使用的数据。此策略一般基于双向链表和哈希表配合实现。双向链表负责存储缓存数据，并总是将最近被访问的数据放置在尾部，使缓存数据在双向链表中按照最近访问时间由远及近排序，每次被淘汰的都是位于双向链表头部的数据。哈希表负责定位数据在双向链表中的位置，以便实现快速数据访问。此策略可以有效提高短期内热点数据的缓存命中率，但如果是偶发性地访问冷数据，或者批量访问数据，则会导致热点数据被淘汰，进而降低缓存命中率。</p><p>LRU策略和LFU策略的缺点是都会导致缓存命中率大幅下降。近年来，业界出现了一些更复杂、效果更好的缓存淘汰策略，比如W-TinyLFU策略。</p><hr><p><strong>分布式缓存</strong></p><h3 id="-2"><a href="#-2" class="headerlink" title=""></a></h3><p>由于本地缓存把数据缓存在服务进程的内存中，不需要网络开销，故而性能非常高。但是把数据缓存到内存中也有较多限制，举例如下。</p><p><strong>◎无法共享：</strong>多个服务进程之间无法共享本地缓存。</p><p><strong>◎编程语言限制：</strong>本地缓存与程序绑定，用Golang语言开发的本地缓存组件不可以直接为用Java语言开发的服务器所使用。</p><p><strong>◎可扩展性差：</strong>由于服务进程携带了数据，因此服务是有状态的。有状态的服务不具备较好的可扩展性。</p><p><strong>◎内存易失性：</strong>服务进程重启，缓存数据全部丢失。</p><p>我们需要一种支持多进程共享、与编程语言无关、可扩展、数据可持久化的缓存，这种缓存就是分布式缓存。</p><h3 id="分布式缓存选型"><a href="#分布式缓存选型" class="headerlink" title="分布式缓存选型"></a><strong>分布式缓存选型</strong></h3><p>主流的分布式缓存开源项目有Memcached和Redis，两者都是优秀的缓存产品，并且都具有缓存数据共享、与编程语言无关的能力。不过，相对于Memcached而言，Redis更为流行，主要体现如下。</p><p><strong>◎数据类型丰富：</strong>Memcached仅支持字符串数据类型缓存，而Redis支持字符串、列表、集合、哈希、有序集合等数据类型缓存。</p><p><strong>◎数据可持久化：</strong>Redis通过RDB机制和AOF机制支持数据持久化，而Memcached没有数据持久化能力。</p><p><strong>◎高可用性：</strong>Redis支持主从复制模式，在服务器遇到故障后，它可以通过主从切换操作保证缓存服务不间断。Redis具有较高的可用性。</p><p><strong>◎分布式能力：</strong>Memcached本身并不支持分布式，因此只能通过客户端，以一致性哈希这样的负载均衡算法来实现基于Memcached的分布式缓存系统。而Redis有官方出品的无中心分布式方案Redis Cluster，业界也有豆瓣Codis和推特Twemproxy的中心化分布式方案。</p><p>由于Redis支持丰富的数据类型和数据持久化，同时拥有高可用性和高可扩展性，因此它成为大部分互联网应用分布式缓存的首选。</p><h3 id="如何使用Redis缓存"><a href="#如何使用Redis缓存" class="headerlink" title="如何使用Redis缓存"></a><strong>如何使用Redis缓存</strong></h3><p>使用Redis缓存的逻辑如下。</p><p>（1）尝试在Redis缓存中查找数据，如果命中缓存，则返回数据。</p><p>（2）如果在Redis缓存中找不到数据，则从数据库中读取数据。</p><p>（3）将从数据库中读取到的数据保存到Redis缓存中，并为此数据设置一个过期时间。</p><p>（4）下次在Redis缓存中查找同样的数据，就会命中缓存。</p><p>将数据保存到Redis缓存时，需要为数据设置一个合适的过期时间，这样做有以下两个好处。</p><p>◎如果没有为缓存数据设置过期时间，那么数据会一直堆积在Redis内存中，尤其是那些不再被访问或者命中率极低的缓存数据，它们一直占据Redis内存会造成大量的资源浪费。设置过期时间可以使Redis自动删除那些不再被访问的缓存数据，而对于经常被访问的缓存数据，每次被访问时都重置过期时间，可以保证<strong>缓存命中率高。</strong></p><p>◎当数据库与Redis缓存由于各种故障出现了数据不一致的情况时，过期时间是一个很好的兜底手段。例如，设置缓存数据的过期时间为10s，那么数据库和Redis缓存即使出现数据不一致的情况，最多也就持续10s。过期时间可以保证数据库和Redis缓存仅在此时间段内有数据不一致的情况，因此可以保证<strong>数据的最终一致性。</strong></p><p>在上述逻辑中，有一个极有可能带来风险的操作：某请求访问的数据在Redis缓存中不存在，此请求会访问数据库读取数据；而如果有大量的请求访问数据库，则可能导致数据库崩溃。Redis缓存中不存在某数据，只可能有两种原因：一是在Redis缓存中从未存储过此数据，二是此数据已经过期。下面我们就这两种原因来做有针对性的优化。</p><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a><strong>缓存穿透</strong></h3><p>当用户试图请求一条连数据库中都不存在的非法数据时，Redis缓存会显得形同虚设。</p><p>（1）尝试在Redis缓存中查找此数据，如果命中，则返回数据。</p><p>（2）如果在Redis缓存中找不到此数据，则从数据库中读取数据。</p><p>（3）如果在数据库中也找不到此数据，则最终向用户返回空数据</p><p>可以看到，Redis缓存完全无法阻挡此类请求直接访问数据库。如果黑客恶意持续发起请求来访问某条不存在的非法数据，那么这些非法请求会全部穿透Redis缓存而直接访问数据库，最终导致数据库崩溃。这种情况被称为“缓存穿透”。</p><p>为了防止出现缓存穿透的情况，当在数据库中也找不到某数据时，可以在Redis缓存中为此数据保存一个空值，用于表示此数据为空。这样一来，之后对此数据的请求均会被Redis缓存拦截，从而阻断非法请求对数据库的骚扰。</p><p>不过，如果黑客访问的不是一条非法数据，而是大量不同的非法数据，那么此方案会使得Redis缓存中存储大量无用的空数据，甚至会逐出较多的合法数据，大大降低了Redis缓存命中率，数据库再次面临风险。我们可以使用布隆过滤器来解决缓存穿透问题。</p><p>布隆过滤器由一个固定长度为m的二进制向量和k个哈希函数组成。当某数据被加入布隆过滤器中后，k个哈希函数为此数据计算出k个哈希值并与m取模，并且在二进制向量对应的N个位置上设置值为1；如果想要查询某数据是否在布隆过滤器中，则可以通过相同的哈希计算后在二进制向量中查看这k个位置值：</p><p>◎如果有任意一个位置值为0，则说明被查询的数据一定不存在；</p><p>◎如果所有的位置值都为1，则说明被查询的数据可能存在。之所以说可能存在，是因为哈希函数免不了会有数据碰撞的可能，在这种情况下会造成对某数据的误判，不过可以通过调整m和k的值来降低误判率。</p><p>虽然布隆过滤器对于“数据存在”有一定的误判，但是对于“数据不存在”的判定是准确的。布隆过滤器很适合用来防止缓存穿透：将数据库中的全部数据加入布隆过滤器中，当用户请求访问某数据但是在Redis缓存中找不到时，检查布隆过滤器中是否记录了此数据。如果布隆过滤器认为数据不存在，则用户请求不再访问数据库；如果布隆过滤器认为数据可能存在，则用户请求继续访问数据库；如果在数据库中找不到此数据，则在Redis缓存中设置空值。虽然布隆过滤器对“数据存在”有一定的误判，但是误判率较低。最后在Redis缓存中设置的空值也很少，不会影响Redis缓存命中率。</p><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a><strong>缓存雪崩</strong></h3><p>如果在同一时间Redis缓存中的数据大面积过期，则会导致请求全部涌向数据库。这种情况被称为“缓存雪崩”。缓存雪崩与缓存穿透的区别是，前者是很多缓存数据不存在造成的，后者是一条缓存数据不存在导致的。</p><p>缓存雪崩一般有两种诱因：大量数据有相同的过期时间，或者Redis服务宕机。第一种诱因的解决方案比较简单，可以在为缓存数据设置过期时间时，让过期时间的值在预设的小范围内随机分布，避免大部分缓存数据有相同的过期时间。第二种诱因取决于Redis的可用性，选取高可用的Redis集群架构可以极大地降低Redis服务宕机的概率。</p><hr><p><strong>高并发读场景总结：CQRS</strong></p><p>无论是数据库读&#x2F;写分离、本地缓存还是分布式缓存，其本质上都是读&#x2F;写分离，这也是在微服务架构中经常被提及的CQRS模式。CQRS（Command Query Responsibility Segregation，命令查询职责分离）是一种将数据的读取操作与更新操作分离的模式。query指的是读取操作，而command是对会引起数据变化的操作的总称，新增、删除、修改这些操作都是命令。</p><h3 id="CQRS的简要架构与实现"><a href="#CQRS的简要架构与实现" class="headerlink" title="CQRS的简要架构与实现"></a><strong>CQRS的简要架构与实现</strong></h3><h3 id="为了避免引入微服务领域驱动设计的相关概念，下图给出了CQRS的简要架构。"><a href="#为了避免引入微服务领域驱动设计的相关概念，下图给出了CQRS的简要架构。" class="headerlink" title="为了避免引入微服务领域驱动设计的相关概念，下图给出了CQRS的简要架构。"></a>为了避免引入微服务领域驱动设计的相关概念，下图给出了CQRS的简要架构。</h3><p><img src="https://mmbiz.qpic.cn/mmbiz_png/PW0wIHxgg3kOkTPoPAr4hibU1UzUVsKg2dladKjFx9dFgJp2LmqE1PCo9zvMgPftvkAtO4WRibadn6ntClbtxibjQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>（1）当业务服务收到客户端发起的command请求（即写请求）时，会将此请求交给写数据存储来处理。</p><p>（2）写数据存储完成数据变更后，将数据变更消息发送到消息队列。</p><p>（3）读数据存储负责监听消息队列，当它收到数据变更消息后，将数据写入自身。</p><p>（4）当业务服务收到客户端发起的query请求（即读请求）时，将此请求交给读数据存储来处理。</p><p>（5）读数据存储将此请求希望访问的数据返回。</p><p>写数据存储、读数据存储、数据传输通道均是较为宽泛的代称，其中写数据存储和读数据存储在不同的高并发场景下有不同的具体指代，数据传输通道在不同的高并发场景下有不同的形式体现，可能是消息队列、定时任务等。</p><p>◎对于数据库读&#x2F;写分离来说，写数据存储是 Master，读数据存储是 Slave，消息队列的实现形式是数据库主从复制。</p><p>◎对于分布式缓存场景来说，写数据存储是数据库，读数据存储是 Redis 缓存，消息队列的实现形式是使用消息中间件监听数据库的binlog数据变更日志。</p><p>无论是何种场景，都应该为写数据存储选择适合高并发写入的存储系统，为读数据存储选择适合高并发读取的存储系统，消息队列作为数据传输通道要足够健壮，保证数据不丢失。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;通用的高并发架构设计&quot;&gt;&lt;a href=&quot;#通用的高并发架构设计&quot; class=&quot;headerlink&quot; title=&quot;通用的高并发架构设计&quot;&gt;&lt;/a&gt;通用的高并发架构设计&lt;/h1&gt;&lt;p&gt;关键词：读&amp;#x2F;写分离、数据缓存、缓存更新、CQRS、数据分片、异步写</summary>
      
    
    
    
    <category term="技术小栈" scheme="http://ai.mak.cn/categories/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/"/>
    
    
    <category term="架构" scheme="http://ai.mak.cn/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>conda、pip、anaconda、miniconda、miniforge、mambaforge 区分</title>
    <link href="http://ai.mak.cn/posts/40058/"/>
    <id>http://ai.mak.cn/posts/40058/</id>
    <published>2024-07-13T16:00:00.000Z</published>
    <updated>2025-02-11T03:10:23.349Z</updated>
    
    <content type="html"><![CDATA[<h1 id="conda、pip、anaconda、miniconda、miniforge、mambaforge-区分"><a href="#conda、pip、anaconda、miniconda、miniforge、mambaforge-区分" class="headerlink" title="conda、pip、anaconda、miniconda、miniforge、mambaforge 区分"></a>conda、pip、anaconda、miniconda、miniforge、mambaforge 区分</h1><p><strong>核心属性和本质：</strong></p><ul><li><strong>conda</strong> 和 <strong>pip</strong> 的本质是包管理工具，它们帮助用户管理和安装软件包。</li><li><strong>anaconda</strong>、<strong>miniconda</strong>、<strong>miniforge</strong> 和 <strong>mambaforge</strong> 的本质是环境管理工具，它们提供了一套完整的工具来管理编程环境。</li></ul><p><strong>来个比较容易理解的比喻</strong>：<br> 在一个巨大的图书馆里，有各种各样的书，你想去借书看。这个图书馆就像是一个编程语言的世界，而书籍就是各种各样的代码库和工具。<br> <strong>conda</strong> 是一个聪明的图书管理员，它不仅能帮你找到书，还能告诉你哪些书是相互关联的，确保你借的每本书都能很好地一起工作。它不仅管理Python的书籍，还管理其他语言的书籍。<br> 解释：一个开源的包管理系统和环境管理系统，可以用来安装、运行和升级包和它们的依赖关系。它支持多种语言。</p><p><strong>pip</strong> 是另一个图书管理员，但它专注于Python的书籍。它很擅长找到你想要的Python书籍，但有时候它不太关心这些书是否能很好地相互协作。<br> 解释：是Python的默认包管理工具，专为python打造，用于安装和管理Python库。</p><p><strong>anaconda</strong> 是一个巨大的书架，上面预先放好了很多最常用的书籍，这样你就不用每次都去找图书管理员了。它特别适合那些不想花太多时间挑选书籍的人。<br> 解释：是一个发行版，由Anaconda公司开发，里面除了conda，还包含了Python以及许多科学计算相关的包。</p><p><strong>miniconda</strong> 是一个更小的书架，上面只有几本你开始阅读时必须的书籍。如果你需要更多的书，你可以去找conda图书管理员帮你。<br> 解释：是anaconda的一个轻量级版本，只包含conda和其依赖项，没有预装其他任何包。Miniconda的优势在于它的体积较小，安装过程更快，用户可以根据需要自行选择和安装所需的包。</p><p><strong>miniforge</strong> 和 <strong>mambaforge</strong> 是类似于miniconda的两个不同品牌的小书架，但它们来自不同的制造商。它们提供了一些不同的特性，比如更快的书籍检索速度（mambaforge）或者更多地支持开源书籍（miniforge）。<br> 解释：miniforge是一个社区驱动的miniconda替代品，与Miniconda相比，提供了更多的编译器和开发工具，适用于更复杂的环境和依赖关系。社区持续在维护和更新，所以一般用这个就足够了。<br> mambaforge脱胎于Miniforge，做了一些优化，以更高的效率实现了和conda 同样的功能，对conda中低效的部分进行了重写。不过从 23 年 9 月份开始，Mambaforge 已经不鼓励使用了，可以放弃。</p><p>mambaforge的官方申明：</p><blockquote><p>Mambaforge（Discouraged as of September 2023）<br> With the <a href="https://link.juejin.cn/?target=https://link.zhihu.com/?target=https://github.com/conda-forge/miniforge/releases/tag/23.3.1-0">release</a> of Miniforge3-23.3.1-0, that incorporated the changes in <a href="https://link.juejin.cn/?target=https://link.zhihu.com/?target=https://github.com/conda-forge/miniforge/pull/277">#277</a>, the packages and configuration of Mambaforge and Miniforge3 are now <strong>identical</strong>. The only difference between the two is the name of the installer and, subsequently, the default installation directory. Given its wide usage, there are no plans to deprecate Mambaforge. If at some point we decide to deprecate Mambaforge, it will be appropriately announced and communicated with sufficient time in advance.<br> As of September 2023, the new usage of Mambaforge is thus discouraged. Bug reports specific to Mambaforge will be closed as won’t fix.</p></blockquote><p>意思就是，Miniforge已经把 Mambaforge 的功能给合并过来了，虽然目前Mambaforge还能用，不过不推荐，随时可能弃用，而且里面的 bug 也不会修了。</p><p>总结一下，绝大部分用户使用Miniforge 即可，常用做法是，conda 命令创建虚拟环境，conda install 安装 torch 包，剩下的包交给 pip 来搞定，兼具安全和高效。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;conda、pip、anaconda、miniconda、miniforge、mambaforge-区分&quot;&gt;&lt;a href=&quot;#conda、pip、anaconda、miniconda、miniforge、mambaforge-区分&quot; class=&quot;headerl</summary>
      
    
    
    
    <category term="技术小栈" scheme="http://ai.mak.cn/categories/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/"/>
    
    
    <category term="python" scheme="http://ai.mak.cn/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>怎样读书，才算对得起自己？</title>
    <link href="http://ai.mak.cn/posts/626/"/>
    <id>http://ai.mak.cn/posts/626/</id>
    <published>2024-07-06T16:00:00.000Z</published>
    <updated>2025-02-11T03:10:23.732Z</updated>
    
    <content type="html"><![CDATA[<p>怎样读书，才算对得起自己？</p><blockquote><p>节选自：得到头条 | 360期</p></blockquote><p>今天，我将从两个话题出发，为你提供知识服务。第一个是，423世界读书日特刊。第二个是，法国巴黎恢复服务员赛跑。</p><p>先来看今天的第一条。今天是4月23日，世界读书日，也是咱们得到的破万卷节。你大概率上能看到好多人在谈论读书的方法，或者推荐这一年的重磅书。这些信息都很有价值，建议你有空去看看。</p><p>回到今天的节目，咱们换个角度，把姿态放轻松点，权当是同学之间互相交流。我想跟你说说，我昨天早上一个小时，在得到电子书随意刷书，获得的收获。没错，就是早上一个小时，在得到电子书的新书榜上随手翻翻。</p><p>有人可能会问，只是随手翻翻，能有多大的收获？你别说，收获还不少。接下来就跟你汇报一下我这一个小时乱翻书的收获。主要也是想跟你交流一下，乱翻书，快刷书，是不是也算一件很有趣的事？</p><p>好，咱们正式开始。这一个小时，我主要有三个收获。</p><p>第一，是安顿感。也就是，以前某些觉得很沉重的事，突然变得轻松了。</p><p>比如，昨天，得到电子书的新书榜上，有本书排名很靠前，复旦大学的经济学者，梁捷老师写的《表层的真理》。这是一本普通人了解经济学的入门书。刚翻开前言部分，就看到一个好玩的故事。</p><p>说的是，曾经有经济学家专门研究非洲的足球比赛。他们主要想搞清楚，踢足球，是怎么影响非洲人的国家认同的。我们都知道，非洲的很多国家是由部落组成的。尽管这些国家已经建成几十年，但很多人对国家其实没什么认同感，他们始终觉得，自己是某个部落的人。这也导致，很多国家内部，经常发生部落冲突，死伤惨重。</p><p>那么，<strong>怎么让大家建立国家认同呢？几位经济学家就去调查数据。结果发现，足球是个特别关键的因素。</strong> 在足球比赛之前你问当地人，说你觉得自己是某个国家的人，还是某个部落的人？他们大概率会回答，我是部落的人。但是，在足球比赛结束你再去问，会有很多人改变想法，觉得自己是某个国家的人。尤其这个国家的足球队取得胜利，会有37%的人改变想法，从部落认同转变为国家认同。有资格参加非洲杯的国家，他们的国内冲突，要比没有资格参加非洲杯的国家，少9%。</p><p>这个感觉就好比，一个公司里，就算AB两个部门矛盾再深，一旦整个公司派出球队，跟别的公司比赛，这两个部门的关系也会好转很多。说白了，想团结团队，就去组织足球赛。</p><p>但是，这个故事，还不是这本《表层的真理》的核心。作者是想通过这个故事跟你说，你看，这就是现在的经济学家们正在研究的事。艰深吗？枯燥吗？并没有。因此，别对经济学犯怵。</p><p>你看，到这一步，我就有了两个选择。我可以接着读这本书，看更多有趣的故事。我也可以顺手就把这个故事转发给身边刚毕业的朋友，然后跟他说，学点经济学吧，你看，经济学多好玩啊。总之，读这本书的短短几分钟，肯定不亏，对得起自己。</p><p>第二个收获是，重逢。也就是，<strong>很多自己经历过的事，你读书时会发现，原来作者也有一模一样的经历，就像在大街上突然遇见多年不见的朋友</strong>。</p><p>比如，在新书榜上，有本书叫《吃着吃着就老了》，作者是著名的纪录片导演，也是《风味人间》的总导演陈晓卿老师。里面主要说的是他自己这些年的跟吃有关的回忆。书里面有几段说的是他工作时，单位附近的餐馆。</p><p>为什么说惊喜？因为我过去跟陈晓卿老师，就在同一栋大楼里办公。尽管没见过面，但他讲的餐馆，我正好都吃过。这个时候你再看书里的内容，就多了一层微妙的感受。</p><p>比如，说到单位楼下新开的连锁饼店，陈晓卿老师说，馅饼还行，但老板胆子大，还做老友粉，味道不好评价。但对我来说，我第一次吃老友粉这个东西，就在这家店。要不是后来去南宁吃到正宗的，我还一直觉得老友粉就是楼下饼店的样子。</p><p>再比如，说到北京的基辅罗斯，是家俄罗斯餐厅。也熟悉，我去那参加过朋友的婚礼，里面有俄罗斯人唱歌表演。顺着玉渊潭公园南门一路往西走就是。假如是晚上一个人走，还有点打怵。这条路总给人种灯下黑的感觉。</p><p>你看，作者讲的是他的回忆。但读者从中读到的，可能是自己经历过的事。</p><p>你看，到这里，我又有两个选择。继续读，能读到更多的故事。但就此打住也行，就像好久不见的朋友重逢。即使只是畅聊几句，也觉得很尽兴。这个感觉是不是很奇妙？</p><p>第三个收获是，不同。也就是，<strong>能看到很多不同的观点。这些观点你未必同意，但是，你会因为知道它而感到有趣。会觉得原来某件事，还可以从这个角度去思考</strong>。</p><p>比如，得到电子书有本最近上线的新书，叫《百岁生活》。作者是一位日本的精神科医生，叫和田秀树。书很薄，只有5万多字。看的人也不多。但是翻开之后，还是能发现一点不一样的东西。</p><p>比如，这本书里一直强调一个概念，叫幸龄。作者一直说，假如一个人能活到80岁以上，这就是幸运，就别想着整天去治病了。因为这会儿身体很多机能在衰退，有可能会因为治了这个毛病，导致其他的问题。这时假如身体出毛病，目标就不是根治，轻易也别做手术，而是想办法让自己能尽可能舒服地活着。这位和田秀树还举了很多日本的数据。比如有的地方因为特殊原因，医院停运了一段时间。结果这段时间离世的80岁以上老人，反而减少了等等。</p><p>这个观点一定对吗？未必。估计很多人也不会同意。但是，这本书至少给了我们一个提醒，就是在面对疾病时，系统的健康观很重要。不能只思考某个局部，而是要尽量全面地考虑自己的健康状况。</p><p>你看，读到这，我又有两个选择。一是继续读下去，看看这位作者还说了什么。二是带着这个提醒，转身就走，去读别的书。总之，至少读这本书的几分钟不白费，对得起自己。</p><p>好，关于昨天早上的刷书收获，咱们先说到这。注意，我们可不是想说，一定要按照某种方法读书。而是想告诉你，<strong>随手乱翻书，其实是一件很好玩，也很有收获的事。假如你现在有类似的感受，别犹豫，也来试试</strong>。同时，423前后，也是咱们得到的破万卷节。得到电子书有优惠活动，优惠力度很大，趁现在别错过。</p><p>再来看今天的第二条。前段时间，法国巴黎恢复了一项奇怪的体育比赛，服务员赛跑。也就是，穿着制服的男女服务员，手托餐盘，餐盘里放一个羊角面包、一个空咖啡杯和一杯水，从巴黎市政厅出发，沿环线跑完2公里赛程。</p><p>这本来是巴黎的传统活动，有100多年的历史。但最近13年一直停办，直到今年，又恢复了举办。</p><p>一方面，是在为夏天的巴黎奥运会造势，另一方面，这个比赛也有强烈的代表意义。咖啡馆是巴黎的标志之一。巴黎市市长伊达尔戈说，大大小小的咖啡馆是“巴黎的灵魂”。比如最著名的花神咖啡馆，15世纪就开业了。据说海明威在这里写了《太阳照常升起》。毕加索在这里的玻璃上作过画。萨特和波伏瓦也每天在这里畅谈，1943年萨特在这里写完了代表作《存在与虚无》。</p><p>其实，直到今天，在咖啡馆写作也特别流行。比如，奥斯卡最佳影片《寄生虫》的导演和编剧奉俊昊，就特别喜欢在咖啡馆写作，而且他会找一个角落，特意背对人群，这样，既能享受咖啡馆的环境，又能让自己专注于手头的任务。</p><p>顺着这个话题，咱们就来说说，一个写作者，怎么写才能写得更快更多？前段时间，美国专栏作家托德·布里森专门写文章做了分享，他给很多美国大媒体供过稿，还每天给读者写一份电子报，算是很高产了。假如你也是一名创作者，尤其是持续创作者，接下来的这三个技巧，你可以做个参考。</p><p><strong>第一个技巧是，给自己设定限制</strong>。说得具体点，就是把电脑电源拔掉。</p><p>这是布里森从一次咖啡馆写作中得来的。他去咖啡店写稿，原本计划集中精力写4小时。但是坐下之后他发现忘了带电源，剩余电量只够写一个多小时。于是，他集中注意力，用一个小时就写完了稿子。这篇稿子，最后成了他2020年最受欢迎的一篇文章。</p><p>你看， 有时候拥有无限的保障，可能反而会模糊你的注意力。因此有时候，需要把自己放在一个没有兜底的环境里。有了这个限制之后，没准反而会提高效率。</p><p><strong>第二个技巧是，不要永远只盯着一篇稿子，你可以尝试同时面对三篇，每20分钟切换一次</strong>。</p><p>布里森说，这个技巧来自奥斯卡得主，《乔乔兔》的编剧塔伊加·维迪提。维迪提完成这部剧本，用了六年时间，听起来很久，但这六年里，他还同时完成了很多其他剧本。方法就是，不同项目同时开展，经常切换。具体到每天的写作上，你可以设置一个20分钟的闹钟，同时写三篇稿子，每20分钟切换一次。当你切回第一个项目的时候，过去了40分钟，这个时间，不至于让你忘了之前的内容，也能让你产生一些新的想法。</p><p><strong>第三个技巧比较细节，跟打字这个动作有关，说的是，眼睛不要看屏幕，手里不要停，一口气把自己的想法打下来</strong>。</p><p>眼睛不看屏幕，是因为，盯着屏幕上的单词，会过多占用你的注意力，有时候你看着自己写的东西，纠结一个用词或者一个句子，速度就会被大大拖慢。布里森建议，确定好光标的位置，然后开始打字，尽可能少看屏幕。假如你用台式机写作，可以把显示器关掉，假如你用笔记本写作，就把屏幕压低。</p><p>写错了也无所谓，关键是，快速把你大脑里的句子写下来，等写完了之后再统一检查。布里森认为，要把写初稿当成一场冲刺，而不是马拉松，一鼓作气地写完，比什么都重要。</p><p>在这里，引用美国科幻作家雷·布拉德伯里的一句话，他一生写了超过500部作品，最有名的一句口号就是，你的直觉知道该写什么，因此别阻挡它。</p><p>最后，总结一下，今天说了两个话题。</p><p>第一，关于怎样阅读？读书不只是为了对书负责，更是为了对人负责，对自己负责。乱翻书，快刷书，往往能获得意外之喜。</p><p>第二，关于怎样书写？关键在于，不让书写这个动作干扰思考。就像刚才说的，你的直觉知道应该写什么，因此别阻挡它。</p><p>这两个话题，一个是关于阅读，一个是关于书写。顺着这两个话题，最后还有个特别分享。前不久，脱不花老师给我推荐了一首诗，说很适合在423这天读一读。这首诗的来历很特别。今年10月，NASA准备往木卫二发射一颗探测器，木卫二也叫欧罗巴，因此这枚探测器就叫欧罗巴快船。有趣的是，这回NASA请桂冠诗人阿达·利蒙专门给木卫二写了一首诗，刻在了欧罗巴快船上，诗的名字叫《赞美神秘》。</p><p>你看，这个事是不是也反映了一个真相。这就是，<strong>哪怕在宇宙深处，只要有人类在，那么有两件事就会始终存在，这就是，阅读与书写</strong>。</p><p>下面是这首诗的全文，我使用的是网络上Tina与大鸣两位老师翻译的版本，翻译得很精彩。</p><blockquote><p>色深邃，如浓墨写意天空。仰望熟悉的满天星斗，脱口而出我们的祈愿。从地球了解太空，仿佛阅读一本关于宇宙的书，准确无误，专业易懂。然而，苍穹之下，仍有未解之谜。鲸鱼的歌声，风中摇动的树枝上，鸣鸟的对歌吟唱。我们是心怀敬畏的生灵，好奇于一切美好、叶子和花开，悲伤和快乐，阳光和阴影。使我们联系在一起的不是黑暗，也不是遥远冰冷的空间，而是水的馈赠。每一滴雨水。每一条小溪，像似每根血管，和每一次的脉搏。木卫二，我们恰巧也由水而生。源自于浩瀚而瞩目的海洋。我们的构成也充满奇迹，有着伟大而平凡的爱，有着小而未知的世界。更有穿越黑暗，探究宇宙的呼唤。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;怎样读书，才算对得起自己？&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;节选自：得到头条 | 360期&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天，我将从两个话题出发，为你提供知识服务。第一个是，423世界读书日特刊。第二个是，法国巴黎恢复服务员赛跑。&lt;/p&gt;
&lt;p&gt;先来看</summary>
      
    
    
    
    <category term="杂记" scheme="http://ai.mak.cn/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
    <category term="杂记" scheme="http://ai.mak.cn/tags/%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>针对不同层次进行性能测试的监控</title>
    <link href="http://ai.mak.cn/posts/46880/"/>
    <id>http://ai.mak.cn/posts/46880/</id>
    <published>2024-07-05T16:00:00.000Z</published>
    <updated>2025-02-11T03:10:23.532Z</updated>
    
    <content type="html"><![CDATA[<h1 id="针对不同层次进行性能测试的监控"><a href="#针对不同层次进行性能测试的监控" class="headerlink" title="针对不同层次进行性能测试的监控"></a>针对不同层次进行性能测试的监控</h1><p>在执行性能测试的过程中，监控服务端的资源消耗等也是必备内容，监控的结果是帮助测试发现问题的眼睛。然而在实操过程中大家喜欢用JMeter 工具提供的插件进行监控，但是并不推荐使用这种方式，原因如下：</p><ul><li>指标相对简单且固定，结果数据粗糙且界面显示并不是很友好；</li><li>较大地增加了客户端压测机的资源开销，影响性能测试结果；</li><li>特定环境下，在服务器上安装插件是不被允许的，会很不方便。</li></ul><p>所以在这里，我们先来聊一下监控要点；</p><h1 id="一、层次清晰"><a href="#一、层次清晰" class="headerlink" title="一、层次清晰"></a><strong>一、层次清晰</strong></h1><p>从执行一次性能测试来看，需要监控的内容有很多，重点是要能理清楚不同的监控类型，以及分别能够解决什么问题？</p><h2 id="1、硬件层"><a href="#1、硬件层" class="headerlink" title="1、硬件层"></a><strong>1、硬件层</strong></h2><p>硬件层是最容易想到的一个层面，一般包含了 <strong>CPU 的使用率</strong>、<strong>内存使用率</strong>、<strong>磁盘</strong>和<strong>网络读写速度</strong>等，通过这些指标能够反馈出系统运行的基本情况，以及不同的 TPS 量级会消耗多少硬件资源。</p><h2 id="2、系统层"><a href="#2、系统层" class="headerlink" title="2、系统层"></a><strong>2、系统层</strong></h2><p><strong>系统层监控</strong>包括<strong>连接请求数</strong>、<strong>拒绝数</strong>、<strong>丢包率</strong>、<strong>请求超时</strong>等，相对于基础的硬件监控而言，<strong>这些指标更能够反映出目前系统存在的瓶颈</strong>，从而为根因问题的定位提供有力的线索。</p><h2 id="3、链路层"><a href="#3、链路层" class="headerlink" title="3、链路层"></a><strong>3、链路层</strong></h2><p><strong>链路层是直接面向架构和代码的</strong>，它的监控能够帮助我们更加准确地看到<strong>代码执行了哪些函数</strong>，<strong>涉及哪些服务</strong>，并且能够较为清晰地<strong>看到函数之间的调用耗时</strong>，还可以帮助<strong>定位代码存在的问题</strong>。</p><h2 id="4、业务层"><a href="#4、业务层" class="headerlink" title="4、业务层"></a><strong>4、业务层</strong></h2><p><strong>业务层监控本意是帮助判断用户输入是否合规，代码逻辑是否健壮</strong>。对于性能测试而言，业务层的监控可以帮助我们发现脚本参数问题以及高并发下业务逻辑运行是否正常等，比如随着测试的进行，可能会存在商品库存不足的情况。如果有业务层面的监控，当库存低于某阈值时，可以进行一定的提示以规避此类问题。</p><h1 id="二、定向深入"><a href="#二、定向深入" class="headerlink" title="二、定向深入"></a><strong>二、定向深入</strong></h1><p>首先我们通过基本的监控可以获得一些异常点，比如 CPU 高了、磁盘在等待，这些说白了是表象问题。就比如说某位同事今天没来，通过没来这个现象并不能直接下定论说他生病了。对于监控也是这样，是否有定位根因问题的手段，CPU 高了，需不需要进行线程分析，需要哪些权限和定位工具，这些在监控部署时都需要考虑到。</p><h2 id="1、CPU"><a href="#1、CPU" class="headerlink" title="1、CPU"></a><strong>1、CPU</strong></h2><p>top 是我们查看各个进程的资源占用状况最常用的命令，如下代码所示，这个命令简单却包含很大的信息量。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">top - 18:17:47 up 158 days,  9:32,  2 users,</span><br><span class="line"></span><br><span class="line">load average: 0.07, 0.15, 0.21</span><br><span class="line"></span><br><span class="line">Tasks: 154 total,   1 running, 152 sleeping,   0 stopped,   1 zombie</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">%</span><span class="language-bash">Cpu(s):  3.9 us,  1.3 sy,  0.0 ni, 94.6 <span class="built_in">id</span>,  0.2 wa,  0.0 hi,  0.0 si,  0.0 st</span></span><br><span class="line"></span><br><span class="line">KiB Mem :  8010676 total,   337308 free,  6036100 used,  1637268 buff/cache</span><br><span class="line"></span><br><span class="line">KiB Swap:        0 total,        0 free,        0 used.  1223072 avail Mem</span><br></pre></td></tr></table></figure><p>从以上的信息中，我们来介绍几个常用的重点指标</p><h3 id="（1）load-average"><a href="#（1）load-average" class="headerlink" title="（1）load average"></a><strong>（1）load average</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load average: 0.07, 0.15, 0.21</span><br></pre></td></tr></table></figure><p>三个数字都是代表进程队列的长度，从左到右分别表示一分钟、 五分钟和十五分钟的数据，数字越小压力值就越低，数字越大则压力越高，然而这个数值多小算小呢？多大算大呢？以单核处理器为例，打个比方就像收费站的一个 ETC 通道一样：</p><ul><li><strong>0</strong> 表示没有任何车辆需要通过；</li><li>从 <strong>0 到 1</strong> 可以认为很流畅，车辆不需要任何等待就可以通过；</li><li><strong>1</strong> 表示正好在这个通道可接受范围之内；</li><li><strong>超过 1</strong> 就已经有车辆在后面排队了。</li></ul><p>所以理想情况下，希望平均负载值在 1 以下。如果是 1 就代表目前没有可用资源了。在实际情况中，很多运维会把理想负载设置在 0.7 以下，这也是业内的一个“<strong>经验值</strong>”。</p><p>上面说的是一个单核处理器的情况，多核 CPU 的话，负载数值 &#x2F; CPU 核数在 0.00~1.00 之间表示正常，理想值也是在 0.7 以内。</p><h3 id="（2）CPU状态"><a href="#（2）CPU状态" class="headerlink" title="（2）CPU状态"></a><strong>（2）CPU状态</strong></h3><p>从 top 中你也可以看到每种类型进程消耗的 CPU 时间百分比，如下所示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">%</span><span class="language-bash">Cpu(s):  3.9 us,  1.3 sy,  0.0 ni, 94.6 <span class="built_in">id</span>,  0.2 wa,  0.0 hi,  0.0 si,  0.0 st</span></span><br></pre></td></tr></table></figure><ul><li><strong>us</strong> 列显示了用户进程所花费 CPU 时间的百分比。这个数值越高，说明用户进程消耗的 CPU 时间越多，可以用来分析代码中的 CPU 消耗热点。</li><li><strong>sy</strong> 列表示系统进程消耗的 CPU 时间百分比。</li><li><strong>ni</strong> 列表示改变优先级的进程占用 CPU 的百分比。</li><li><strong>id</strong> 列表示 CPU 处于空闲状态的时间百分比。</li><li><strong>wa</strong> 列显示了 I&#x2F;O 等待所占用的 CPU 时间的百分比，这里 wa 的参考值为 0.5，如果长期高于这个参考值，需要注意是否存在磁盘瓶颈。</li><li><strong>hi</strong> 列表示硬件中断占用 CPU 时间百分比。</li><li><strong>si</strong> 列表示软件中断占用 CPU 时间百分比。</li><li><strong>st</strong> 列表示当系统运行在虚拟机中时，当前虚拟机在等待 CPU 为它服务的时间；</li></ul><p>在已经输入 top 的情况下再输入数字 1，可以查看 CPU 的核数和每个核的运行状态。如下图是两核 CPU 的运行状态。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">%</span><span class="language-bash">Cpu0  :  3.0 us,  1.7 sy,  0.0 ni, 95.3 <span class="built_in">id</span>,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">%</span><span class="language-bash">Cpu1  :  2.4 us,  1.0 sy,  0.0 ni, 96.6 <span class="built_in">id</span>,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span></span><br></pre></td></tr></table></figure><h2 id="2、内存"><a href="#2、内存" class="headerlink" title="2、内存"></a><strong>2、内存</strong></h2><p>最常见的是通过 free 来查看 Linux 内存使用情况。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@JD ~]# free -m</span><br><span class="line"></span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line"></span><br><span class="line">Mem:           7822        5917         302         373        1602        1195</span><br><span class="line"></span><br><span class="line">Swap:             0           0           0</span><br></pre></td></tr></table></figure><p>通过单词的意思我们也能大概看出来 total、used、free 表示什么，它们分别是总的<strong>物理内存大小、已经被使用的物理内存和空闲的物理内存值</strong>是多少。</p><h2 id="3、磁盘"><a href="#3、磁盘" class="headerlink" title="3、磁盘"></a><strong>3、磁盘</strong></h2><h3 id="（1）iostat"><a href="#（1）iostat" class="headerlink" title="（1）iostat"></a><strong>（1）iostat</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> [root@JD ~]# iostat -x</span><br><span class="line"></span><br><span class="line">Linux 3.10.0-514.el7.x86_64 (JD)        01/18/2021      _x86_64_        (2 CPU)</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line"></span><br><span class="line">           5.24    0.00    1.57    0.07    0.00   93.12</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line"></span><br><span class="line">vda               0.00     0.29    0.57    5.30    20.50   630.14   221.82     0.07   11.53   59.83    6.36   1.18   0.69</span><br></pre></td></tr></table></figure><p>通过这个命令你能看到磁盘实时运行的情况，一般可以优先看 idle、util 和 svctm 这几列的数值：</p><ul><li><strong>idle</strong> 代表磁盘空闲百分比；</li><li><strong>util</strong> 接近 100%，表示磁盘产生的 I&#x2F;O 请求太多，I&#x2F;O 系统已经满负荷在工作，该磁盘可能存在瓶颈；</li><li><strong>svctm</strong> 代表平均每次设备 I&#x2F;O 操作的服务时间 (毫秒)。</li></ul><h3 id="（2）iotop"><a href="#（2）iotop" class="headerlink" title="（2）iotop"></a><strong>（2）iotop</strong></h3><p>iotop 这个命令并不是 linux 原生的，需要安装，以 CentOS 7.0 为例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@JD ~]# yum -y install iotop</span><br></pre></td></tr></table></figure><p>安装完成之后，直接输入 iotop，示意如下，就能清楚地看到哪些进程在消耗磁盘资源。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">6448 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % ifrit-agent</span><br><span class="line"></span><br><span class="line">14647 be/4 root        0.00 B/s    7.70 K/s  0.00 %  0.00 % java -Dserver.port=9080</span><br></pre></td></tr></table></figure><h2 id="4、网络"><a href="#4、网络" class="headerlink" title="4、网络"></a><strong>4、网络</strong></h2><h3 id="（1）netstat"><a href="#（1）netstat" class="headerlink" title="（1）netstat"></a><strong>（1）netstat</strong></h3><p>netstat 能提供 TCP 和 UDP 的连接状态等统计信息，可以简单判断网络是否存在堵塞。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@JD ~]# netstat</span><br><span class="line"></span><br><span class="line">Active Internet connections (w/o servers)</span><br><span class="line"></span><br><span class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State</span><br><span class="line"></span><br><span class="line">tcp        0      1 JD:49190                169.254.169.250:http    FIN_WAIT1</span><br><span class="line"></span><br><span class="line">tcp        0      0 JD:39444                169.254.169.254:http    TIME_WAIT</span><br><span class="line"></span><br><span class="line">tcp        0      0 JD:us-srv               worker-18.:sentinel-ent ESTABLISHED</span><br></pre></td></tr></table></figure><ul><li><strong>Proto：</strong>协议名（可以 TCP 协议或者 UDP 协议）。</li><li><strong>recv-Q：</strong>网络接收队列还有多少请求在排队。</li><li><strong>send-Q：</strong>网络发送队列有多少请求在排队。</li></ul><blockquote><p><strong>recv-Q 和 send-Q</strong> 如果长期不为 0，很可能存在网络拥堵，这个是判断网络瓶颈的重要依据。</p></blockquote><ul><li><strong>Foreign Address：</strong>与本机端口通信的外部 socket。</li><li><strong>State：</strong>TCP 的连接状态。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;针对不同层次进行性能测试的监控&quot;&gt;&lt;a href=&quot;#针对不同层次进行性能测试的监控&quot; class=&quot;headerlink&quot; title=&quot;针对不同层次进行性能测试的监控&quot;&gt;&lt;/a&gt;针对不同层次进行性能测试的监控&lt;/h1&gt;&lt;p&gt;在执行性能测试的过程中，监控服务端的</summary>
      
    
    
    
    <category term="技术小栈" scheme="http://ai.mak.cn/categories/%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%A0%88/"/>
    
    
    <category term="测试" scheme="http://ai.mak.cn/tags/%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
</feed>
